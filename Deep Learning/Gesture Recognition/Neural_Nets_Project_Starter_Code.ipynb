{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VDqMakhdmxeZ"
   },
   "source": [
    "# Gesture Recognition\n",
    "In this group project, you are going to build a 3D Conv model that will be able to predict the 5 gestures correctly. Please import the following libraries to get started."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 3407,
     "status": "ok",
     "timestamp": 1604436126836,
     "user": {
      "displayName": "Amit Chawla",
      "photoUrl": "",
      "userId": "06080236380106251748"
     },
     "user_tz": -330
    },
    "id": "TQBPqv4tmxek"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# import libraries\n",
    "import numpy as np\n",
    "import os\n",
    "import datetime\n",
    "import os\n",
    "import keras\n",
    "from skimage import io\n",
    "from skimage.transform import rescale, resize\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter \n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tGWWjZmWmxem"
   },
   "source": [
    "We set the random seed so that the results don't vary drastically."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uIgjhwHP1K4S"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 3405,
     "status": "ok",
     "timestamp": 1604436126840,
     "user": {
      "displayName": "Amit Chawla",
      "photoUrl": "",
      "userId": "06080236380106251748"
     },
     "user_tz": -330
    },
    "id": "WMQ8D_b7mxen"
   },
   "outputs": [],
   "source": [
    "np.random.seed(30)\n",
    "import random as rn\n",
    "rn.seed(30)\n",
    "from keras import backend as K\n",
    "import tensorflow as tf\n",
    "tf.set_random_seed(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ElbM_EOhmxep"
   },
   "source": [
    "In this block, you read the folder names for training and validation. You also set the `batch_size` here. Note that you set the batch size in such a way that you are able to use the GPU in full capacity. You keep increasing the batch size until the machine throws an error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 3398,
     "status": "ok",
     "timestamp": 1604436126840,
     "user": {
      "displayName": "Amit Chawla",
      "photoUrl": "",
      "userId": "06080236380106251748"
     },
     "user_tz": -330
    },
    "id": "Ktl51Bgjmxeq"
   },
   "outputs": [],
   "source": [
    "train_doc = np.random.permutation(open('Project_data/train.csv').readlines())\n",
    "val_doc = np.random.permutation(open('Project_data/val.csv').readlines())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 3392,
     "status": "ok",
     "timestamp": 1604436126841,
     "user": {
      "displayName": "Amit Chawla",
      "photoUrl": "",
      "userId": "06080236380106251748"
     },
     "user_tz": -330
    },
    "id": "iXpH5G_Zmxes"
   },
   "outputs": [],
   "source": [
    "# we started with batch size = 663 and slowly optimised it to fit into our resources \n",
    "batch_size = 30 #experiment with the batch size\n",
    "frames = 30 #number of frames in each video \n",
    "# we start with 120*120 images and adjust these later for model building process\n",
    "rows = 120 # final image height to be decided\n",
    "cols = 120 # final image width to be decided\n",
    "channels = 3\n",
    "step_size = 1 #this will help in customising the frames chosen from the video for model building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 3381,
     "status": "ok",
     "timestamp": 1604436126841,
     "user": {
      "displayName": "Amit Chawla",
      "photoUrl": "",
      "userId": "06080236380106251748"
     },
     "user_tz": -330
    },
    "id": "13E1RyUxmxew"
   },
   "outputs": [],
   "source": [
    "# we distribute the images on the basis of size. This is just done for experiment puroposes later.\n",
    "# outpaths = [train_path] #val_path\n",
    "def image_segregation(path='train'):\n",
    "    final_120 =[]\n",
    "    final_360=[]\n",
    "    doc = ''\n",
    "    if(path=='train'):\n",
    "        op = 'Project_data/train/'\n",
    "        doc = train_doc\n",
    "    else:\n",
    "        op = 'Project_data/val/'\n",
    "        doc = val_doc\n",
    "    for f in doc:\n",
    "        path = f.split(';')[0]\n",
    "        imgs = os.listdir(op+path)\n",
    "        for img in imgs:\n",
    "            image = io.imread(op+path+'/'+img)\n",
    "            if(image.shape[0]==360):\n",
    "                final_120.append(op+path+'/'+img) \n",
    "\n",
    "            if(image.shape[0]==120):\n",
    "                final_360.append(op+path+'/'+img)\n",
    "    return (final_120, final_360)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 3376,
     "status": "ok",
     "timestamp": 1604436126842,
     "user": {
      "displayName": "Amit Chawla",
      "photoUrl": "",
      "userId": "06080236380106251748"
     },
     "user_tz": -330
    },
    "id": "HXYE041rmxey"
   },
   "outputs": [],
   "source": [
    "make list of images with corresponding sizes\n",
    "final_120, final_360 = image_segregation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 3370,
     "status": "ok",
     "timestamp": 1604436126842,
     "user": {
      "displayName": "Amit Chawla",
      "photoUrl": "",
      "userId": "06080236380106251748"
     },
     "user_tz": -330
    },
    "id": "wNbx3UeNmxe1"
   },
   "outputs": [],
   "source": [
    "view random imagees\n",
    "selectedIndexes  = []\n",
    "for i in range(3):\n",
    "    selectedIndexes.append(rn.randint(0,5520))\n",
    "\n",
    "\n",
    "s_im_120 = [final_120[i] for i in selectedIndexes]\n",
    "s_im_360 = [final_360[i] for i in selectedIndexes]\n",
    "print(s_im_120)\n",
    "print(s_im_360)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VwHEJ0ajmxe4"
   },
   "source": [
    "## Generator\n",
    "This is one of the most important part of the code. The overall structure of the generator has been given. In the generator, you are going to preprocess the images as you have images of 2 different dimensions as well as create a batch of video frames. You have to experiment with `img_idx`, `y`,`z` and normalization such that you get high accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 3362,
     "status": "ok",
     "timestamp": 1604436126842,
     "user": {
      "displayName": "Amit Chawla",
      "photoUrl": "",
      "userId": "06080236380106251748"
     },
     "user_tz": -330
    },
    "id": "bZVAwtRLmxe4"
   },
   "outputs": [],
   "source": [
    "# we have looked at random images from the set and decided the following dimensions for the images. This has helped to \n",
    "# remove the edges and preserve the center of the image where gesture data is present. \n",
    "def cropImage(image):\n",
    "    (image_h, image_w, _) = image.shape\n",
    "    print(image.shape)\n",
    "    h_start=0\n",
    "    h_end = image_h\n",
    "    w_start=0\n",
    "    w_end = image_w\n",
    "    # for images 120*160\n",
    "    if(image_h==120):\n",
    "        h_start=20\n",
    "        w_start=10\n",
    "        w_end = 120\n",
    "    # for images of size 360*360\n",
    "    elif image_h==360:\n",
    "        h_start=30\n",
    "        w_start=30\n",
    "        w_end = 320\n",
    "    return image[h_start:h_end, w_start:w_end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 3351,
     "status": "ok",
     "timestamp": 1604436126843,
     "user": {
      "displayName": "Amit Chawla",
      "photoUrl": "",
      "userId": "06080236380106251748"
     },
     "user_tz": -330
    },
    "id": "iPDq9Y_qmxe7"
   },
   "outputs": [],
   "source": [
    "# this method will adjust the size of the image to given dimensions. The appropriate size will be found through experments.\n",
    "def resize_image(image, height=rows, width=cols):\n",
    "    return  resize(image, (height, width),anti_aliasing=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 3344,
     "status": "ok",
     "timestamp": 1604436126844,
     "user": {
      "displayName": "Amit Chawla",
      "photoUrl": "",
      "userId": "06080236380106251748"
     },
     "user_tz": -330
    },
    "id": "VtA2DmeHmxe9"
   },
   "outputs": [],
   "source": [
    "# we try different normalization technique\n",
    "def normalize_image(image):\n",
    "    norm_image = image - np.min(image)/np.max(image) - np.min(image)\n",
    "#     norm_image = image - np.percentile(image,5)/ np.percentile(image,95) - np.percentile(image,5)\n",
    "    return norm_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 3334,
     "status": "ok",
     "timestamp": 1604436126844,
     "user": {
      "displayName": "Amit Chawla",
      "photoUrl": "",
      "userId": "06080236380106251748"
     },
     "user_tz": -330
    },
    "id": "qZT62WCDmxfA"
   },
   "outputs": [],
   "source": [
    "#utility to show processed images\n",
    "def showImage(array, idx):\n",
    "    a = array[idx]\n",
    "    image = io.imread(a)\n",
    "    plt.subplot(2, 2,1)\n",
    "    plt.imshow(image)\n",
    "\n",
    "    cropped = cropImage(image)\n",
    "    plt.subplot(2,2,2)\n",
    "    plt.imshow(cropped)\n",
    "\n",
    "    resized = resize_image(cropped)\n",
    "    plt.subplot(2, 2,3)\n",
    "    plt.imshow(resized)\n",
    "\n",
    "    \n",
    "    normalized = normalize_image(resized)\n",
    "    plt.subplot(2, 2,4)\n",
    "    plt.imshow(normalized)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 3327,
     "status": "ok",
     "timestamp": 1604436126845,
     "user": {
      "displayName": "Amit Chawla",
      "photoUrl": "",
      "userId": "06080236380106251748"
     },
     "user_tz": -330
    },
    "id": "K7tnO7qMmxfE"
   },
   "outputs": [],
   "source": [
    "#plt.figure(figsize=(300,300))\n",
    "#showImage(s_im_360, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "executionInfo": {
     "elapsed": 3320,
     "status": "ok",
     "timestamp": 1604436126845,
     "user": {
      "displayName": "Amit Chawla",
      "photoUrl": "",
      "userId": "06080236380106251748"
     },
     "user_tz": -330
    },
    "id": "BsJO0HlMmxfG"
   },
   "outputs": [],
   "source": [
    "# view random images\n",
    "#plt.figure(figsize=(300,300))\n",
    "#showImage(s_im_120, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to generate a random affine transform on the iamge\n",
    "def get_random_affine():\n",
    "    dx, dy = np.random.randint(-1.7, 1.8, 2)\n",
    "    M = np.float32([[1, 0, dx], [0, 1, dy]])\n",
    "    return M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to initialize all the batch image data and labels\n",
    "def init_batch_data(batch_size):\n",
    "    batch_data = np.zeros((batch_size, frames, rows, cols, channels)) \n",
    "    batch_labels = np.zeros((batch_size,5)) # batch_labels is the one hot representation of the output\n",
    "    return batch_data, batch_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "executionInfo": {
     "elapsed": 3313,
     "status": "ok",
     "timestamp": 1604436126846,
     "user": {
      "displayName": "Amit Chawla",
      "photoUrl": "",
      "userId": "06080236380106251748"
     },
     "user_tz": -330
    },
    "id": "d6X9RiBtmSxp"
   },
   "outputs": [],
   "source": [
    "# internal function to generate augmented data. \n",
    "# We have done 2 types of augmentation to prevent overfitting of data- flipping of the images and affine transformation. \n",
    "def fetch_aug_batchdata(source_path, folder_list, batch_num, batch_size, t,validation):\n",
    "    \n",
    "    batch_data,batch_labels = init_batch_data(batch_size)\n",
    "    \n",
    "    # We will also build an augumented batch data with affine transformation\n",
    "    batch_data_aug,batch_labels_aug = init_batch_data(batch_size)\n",
    "    \n",
    "    # We will also build an augmented batch data with horizontal flip\n",
    "    batch_data_flip,batch_labels_flip = init_batch_data(batch_size)\n",
    "    \n",
    "    #create a list of image numbers you want to use for a particular video using full frames\n",
    "    img_idx = [x for x in range(0, frames)] \n",
    "\n",
    "    for folder in range(batch_size): # iterate over the batch_size\n",
    "        # read all the images in the folder\n",
    "        imgs = sorted(os.listdir(source_path+'/'+ t[folder + (batch_num*batch_size)].split(';')[0])) \n",
    "        # Generate a random affine to be used in image transformation for buidling agumented data set\n",
    "        M = get_random_affine()\n",
    "        \n",
    "        #  Iterate over the frames/images of a folder to read them in\n",
    "        for idx, item in enumerate(img_idx): \n",
    "            ## image = imread(source_path+'/'+ t[folder + (batch_num*batch_size)].strip().split(';')[0]+'/'+imgs[item]).astype(np.float32)\n",
    "            image = cv2.imread(source_path+'/'+ t[folder + (batch_num*batch_size)].strip().split(';')[0]+'/'+imgs[item], cv2.IMREAD_COLOR)\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "            \n",
    "            # Cropping non symmetric frames\n",
    "            if image.shape[0] != image.shape[1]:\n",
    "                image=image[0:120,20:140]\n",
    "            \n",
    "            #crop the images and resize them. Note that the images are of 2 different shape \n",
    "            #and the conv3D will throw error if the inputs in a batch have different shapes   \n",
    "            resized = cv2.resize(image, (rows, cols), interpolation = cv2.INTER_AREA)\n",
    "            #Normal data\n",
    "            batch_data[folder,idx] = (resized)\n",
    "            \n",
    "            #Data with affine transformation\n",
    "            batch_data_aug[folder,idx] = (cv2.warpAffine(resized, M, (resized.shape[0], resized.shape[1])))\n",
    "            \n",
    "            # Data with horizontal flip\n",
    "            batch_data_flip[folder,idx]= np.flip(resized,1)\n",
    "\n",
    "        batch_labels[folder, int(t[folder + (batch_num*batch_size)].strip().split(';')[2])] = 1\n",
    "        batch_labels_aug[folder, int(t[folder + (batch_num*batch_size)].strip().split(';')[2])] = 1\n",
    "        \n",
    "        # Labeling data with horizobtal flip, right swipe becomes left swipe and viceversa\n",
    "        if int(t[folder + (batch_num*batch_size)].strip().split(';')[2])==0:\n",
    "                    batch_labels_flip[folder, 1] = 1\n",
    "        elif int(t[folder + (batch_num*batch_size)].strip().split(';')[2])==1:\n",
    "                    batch_labels_flip[folder, 0] = 1\n",
    "                    \n",
    "        else:\n",
    "                    batch_labels_flip[folder, int(t[folder + (batch_num*batch_size)].strip().split(';')[2])] = 1\n",
    "                  \n",
    "    \n",
    "    batch_data_final = np.append(batch_data, batch_data_aug, axis = 0)\n",
    "    batch_data_final = np.append(batch_data_final, batch_data_flip, axis = 0)\n",
    "\n",
    "    batch_labels_final = np.append(batch_labels, batch_labels_aug, axis = 0) \n",
    "    batch_labels_final = np.append(batch_labels_final, batch_labels_flip, axis = 0)\n",
    "    \n",
    "    if validation:\n",
    "        batch_data_final=batch_data\n",
    "        batch_labels_final= batch_labels\n",
    "        \n",
    "    return batch_data_final,batch_labels_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "executionInfo": {
     "elapsed": 3304,
     "status": "ok",
     "timestamp": 1604436126846,
     "user": {
      "displayName": "Amit Chawla",
      "photoUrl": "",
      "userId": "06080236380106251748"
     },
     "user_tz": -330
    },
    "id": "Sjjx0Zt6mxfI"
   },
   "outputs": [],
   "source": [
    "# wrapper generator function. it supports ablation experiment and a flag to decide between training and validation folder\n",
    "def generator(source_path, folder_list, batch_size, validation=False,ablation=None):\n",
    "    print( 'Source path = ', source_path, '; batch size =', batch_size)\n",
    "    if(ablation!=None):\n",
    "        folder_list=folder_list[:ablation]\n",
    "    while True:\n",
    "        t = np.random.permutation(folder_list)\n",
    "        num_batches = len(folder_list)//batch_size # calculate the number of batches\n",
    "        for batch in range(num_batches): # we iterate over the number of batches\n",
    "            # you yield the batch_data and the batch_labels, remember what does yield do\n",
    "\n",
    "            yield fetch_aug_batchdata(source_path, folder_list, batch, batch_size, t,validation)\n",
    "        \n",
    "        # Code for the remaining data points which are left after full batches\n",
    "        if (len(folder_list) != batch_size*num_batches):\n",
    "            batch_size = len(folder_list) - (batch_size*num_batches)\n",
    "            yield fetch_aug_batchdata(source_path, folder_list, batch, batch_size, t,validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vS7SH2h6mxfK"
   },
   "source": [
    "Note here that a video is represented above in the generator as (number of images, height, width, number of channels). Take this into consideration while creating the model architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3297,
     "status": "ok",
     "timestamp": 1604436126847,
     "user": {
      "displayName": "Amit Chawla",
      "photoUrl": "",
      "userId": "06080236380106251748"
     },
     "user_tz": -330
    },
    "id": "1lAO-MjDmxfK",
    "outputId": "d71f8854-2608-4939-ebd4-42f6d0b4aa7a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# training sequences = 663\n",
      "# validation sequences = 100\n",
      "# epochs = 10\n"
     ]
    }
   ],
   "source": [
    "# path to images folders\n",
    "train_path = 'Project_data/train'\n",
    "val_path = 'Project_data/val'\n",
    "\n",
    "num_train_sequences = len(train_doc)\n",
    "print('# training sequences =', num_train_sequences)\n",
    "\n",
    "num_val_sequences = len(val_doc)\n",
    "print('# validation sequences =', num_val_sequences)\n",
    "\n",
    "num_epochs = 10 # choose the number of epochs\n",
    "print ('# epochs =', num_epochs)\n",
    "\n",
    "classes= 5 # output classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to plot performance of model\n",
    "def plot(history):\n",
    "    fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(15,4))\n",
    "    axes[0].plot(history.history['loss'])   \n",
    "    axes[0].plot(history.history['val_loss'])\n",
    "    axes[0].legend(['loss','val_loss'])\n",
    "\n",
    "    axes[1].plot(history.history['categorical_accuracy'])   \n",
    "    axes[1].plot(history.history['val_categorical_accuracy'])\n",
    "    axes[1].legend(['categorical_accuracy','val_categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0pSW5czRmxfO"
   },
   "source": [
    "## Model\n",
    "Here you make the model using different functionalities that Keras provides. Remember to use `Conv3D` and `MaxPooling3D` and not `Conv2D` and `Maxpooling2D` for a 3D convolution model. You would want to use `TimeDistributed` while building a Conv2D + RNN model. Also remember that the last layer is the softmax. Design the network in such a way that the model is able to give good accuracy on the least number of parameters so that it can fit in the memory of the webcam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "executionInfo": {
     "elapsed": 3291,
     "status": "ok",
     "timestamp": 1604436126847,
     "user": {
      "displayName": "Amit Chawla",
      "photoUrl": "",
      "userId": "06080236380106251748"
     },
     "user_tz": -330
    },
    "id": "oomrFBismxfO"
   },
   "outputs": [],
   "source": [
    "# keras related imports\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, GRU, Flatten, TimeDistributed, Flatten, BatchNormalization, Activation, Dropout, LSTM, ZeroPadding3D\n",
    "from keras.layers.convolutional import Conv3D, MaxPooling3D, Conv2D, MaxPooling2D\n",
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras import optimizers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we have decided to experiment with this optimizer first. So keeping it in common place\n",
    "optimiser = optimizers.Adam(0.001) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_map=[8, 16, 32, 64, 128] # we will expirment with different number of features for different layers\n",
    "dense_layer_size = [1000,500,5]\n",
    "num_epochs = 10\n",
    "batch_size = 10\n",
    "input_shape = (frames, rows, cols, channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write your model here\n",
    "model = Sequential()\n",
    "# add multiple convulation layers\n",
    "model.add(TimeDistributed(Conv2D(feature_map[0], (3, 3), strides=(2, 2),activation='relu', padding='same'), input_shape=input_shape))\n",
    "\n",
    "model.add(TimeDistributed(Conv2D(feature_map[1], (3,3),padding='same', activation='relu')))\n",
    "model.add(TimeDistributed(MaxPooling2D((2, 2), strides=(2, 2))))\n",
    "\n",
    "model.add(TimeDistributed(Conv2D(feature_map[2], (3,3),padding='same', activation='relu')))\n",
    "model.add(TimeDistributed(MaxPooling2D((2, 2), strides=(2, 2))))\n",
    "\n",
    "model.add(TimeDistributed(Conv2D(feature_map[3], (2,2),padding='same', activation='relu')))\n",
    "model.add(TimeDistributed(MaxPooling2D((2, 2), strides=(2, 2))))\n",
    "\n",
    "\n",
    "model.add(TimeDistributed(BatchNormalization()))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(TimeDistributed(Flatten()))\n",
    "\n",
    "model.add(Dense(dense_layer_size[0], activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(dense_layer_size[1], activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "## using LSTM as the RNN model along with softmax as our last layer.\n",
    "model.add(LSTM(128, return_sequences=False))\n",
    "model.add(Dense(classes, activation='softmax')) # using Softmax as last layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "time_distributed_1 (TimeDist (None, 30, 60, 60, 8)     224       \n",
      "_________________________________________________________________\n",
      "time_distributed_2 (TimeDist (None, 30, 60, 60, 16)    1168      \n",
      "_________________________________________________________________\n",
      "time_distributed_3 (TimeDist (None, 30, 30, 30, 16)    0         \n",
      "_________________________________________________________________\n",
      "time_distributed_4 (TimeDist (None, 30, 30, 30, 32)    4640      \n",
      "_________________________________________________________________\n",
      "time_distributed_5 (TimeDist (None, 30, 15, 15, 32)    0         \n",
      "_________________________________________________________________\n",
      "time_distributed_6 (TimeDist (None, 30, 15, 15, 64)    8256      \n",
      "_________________________________________________________________\n",
      "time_distributed_7 (TimeDist (None, 30, 7, 7, 64)      0         \n",
      "_________________________________________________________________\n",
      "time_distributed_8 (TimeDist (None, 30, 7, 7, 64)      256       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 30, 7, 7, 64)      0         \n",
      "_________________________________________________________________\n",
      "time_distributed_9 (TimeDist (None, 30, 3136)          0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 30, 1000)          3137000   \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 30, 1000)          0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 30, 500)           500500    \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 30, 500)           0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 128)               322048    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 5)                 645       \n",
      "=================================================================\n",
      "Total params: 3,974,737\n",
      "Trainable params: 3,974,609\n",
      "Non-trainable params: 128\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "print (model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/keras/callbacks.py:999: UserWarning: `epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n",
      "  warnings.warn('`epsilon` argument is deprecated and '\n"
     ]
    }
   ],
   "source": [
    "# timestamp to use in model name. \n",
    "curr_dt_time = datetime.datetime.now()\n",
    "\n",
    "model_name = 'model_init_lstm' + '_' + str(curr_dt_time).replace(' ','').replace(':','_') + '/'\n",
    "    \n",
    "if not os.path.exists(model_name):\n",
    "    os.mkdir(model_name)\n",
    "        \n",
    "filepath = model_name + 'model-{epoch:05d}-{loss:.5f}-{categorical_accuracy:.5f}-{val_loss:.5f}-{val_categorical_accuracy:.5f}.h5'\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath, save_best_only=True, monitor='val_loss', verbose=1, save_weights_only=False, mode='auto', period=1)\n",
    "\n",
    "LR = ReduceLROnPlateau(monitor='val_loss', factor=0.001, patience=5, cooldown=4, verbose=1,mode='auto',epsilon=0.0001)# write the REducelronplateau code here\n",
    "callbacks_list = [checkpoint, LR]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = generator(train_path, train_doc, batch_size,validation=True) # validation=True just prevents the augmentation of data\n",
    "val_generator = generator(val_path, val_doc, batch_size, validation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (num_train_sequences%batch_size) == 0:\n",
    "    steps_per_epoch = int(num_train_sequences/batch_size)\n",
    "else:\n",
    "    steps_per_epoch = (num_train_sequences//batch_size) + 1\n",
    "\n",
    "if (num_val_sequences%batch_size) == 0:\n",
    "    validation_steps = int(num_val_sequences/batch_size)\n",
    "else:\n",
    "    validation_steps = (num_val_sequences//batch_size) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source path = Source path =  Project_data/train ; batch size = 10\n",
      "Epoch 1/10\n",
      " Project_data/val ; batch size = 10\n",
      "67/67 [==============================] - 193s 3s/step - loss: 1.3517 - categorical_accuracy: 0.4204 - val_loss: 1.2241 - val_categorical_accuracy: 0.5100\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.22408, saving model to model_init_lstm_2020-11-0811_02_37.269104/model-00001-1.35592-0.41780-1.22408-0.51000.h5\n",
      "Epoch 2/10\n",
      "67/67 [==============================] - 47s 699ms/step - loss: 1.2850 - categorical_accuracy: 0.4925 - val_loss: 1.4767 - val_categorical_accuracy: 0.4600\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 1.22408\n",
      "Epoch 3/10\n",
      "67/67 [==============================] - 47s 708ms/step - loss: 1.3040 - categorical_accuracy: 0.5025 - val_loss: 1.4456 - val_categorical_accuracy: 0.4200\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1.22408\n",
      "Epoch 4/10\n",
      "67/67 [==============================] - 45s 670ms/step - loss: 1.2247 - categorical_accuracy: 0.5224 - val_loss: 1.3635 - val_categorical_accuracy: 0.4600\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.22408\n",
      "Epoch 5/10\n",
      "67/67 [==============================] - 50s 747ms/step - loss: 1.1117 - categorical_accuracy: 0.5572 - val_loss: 1.0545 - val_categorical_accuracy: 0.6000\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.22408 to 1.05451, saving model to model_init_lstm_2020-11-0811_02_37.269104/model-00005-1.11169-0.55721-1.05451-0.60000.h5\n",
      "Epoch 6/10\n",
      "67/67 [==============================] - 46s 693ms/step - loss: 1.1221 - categorical_accuracy: 0.5871 - val_loss: 1.1117 - val_categorical_accuracy: 0.5900\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.05451\n",
      "Epoch 7/10\n",
      "67/67 [==============================] - 45s 665ms/step - loss: 1.1671 - categorical_accuracy: 0.5572 - val_loss: 1.3191 - val_categorical_accuracy: 0.4600\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1.05451\n",
      "Epoch 8/10\n",
      "67/67 [==============================] - 48s 715ms/step - loss: 1.0908 - categorical_accuracy: 0.5622 - val_loss: 1.9565 - val_categorical_accuracy: 0.3300\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1.05451\n",
      "Epoch 9/10\n",
      "67/67 [==============================] - 59s 875ms/step - loss: 1.1899 - categorical_accuracy: 0.5522 - val_loss: 2.0965 - val_categorical_accuracy: 0.2400\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 1.05451\n",
      "Epoch 10/10\n",
      "67/67 [==============================] - 40s 600ms/step - loss: 1.1772 - categorical_accuracy: 0.5821 - val_loss: 1.6759 - val_categorical_accuracy: 0.3800\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 1.05451\n",
      "\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 1.0000000474974512e-06.\n"
     ]
    }
   ],
   "source": [
    "model_history = model.fit_generator(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
    "                  callbacks=callbacks_list, validation_data=val_generator, \n",
    "                  validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot(model_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'a' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-3f786850e387>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0ma\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'a' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 1.b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We augment the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write your model here\n",
    "model = Sequential()\n",
    "# add multiple convulation layers\n",
    "model.add(TimeDistributed(Conv2D(feature_map[0], (3, 3), strides=(2, 2),activation='relu', padding='same'), input_shape=input_shape))\n",
    "\n",
    "model.add(TimeDistributed(Conv2D(feature_map[1], (3,3),padding='same', activation='relu')))\n",
    "model.add(TimeDistributed(MaxPooling2D((2, 2), strides=(2, 2))))\n",
    "\n",
    "model.add(TimeDistributed(Conv2D(feature_map[2], (3,3),padding='same', activation='relu')))\n",
    "model.add(TimeDistributed(MaxPooling2D((2, 2), strides=(2, 2))))\n",
    "\n",
    "model.add(TimeDistributed(Conv2D(feature_map[3], (2,2),padding='same', activation='relu')))\n",
    "model.add(TimeDistributed(MaxPooling2D((2, 2), strides=(2, 2))))\n",
    "\n",
    "\n",
    "model.add(TimeDistributed(BatchNormalization()))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(TimeDistributed(Flatten()))\n",
    "\n",
    "model.add(Dense(dense_layer_size[0], activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(dense_layer_size[1], activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "## using LSTM as the RNN model along with softmax as our last layer.\n",
    "model.add(LSTM(128, return_sequences=False))\n",
    "model.add(Dense(classes, activation='softmax')) # using Softmax as last layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "print (model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# timestamp to use in model name. \n",
    "curr_dt_time = datetime.datetime.now()\n",
    "\n",
    "model_name = 'model_init_lstm' + '_' + str(curr_dt_time).replace(' ','').replace(':','_') + '/'\n",
    "    \n",
    "if not os.path.exists(model_name):\n",
    "    os.mkdir(model_name)\n",
    "        \n",
    "filepath = model_name + 'model-{epoch:05d}-{loss:.5f}-{categorical_accuracy:.5f}-{val_loss:.5f}-{val_categorical_accuracy:.5f}.h5'\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath, save_best_only=True, monitor='val_loss', verbose=1, save_weights_only=False, mode='auto', period=1)\n",
    "\n",
    "LR = ReduceLROnPlateau(monitor='val_loss', factor=0.001, patience=5, cooldown=4, verbose=1,mode='auto',epsilon=0.0001)# write the REducelronplateau code here\n",
    "callbacks_list = [checkpoint, LR]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = generator(train_path, train_doc, batch_size)\n",
    "val_generator = generator(val_path, val_doc, batch_size, validation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (num_train_sequences%batch_size) == 0:\n",
    "    steps_per_epoch = int(num_train_sequences/batch_size)\n",
    "else:\n",
    "    steps_per_epoch = (num_train_sequences//batch_size) + 1\n",
    "\n",
    "if (num_val_sequences%batch_size) == 0:\n",
    "    validation_steps = int(num_val_sequences/batch_size)\n",
    "else:\n",
    "    validation_steps = (num_val_sequences//batch_size) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_history = model.fit_generator(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
    "                  callbacks=callbacks_list, validation_data=val_generator, \n",
    "                  validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(model_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We add batch normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_map=[8, 16, 32, 64, 128] # we will expirment with different number of features for different layers\n",
    "dense_layer_size = [1000,500,5]\n",
    "num_epochs = 10\n",
    "batch_size = 10\n",
    "input_shape = (frames, rows, cols, channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write your model here\n",
    "model = Sequential()\n",
    "# add multiple convulation layers\n",
    "model.add(TimeDistributed(Conv2D(feature_map[0], (3, 3), strides=(2, 2),activation='relu', padding='same'), input_shape=input_shape))\n",
    "\n",
    "model.add(TimeDistributed(Conv2D(feature_map[1], (3,3),padding='same', activation='relu')))\n",
    "model.add(TimeDistributed(MaxPooling2D((2, 2), strides=(2, 2))))\n",
    "model.add(TimeDistributed(BatchNormalization()))\n",
    "\n",
    "\n",
    "model.add(TimeDistributed(Conv2D(feature_map[2], (3,3),padding='same', activation='relu')))\n",
    "model.add(TimeDistributed(MaxPooling2D((2, 2), strides=(2, 2))))\n",
    "model.add(TimeDistributed(BatchNormalization()))\n",
    "\n",
    "model.add(TimeDistributed(Conv2D(feature_map[3], (2,2),padding='same', activation='relu')))\n",
    "model.add(TimeDistributed(MaxPooling2D((2, 2), strides=(2, 2))))\n",
    "\n",
    "\n",
    "model.add(TimeDistributed(BatchNormalization()))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(TimeDistributed(Flatten()))\n",
    "\n",
    "model.add(Dense(dense_layer_size[0], activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(dense_layer_size[1], activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "## using LSTM as the RNN model along with softmax as our last layer.\n",
    "model.add(LSTM(128, return_sequences=False))\n",
    "model.add(Dense(classes, activation='softmax')) # using Softmax as last layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "print (model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# timestamp to use in model name. \n",
    "curr_dt_time = datetime.datetime.now()\n",
    "\n",
    "model_name = 'model_init_lstm' + '_' + str(curr_dt_time).replace(' ','').replace(':','_') + '/'\n",
    "    \n",
    "if not os.path.exists(model_name):\n",
    "    os.mkdir(model_name)\n",
    "        \n",
    "filepath = model_name + 'model-{epoch:05d}-{loss:.5f}-{categorical_accuracy:.5f}-{val_loss:.5f}-{val_categorical_accuracy:.5f}.h5'\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath, save_best_only=True, monitor='val_loss', verbose=1, save_weights_only=False, mode='auto', period=1)\n",
    "\n",
    "LR = ReduceLROnPlateau(monitor='val_loss', factor=0.001, patience=5, cooldown=4, verbose=1,mode='auto',epsilon=0.0001)# write the REducelronplateau code here\n",
    "callbacks_list = [checkpoint, LR]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (num_train_sequences%batch_size) == 0:\n",
    "    steps_per_epoch = int(num_train_sequences/batch_size)\n",
    "else:\n",
    "    steps_per_epoch = (num_train_sequences//batch_size) + 1\n",
    "\n",
    "if (num_val_sequences%batch_size) == 0:\n",
    "    validation_steps = int(num_val_sequences/batch_size)\n",
    "else:\n",
    "    validation_steps = (num_val_sequences//batch_size) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = generator(train_path, train_doc, batch_size)\n",
    "val_generator = generator(val_path, val_doc, batch_size, validation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_history = model.fit_generator(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
    "                  callbacks=callbacks_list, validation_data=val_generator, \n",
    "                  validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(model_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We reduce the dense layer neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_map=[8, 16, 32, 64, 128] \n",
    "dense_layer_size = [256,128,5] # we reduce the dense layer neurons\n",
    "num_epochs = 10\n",
    "batch_size = 10\n",
    "input_shape = (frames, rows, cols, channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = Sequential()\n",
    "# add multiple convulation layers\n",
    "model.add(TimeDistributed(Conv2D(feature_map[0], (3, 3), strides=(2, 2),activation='relu', padding='same'), input_shape=input_shape))\n",
    "\n",
    "model.add(TimeDistributed(Conv2D(feature_map[1], (3,3),padding='same', activation='relu')))\n",
    "model.add(TimeDistributed(MaxPooling2D((2, 2), strides=(2, 2))))\n",
    "model.add(TimeDistributed(BatchNormalization()))\n",
    "\n",
    "# model.add(keras.layers.Dropout(0.4))\n",
    "\n",
    "model.add(TimeDistributed(Conv2D(feature_map[2], (3,3),padding='same', activation='relu')))\n",
    "model.add(TimeDistributed(MaxPooling2D((2, 2), strides=(2, 2))))\n",
    "# model.add(keras.layers.Dropout(0.4))\n",
    "model.add(TimeDistributed(BatchNormalization()))\n",
    "\n",
    "model.add(TimeDistributed(Conv2D(feature_map[3], (2,2),padding='same', activation='relu')))\n",
    "model.add(TimeDistributed(MaxPooling2D((2, 2), strides=(2, 2))))\n",
    "\n",
    "\n",
    "model.add(TimeDistributed(BatchNormalization()))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(TimeDistributed(Flatten()))\n",
    "\n",
    "model.add(Dense(dense_layer_size[0], activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(dense_layer_size[1], activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "## using LSTM as the RNN model along with softmax as our last layer.\n",
    "model.add(LSTM(128, return_sequences=False))\n",
    "model.add(Dense(classes, activation='softmax')) # using Softmax as last layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "print (model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# timestamp to use in model name. \n",
    "curr_dt_time = datetime.datetime.now()\n",
    "\n",
    "model_name = 'model_init_lstm' + '_' + str(curr_dt_time).replace(' ','').replace(':','_') + '/'\n",
    "    \n",
    "if not os.path.exists(model_name):\n",
    "    os.mkdir(model_name)\n",
    "        \n",
    "filepath = model_name + 'model-{epoch:05d}-{loss:.5f}-{categorical_accuracy:.5f}-{val_loss:.5f}-{val_categorical_accuracy:.5f}.h5'\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath, save_best_only=True, monitor='val_loss', verbose=1, save_weights_only=False, mode='auto', period=1)\n",
    "\n",
    "LR = ReduceLROnPlateau(monitor='val_loss', factor=0.001, patience=5, cooldown=4, verbose=1,mode='auto',epsilon=0.0001)# write the REducelronplateau code here\n",
    "callbacks_list = [checkpoint, LR]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (num_train_sequences%batch_size) == 0:\n",
    "    steps_per_epoch = int(num_train_sequences/batch_size)\n",
    "else:\n",
    "    steps_per_epoch = (num_train_sequences//batch_size) + 1\n",
    "\n",
    "if (num_val_sequences%batch_size) == 0:\n",
    "    validation_steps = int(num_val_sequences/batch_size)\n",
    "else:\n",
    "    validation_steps = (num_val_sequences//batch_size) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = generator(train_path, train_doc, batch_size)\n",
    "val_generator = generator(val_path, val_doc, batch_size, validation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_history = model.fit_generator(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
    "                  callbacks=callbacks_list, validation_data=val_generator, \n",
    "                  validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(model_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We increase learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_map=[8, 16, 32, 64, 128] \n",
    "dense_layer_size = [256,128,5] # we reduce the dense layer neurons\n",
    "num_epochs = 10\n",
    "batch_size = 10\n",
    "input_shape = (frames, rows, cols, channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = Sequential()\n",
    "# add multiple convulation layers\n",
    "model.add(TimeDistributed(Conv2D(feature_map[0], (3, 3), strides=(2, 2),activation='relu', padding='same'), input_shape=input_shape))\n",
    "\n",
    "model.add(TimeDistributed(Conv2D(feature_map[1], (3,3),padding='same', activation='relu')))\n",
    "model.add(TimeDistributed(MaxPooling2D((2, 2), strides=(2, 2))))\n",
    "model.add(TimeDistributed(BatchNormalization()))\n",
    "\n",
    "model.add(TimeDistributed(Conv2D(feature_map[2], (3,3),padding='same', activation='relu')))\n",
    "model.add(TimeDistributed(MaxPooling2D((2, 2), strides=(2, 2))))\n",
    "model.add(TimeDistributed(BatchNormalization()))\n",
    "\n",
    "model.add(TimeDistributed(Conv2D(feature_map[3], (2,2),padding='same', activation='relu')))\n",
    "model.add(TimeDistributed(MaxPooling2D((2, 2), strides=(2, 2))))\n",
    "\n",
    "\n",
    "model.add(TimeDistributed(BatchNormalization()))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(TimeDistributed(Flatten()))\n",
    "\n",
    "model.add(Dense(dense_layer_size[0], activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(dense_layer_size[1], activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "## using LSTM as the RNN model along with softmax as our last layer.\n",
    "model.add(LSTM(128, return_sequences=False))\n",
    "model.add(Dense(classes, activation='softmax')) # using Softmax as last layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "print (model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# timestamp to use in model name. \n",
    "curr_dt_time = datetime.datetime.now()\n",
    "\n",
    "model_name = 'model_init_lstm' + '_' + str(curr_dt_time).replace(' ','').replace(':','_') + '/'\n",
    "    \n",
    "if not os.path.exists(model_name):\n",
    "    os.mkdir(model_name)\n",
    "        \n",
    "filepath = model_name + 'model-{epoch:05d}-{loss:.5f}-{categorical_accuracy:.5f}-{val_loss:.5f}-{val_categorical_accuracy:.5f}.h5'\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath, save_best_only=True, monitor='val_loss', verbose=1, save_weights_only=False, mode='auto', period=1)\n",
    "\n",
    "LR = ReduceLROnPlateau(monitor='val_loss', factor=0.001, patience=5, cooldown=4, verbose=1,mode='auto',epsilon=0.0001)# write the REducelronplateau code here\n",
    "callbacks_list = [checkpoint, LR]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (num_train_sequences%batch_size) == 0:\n",
    "    steps_per_epoch = int(num_train_sequences/batch_size)\n",
    "else:\n",
    "    steps_per_epoch = (num_train_sequences//batch_size) + 1\n",
    "\n",
    "if (num_val_sequences%batch_size) == 0:\n",
    "    validation_steps = int(num_val_sequences/batch_size)\n",
    "else:\n",
    "    validation_steps = (num_val_sequences//batch_size) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = generator(train_path, train_doc, batch_size)\n",
    "val_generator = generator(val_path, val_doc, batch_size, validation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_history = model.fit_generator(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
    "                  callbacks=callbacks_list, validation_data=val_generator, \n",
    "                  validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(model_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GRU MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 4564,
     "status": "ok",
     "timestamp": 1604436128129,
     "user": {
      "displayName": "Amit Chawla",
      "photoUrl": "",
      "userId": "06080236380106251748"
     },
     "user_tz": -330
    },
    "id": "-Tlfx79bmxfR"
   },
   "outputs": [],
   "source": [
    "#write your model here\n",
    "feature_map=[8, 16, 32, 64, 128, 256] # we will expirment with different number of features for different layers\n",
    "dense_layer_size = [1000,500,5] # \n",
    "classes= 5\n",
    "input_shape = (frames, rows, cols, channels)\n",
    "model = Sequential()\n",
    "# add multiple convulation layers\n",
    "model.add(TimeDistributed(Conv2D(feature_map[0], (3, 3), strides=(2, 2),activation='relu', padding='same'), input_shape=input_shape))\n",
    "\n",
    "model.add(TimeDistributed(Conv2D(feature_map[1], (3,3),padding='same', activation='relu')))\n",
    "model.add(TimeDistributed(MaxPooling2D((2, 2), strides=(2, 2))))\n",
    "model.add(TimeDistributed(BatchNormalization()))\n",
    "\n",
    "model.add(TimeDistributed(Conv2D(feature_map[2], (3,3),padding='same', activation='relu')))\n",
    "model.add(TimeDistributed(MaxPooling2D((2, 2), strides=(2, 2))))\n",
    "model.add(TimeDistributed(BatchNormalization()))\n",
    "\n",
    "model.add(TimeDistributed(Conv2D(feature_map[3], (2,2),padding='same', activation='relu')))\n",
    "model.add(TimeDistributed(MaxPooling2D((2, 2), strides=(2, 2))))\n",
    "model.add(TimeDistributed(BatchNormalization()))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(TimeDistributed(Conv2D(feature_map[4], (2,2),padding='same', activation='relu')))\n",
    "model.add(TimeDistributed(MaxPooling2D((2, 2), strides=(2, 2))))\n",
    "model.add(TimeDistributed(BatchNormalization()))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(TimeDistributed(Flatten()))\n",
    "\n",
    "model.add(Dense(dense_layer_size[0], activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(dense_layer_size[1], activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "## using GRU as the RNN model along with softmax as our last layer.\n",
    "model.add(GRU(128, return_sequences=False))\n",
    "model.add(Dense(classes, activation='softmax')) # using Softmax as last layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jKpo5LkKmxfT"
   },
   "source": [
    "Now that you have written the model, the next step is to `compile` the model. When you print the `summary` of the model, you'll see the total number of parameters you have to train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4560,
     "status": "ok",
     "timestamp": 1604436128130,
     "user": {
      "displayName": "Amit Chawla",
      "photoUrl": "",
      "userId": "06080236380106251748"
     },
     "user_tz": -330
    },
    "id": "NaRv2AivmxfU",
    "outputId": "44e90e46-23c6-4207-8810-a0dfbff59b37",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "optimiser = optimizers.Adam(0.001) #write your optimizer\n",
    "model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "print (model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MqlBfwFtmxfW"
   },
   "source": [
    "Let us create the `train_generator` and the `val_generator` which will be used in `.fit_generator`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 4551,
     "status": "ok",
     "timestamp": 1604436128132,
     "user": {
      "displayName": "Amit Chawla",
      "photoUrl": "",
      "userId": "06080236380106251748"
     },
     "user_tz": -330
    },
    "id": "c45IEYaZmxfX"
   },
   "outputs": [],
   "source": [
    "train_generator = generator(train_path, train_doc, batch_size)\n",
    "val_generator = generator(val_path, val_doc, batch_size, validation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4544,
     "status": "ok",
     "timestamp": 1604436128132,
     "user": {
      "displayName": "Amit Chawla",
      "photoUrl": "",
      "userId": "06080236380106251748"
     },
     "user_tz": -330
    },
    "id": "c6E-9uGqmxfZ",
    "outputId": "59d5557a-1311-4c21-ec60-8e3a5b71cadb"
   },
   "outputs": [],
   "source": [
    "model_name = 'model_init_CNN' + '_' + str(curr_dt_time).replace(' ','').replace(':','_') + '/'\n",
    "    \n",
    "if not os.path.exists(model_name):\n",
    "    os.mkdir(model_name)\n",
    "        \n",
    "filepath = model_name + 'model-{epoch:05d}-{loss:.5f}-{categorical_accuracy:.5f}-{val_loss:.5f}-{val_categorical_accuracy:.5f}.h5'\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath, save_best_only=True, monitor='val_loss', verbose=1, save_weights_only=False, mode='auto', period=1)\n",
    "\n",
    "LR = ReduceLROnPlateau(monitor='val_loss', factor=0.001, patience=5, cooldown=4, verbose=1,mode='auto',epsilon=0.0001)# write the REducelronplateau code here\n",
    "callbacks_list = [checkpoint, LR]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hErw7p94mxfb"
   },
   "source": [
    "The `steps_per_epoch` and `validation_steps` are used by `fit_generator` to decide the number of next() calls it need to make."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 4538,
     "status": "ok",
     "timestamp": 1604436128133,
     "user": {
      "displayName": "Amit Chawla",
      "photoUrl": "",
      "userId": "06080236380106251748"
     },
     "user_tz": -330
    },
    "id": "iCuo6cpBmxfc"
   },
   "outputs": [],
   "source": [
    "if (num_train_sequences%batch_size) == 0:\n",
    "    steps_per_epoch = int(num_train_sequences/batch_size)\n",
    "else:\n",
    "    steps_per_epoch = (num_train_sequences//batch_size) + 1\n",
    "\n",
    "if (num_val_sequences%batch_size) == 0:\n",
    "    validation_steps = int(num_val_sequences/batch_size)\n",
    "else:\n",
    "    validation_steps = (num_val_sequences//batch_size) + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xj_F8IVMmxff"
   },
   "source": [
    "Let us now fit the model. This will start training the model and with the help of the checkpoints, you'll be able to save the model at the end of each epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QYF2SSQtmxfh",
    "outputId": "5e024d26-ac4d-4614-a8c8-a8477b53f1b7"
   },
   "outputs": [],
   "source": [
    "batch_size = 10\n",
    "num_epochs = 10\n",
    "model_history = model.fit_generator(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
    "                  callbacks=callbacks_list, validation_data=val_generator, \n",
    "                  validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(model_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing dropout layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write your model here\n",
    "feature_map=[8, 16, 32, 64, 128, 256] # we will expirment with different number of features for different layers\n",
    "dense_layer_size = [1000,500,5] # \n",
    "classes= 5\n",
    "input_shape = (frames, rows, cols, channels)\n",
    "model = Sequential()\n",
    "# add multiple convulation layers\n",
    "model.add(TimeDistributed(Conv2D(feature_map[0], (3, 3), strides=(2, 2),activation='relu', padding='same'), input_shape=input_shape))\n",
    "\n",
    "model.add(TimeDistributed(Conv2D(feature_map[1], (3,3),padding='same', activation='relu')))\n",
    "model.add(TimeDistributed(MaxPooling2D((2, 2), strides=(2, 2))))\n",
    "model.add(TimeDistributed(BatchNormalization()))\n",
    "\n",
    "model.add(TimeDistributed(Conv2D(feature_map[2], (3,3),padding='same', activation='relu')))\n",
    "model.add(TimeDistributed(MaxPooling2D((2, 2), strides=(2, 2))))\n",
    "model.add(TimeDistributed(BatchNormalization()))\n",
    "\n",
    "model.add(TimeDistributed(Conv2D(feature_map[3], (2,2),padding='same', activation='relu')))\n",
    "model.add(TimeDistributed(MaxPooling2D((2, 2), strides=(2, 2))))\n",
    "model.add(TimeDistributed(BatchNormalization()))\n",
    "\n",
    "model.add(TimeDistributed(Conv2D(feature_map[4], (2,2),padding='same', activation='relu')))\n",
    "model.add(TimeDistributed(MaxPooling2D((2, 2), strides=(2, 2))))\n",
    "model.add(TimeDistributed(BatchNormalization()))\n",
    "\n",
    "model.add(TimeDistributed(Flatten()))\n",
    "\n",
    "model.add(Dense(dense_layer_size[0], activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(dense_layer_size[1], activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "## using GRU as the RNN model along with softmax as our last layer.\n",
    "model.add(GRU(128, return_sequences=False))\n",
    "model.add(Dense(classes, activation='softmax')) # using Softmax as last layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimiser = optimizers.Adam(0.001) #write your optimizer\n",
    "model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "print (model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = generator(train_path, train_doc, batch_size)\n",
    "val_generator = generator(val_path, val_doc, batch_size, validation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'model_init_CNN' + '_' + str(curr_dt_time).replace(' ','').replace(':','_') + '/'\n",
    "    \n",
    "if not os.path.exists(model_name):\n",
    "    os.mkdir(model_name)\n",
    "        \n",
    "filepath = model_name + 'model-{epoch:05d}-{loss:.5f}-{categorical_accuracy:.5f}-{val_loss:.5f}-{val_categorical_accuracy:.5f}.h5'\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath, save_best_only=True, monitor='val_loss', verbose=1, save_weights_only=False, mode='auto', period=1)\n",
    "\n",
    "LR = ReduceLROnPlateau(monitor='val_loss', factor=0.001, patience=5, cooldown=4, verbose=1,mode='auto',epsilon=0.0001)# write the REducelronplateau code here\n",
    "callbacks_list = [checkpoint, LR]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (num_train_sequences%batch_size) == 0:\n",
    "    steps_per_epoch = int(num_train_sequences/batch_size)\n",
    "else:\n",
    "    steps_per_epoch = (num_train_sequences//batch_size) + 1\n",
    "\n",
    "if (num_val_sequences%batch_size) == 0:\n",
    "    validation_steps = int(num_val_sequences/batch_size)\n",
    "else:\n",
    "    validation_steps = (num_val_sequences//batch_size) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 10\n",
    "num_epochs = 20\n",
    "model_history = model.fit_generator(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
    "                  callbacks=callbacks_list, validation_data=val_generator, \n",
    "                  validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(model_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### change image size to 84X84"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write your model here\n",
    "feature_map=[8, 16, 32, 64, 128, 256] # we will expirment with different number of features for different layers\n",
    "dense_layer_size = [1000,500,5] # \n",
    "classes= 5\n",
    "rows = 84\n",
    "cols = 84\n",
    "\n",
    "input_shape = (frames, rows, cols, channels)\n",
    "\n",
    "model = Sequential()\n",
    "# add multiple convulation layers\n",
    "model.add(TimeDistributed(Conv2D(feature_map[0], (3, 3), strides=(2, 2),activation='relu', padding='same'), input_shape=input_shape))\n",
    "\n",
    "model.add(TimeDistributed(Conv2D(feature_map[1], (3,3),padding='same', activation='relu')))\n",
    "model.add(TimeDistributed(MaxPooling2D((2, 2), strides=(2, 2))))\n",
    "model.add(TimeDistributed(BatchNormalization()))\n",
    "\n",
    "model.add(TimeDistributed(Conv2D(feature_map[2], (3,3),padding='same', activation='relu')))\n",
    "model.add(TimeDistributed(MaxPooling2D((2, 2), strides=(2, 2))))\n",
    "model.add(TimeDistributed(BatchNormalization()))\n",
    "\n",
    "model.add(TimeDistributed(Conv2D(feature_map[3], (2,2),padding='same', activation='relu')))\n",
    "model.add(TimeDistributed(MaxPooling2D((2, 2), strides=(2, 2))))\n",
    "model.add(TimeDistributed(BatchNormalization()))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(TimeDistributed(Conv2D(feature_map[4], (2,2),padding='same', activation='relu')))\n",
    "model.add(TimeDistributed(MaxPooling2D((2, 2), strides=(2, 2))))\n",
    "model.add(TimeDistributed(BatchNormalization()))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(TimeDistributed(Flatten()))\n",
    "\n",
    "model.add(Dense(dense_layer_size[0], activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(dense_layer_size[1], activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "## using GRU as the RNN model along with softmax as our last layer.\n",
    "model.add(GRU(128, return_sequences=False))\n",
    "model.add(Dense(classes, activation='softmax')) # using Softmax as last layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimiser = optimizers.Adam(0.001) #write your optimizer\n",
    "model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "print (model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = generator(train_path, train_doc, batch_size)\n",
    "val_generator = generator(val_path, val_doc, batch_size, validation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'model_init_CNN' + '_' + str(curr_dt_time).replace(' ','').replace(':','_') + '/'\n",
    "    \n",
    "if not os.path.exists(model_name):\n",
    "    os.mkdir(model_name)\n",
    "        \n",
    "filepath = model_name + 'model-{epoch:05d}-{loss:.5f}-{categorical_accuracy:.5f}-{val_loss:.5f}-{val_categorical_accuracy:.5f}.h5'\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath, save_best_only=True, monitor='val_loss', verbose=1, save_weights_only=False, mode='auto', period=1)\n",
    "\n",
    "LR = ReduceLROnPlateau(monitor='val_loss', factor=0.001, patience=5, cooldown=4, verbose=1,mode='auto',epsilon=0.0001)# write the REducelronplateau code here\n",
    "callbacks_list = [checkpoint, LR]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (num_train_sequences%batch_size) == 0:\n",
    "    steps_per_epoch = int(num_train_sequences/batch_size)\n",
    "else:\n",
    "    steps_per_epoch = (num_train_sequences//batch_size) + 1\n",
    "\n",
    "if (num_val_sequences%batch_size) == 0:\n",
    "    validation_steps = int(num_val_sequences/batch_size)\n",
    "else:\n",
    "    validation_steps = (num_val_sequences//batch_size) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 10\n",
    "num_epochs = 20\n",
    "model_history = model.fit_generator(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
    "                  callbacks=callbacks_list, validation_data=val_generator, \n",
    "                  validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(model_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding one more dense layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # reset image size to 120*120\n",
    "rows = 120\n",
    "cols = 120"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write your model here\n",
    "feature_map=[8, 16, 32, 64, 128, 256] # we will expirment with different number of features for different layers\n",
    "dense_layer_size = [1000, 500, 250, 5] # \n",
    "classes= 5\n",
    "\n",
    "input_shape = (frames, rows, cols, channels)\n",
    "\n",
    "model = Sequential()\n",
    "# add multiple convulation layers\n",
    "model.add(TimeDistributed(Conv2D(feature_map[0], (3, 3), strides=(2, 2),activation='relu', padding='same'), input_shape=input_shape))\n",
    "\n",
    "model.add(TimeDistributed(Conv2D(feature_map[1], (3,3),padding='same', activation='relu')))\n",
    "model.add(TimeDistributed(MaxPooling2D((2, 2), strides=(2, 2))))\n",
    "model.add(TimeDistributed(BatchNormalization()))\n",
    "\n",
    "model.add(TimeDistributed(Conv2D(feature_map[2], (3,3),padding='same', activation='relu')))\n",
    "model.add(TimeDistributed(MaxPooling2D((2, 2), strides=(2, 2))))\n",
    "model.add(TimeDistributed(BatchNormalization()))\n",
    "\n",
    "model.add(TimeDistributed(Conv2D(feature_map[3], (2,2),padding='same', activation='relu')))\n",
    "model.add(TimeDistributed(MaxPooling2D((2, 2), strides=(2, 2))))\n",
    "model.add(TimeDistributed(BatchNormalization()))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(TimeDistributed(Conv2D(feature_map[4], (2,2),padding='same', activation='relu')))\n",
    "model.add(TimeDistributed(MaxPooling2D((2, 2), strides=(2, 2))))\n",
    "model.add(TimeDistributed(BatchNormalization()))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(TimeDistributed(Flatten()))\n",
    "\n",
    "model.add(Dense(dense_layer_size[0], activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(dense_layer_size[1], activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(dense_layer_size[2], activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "## using GRU as the RNN model along with softmax as our last layer.\n",
    "model.add(GRU(128, return_sequences=False))\n",
    "model.add(Dense(classes, activation='softmax')) # using Softmax as last layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimiser = optimizers.Adam(0.001) #write your optimizer\n",
    "model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "print (model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = generator(train_path, train_doc, batch_size)\n",
    "val_generator = generator(val_path, val_doc, batch_size, validation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'model_init_CNN' + '_' + str(curr_dt_time).replace(' ','').replace(':','_') + '/'\n",
    "    \n",
    "if not os.path.exists(model_name):\n",
    "    os.mkdir(model_name)\n",
    "        \n",
    "filepath = model_name + 'model-{epoch:05d}-{loss:.5f}-{categorical_accuracy:.5f}-{val_loss:.5f}-{val_categorical_accuracy:.5f}.h5'\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath, save_best_only=True, monitor='val_loss', verbose=1, save_weights_only=False, mode='auto', period=1)\n",
    "\n",
    "LR = ReduceLROnPlateau(monitor='val_loss', factor=0.001, patience=5, cooldown=4, verbose=1,mode='auto',epsilon=0.0001)# write the REducelronplateau code here\n",
    "callbacks_list = [checkpoint, LR]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (num_train_sequences%batch_size) == 0:\n",
    "    steps_per_epoch = int(num_train_sequences/batch_size)\n",
    "else:\n",
    "    steps_per_epoch = (num_train_sequences//batch_size) + 1\n",
    "\n",
    "if (num_val_sequences%batch_size) == 0:\n",
    "    validation_steps = int(num_val_sequences/batch_size)\n",
    "else:\n",
    "    validation_steps = (num_val_sequences//batch_size) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 10\n",
    "num_epochs = 20\n",
    "model_history = model.fit_generator(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
    "                  callbacks=callbacks_list, validation_data=val_generator, \n",
    "                  validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(model_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0eCOFgTUmxfj"
   },
   "source": [
    "## Conv3D model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimiser SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filters = [8,16,32,64]\n",
    "dense = [256, 128, 5]\n",
    "\n",
    "# Input\n",
    "input_shape=(frames, rows, cols, channels)\n",
    "\n",
    "# Define model\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv3D(filters[0], \n",
    "                 kernel_size=(3,3,3), \n",
    "                 input_shape=input_shape,\n",
    "                 padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(MaxPooling3D(pool_size=(2,2,2)))\n",
    "\n",
    "model.add(Conv3D(filters[1], \n",
    "                 kernel_size=(3,3,3), \n",
    "                 padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(MaxPooling3D(pool_size=(2,2,2)))\n",
    "\n",
    "model.add(Conv3D(filters[2], \n",
    "                 kernel_size=(1,3,3), \n",
    "                 padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(MaxPooling3D(pool_size=(2,2,2)))\n",
    "\n",
    "model.add(Conv3D(filters[3], \n",
    "                 kernel_size=(1,3,3), \n",
    "                 padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(MaxPooling3D(pool_size=(2,2,2)))\n",
    "\n",
    "#Flatten Layers\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(dense[0], activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(dense[1], activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "#softmax layer\n",
    "model.add(Dense(dense[2], activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimiser = optimizers.SGD() #write your optimizer\n",
    "model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "print (model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = generator(train_path, train_doc, batch_size)\n",
    "val_generator = generator(val_path, val_doc, batch_size,validation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'model_init_Conv3D' + '_' + str(curr_dt_time).replace(' ','').replace(':','_') + '/'\n",
    "    \n",
    "if not os.path.exists(model_name):\n",
    "    os.mkdir(model_name)\n",
    "        \n",
    "filepath = model_name + 'model-{epoch:05d}-{loss:.5f}-{categorical_accuracy:.5f}-{val_loss:.5f}-{val_categorical_accuracy:.5f}.h5'\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath, save_best_only=True, monitor='val_loss', verbose=1, save_weights_only=False, mode='auto', period=1)\n",
    "\n",
    "# write the Reducelronplateau code here\n",
    "LR = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, cooldown=1, verbose=1)\n",
    "callbacks_list = [checkpoint, LR]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (num_train_sequences%batch_size) == 0:\n",
    "    steps_per_epoch = int(num_train_sequences/batch_size)\n",
    "else:\n",
    "    steps_per_epoch = (num_train_sequences//batch_size) + 1\n",
    "\n",
    "if (num_val_sequences%batch_size) == 0:\n",
    "    validation_steps = int(num_val_sequences/batch_size)\n",
    "else:\n",
    "    validation_steps = (num_val_sequences//batch_size) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 10\n",
    "num_epochs = 10\n",
    "model_history = model.fit_generator(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
    "                   callbacks=callbacks_list, validation_data=val_generator, \n",
    "                   validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(model_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Increased Epochs and Adam optimiser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y6zFhT4ugNe6"
   },
   "outputs": [],
   "source": [
    "filters = [8,16,32,64]\n",
    "dense = [256, 128, 5]\n",
    "\n",
    "# Input\n",
    "input_shape=(frames, rows, cols, channels)\n",
    "\n",
    "# Define model\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv3D(filters[0], \n",
    "                 kernel_size=(3,3,3), \n",
    "                 input_shape=input_shape,\n",
    "                 padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(MaxPooling3D(pool_size=(2,2,2)))\n",
    "\n",
    "model.add(Conv3D(filters[1], \n",
    "                 kernel_size=(3,3,3), \n",
    "                 padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(MaxPooling3D(pool_size=(2,2,2)))\n",
    "\n",
    "model.add(Conv3D(filters[2], \n",
    "                 kernel_size=(1,3,3), \n",
    "                 padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(MaxPooling3D(pool_size=(2,2,2)))\n",
    "\n",
    "model.add(Conv3D(filters[3], \n",
    "                 kernel_size=(1,3,3), \n",
    "                 padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(MaxPooling3D(pool_size=(2,2,2)))\n",
    "\n",
    "#Flatten Layers\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(dense[0], activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(dense[1], activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "#softmax layer\n",
    "model.add(Dense(dense[2], activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimiser = optimizers.Adam() #write your optimizer\n",
    "model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "print (model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = generator(train_path, train_doc, batch_size)\n",
    "val_generator = generator(val_path, val_doc, batch_size,validation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'model_init_Conv3D' + '_' + str(curr_dt_time).replace(' ','').replace(':','_') + '/'\n",
    "    \n",
    "if not os.path.exists(model_name):\n",
    "    os.mkdir(model_name)\n",
    "        \n",
    "filepath = model_name + 'model-{epoch:05d}-{loss:.5f}-{categorical_accuracy:.5f}-{val_loss:.5f}-{val_categorical_accuracy:.5f}.h5'\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath, save_best_only=True, monitor='val_loss', verbose=1, save_weights_only=False, mode='auto', period=1)\n",
    "\n",
    "# write the Reducelronplateau code here\n",
    "LR = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, cooldown=1, verbose=1)\n",
    "callbacks_list = [checkpoint, LR]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (num_train_sequences%batch_size) == 0:\n",
    "    steps_per_epoch = int(num_train_sequences/batch_size)\n",
    "else:\n",
    "    steps_per_epoch = (num_train_sequences//batch_size) + 1\n",
    "\n",
    "if (num_val_sequences%batch_size) == 0:\n",
    "    validation_steps = int(num_val_sequences/batch_size)\n",
    "else:\n",
    "    validation_steps = (num_val_sequences//batch_size) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 10\n",
    "num_epochs = 20\n",
    "model_history = model.fit_generator(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
    "                   callbacks=callbacks_list, validation_data=val_generator, \n",
    "                   validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(model_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Increasing dense perceptrons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes= 5\n",
    "input_shape = (frames, rows, cols, channels)\n",
    "\n",
    "nb_filters = [8,16,32,64]\n",
    "nb_dense = [1000, 500, 5]\n",
    "\n",
    "# Define model\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv3D(nb_filters[0], \n",
    "                 kernel_size=(3,3,3), \n",
    "                 input_shape=input_shape,\n",
    "                 padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(MaxPooling3D(pool_size=(2,2,2)))\n",
    "\n",
    "model.add(Conv3D(nb_filters[1], \n",
    "                 kernel_size=(3,3,3), \n",
    "                 padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(MaxPooling3D(pool_size=(2,2,2)))\n",
    "\n",
    "model.add(Conv3D(nb_filters[2], \n",
    "                 kernel_size=(1,3,3), \n",
    "                 padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(MaxPooling3D(pool_size=(2,2,2)))\n",
    "\n",
    "model.add(Conv3D(nb_filters[3], \n",
    "                 kernel_size=(1,3,3), \n",
    "                 padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(MaxPooling3D(pool_size=(2,2,2)))\n",
    "\n",
    "#Flatten Layers\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(nb_dense[0], activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(nb_dense[1], activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "#softmax layer\n",
    "model.add(Dense(nb_dense[2], activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimiser = optimizers.Adam() #write your optimizer\n",
    "model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "print (model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = generator(train_path, train_doc, batch_size)\n",
    "val_generator = generator(val_path, val_doc, batch_size,validation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'model_init_Conv3D' + '_' + str(curr_dt_time).replace(' ','').replace(':','_') + '/'\n",
    "    \n",
    "if not os.path.exists(model_name):\n",
    "    os.mkdir(model_name)\n",
    "        \n",
    "filepath = model_name + 'model-{epoch:05d}-{loss:.5f}-{categorical_accuracy:.5f}-{val_loss:.5f}-{val_categorical_accuracy:.5f}.h5'\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath, save_best_only=True, monitor='val_loss', verbose=1, save_weights_only=False, mode='auto', period=1)\n",
    "\n",
    "# write the Reducelronplateau code here\n",
    "LR = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, cooldown=1, verbose=1)\n",
    "callbacks_list = [checkpoint, LR]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (num_train_sequences%batch_size) == 0:\n",
    "    steps_per_epoch = int(num_train_sequences/batch_size)\n",
    "else:\n",
    "    steps_per_epoch = (num_train_sequences//batch_size) + 1\n",
    "\n",
    "if (num_val_sequences%batch_size) == 0:\n",
    "    validation_steps = int(num_val_sequences/batch_size)\n",
    "else:\n",
    "    validation_steps = (num_val_sequences//batch_size) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 10\n",
    "num_epochs = 20\n",
    "model_history = model.fit_generator(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
    "                   callbacks=callbacks_list, validation_data=val_generator, \n",
    "                   validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(model_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding one extra layer with dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes= 5\n",
    "input_shape = (frames, rows, cols, channels)\n",
    "\n",
    "nb_filters = [8, 16, 32, 64, 128]\n",
    "nb_dense = [1000, 500, 5]\n",
    "\n",
    "# Define model\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv3D(nb_filters[0], \n",
    "                 kernel_size=(3,3,3), \n",
    "                 input_shape=input_shape,\n",
    "                 padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(MaxPooling3D(pool_size=(2,2,2)))\n",
    "\n",
    "model.add(Conv3D(nb_filters[1], \n",
    "                 kernel_size=(3,3,3), \n",
    "                 padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(MaxPooling3D(pool_size=(2,2,2)))\n",
    "\n",
    "model.add(Conv3D(nb_filters[2], \n",
    "                 kernel_size=(1,3,3), \n",
    "                 padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(MaxPooling3D(pool_size=(2,2,2)))\n",
    "\n",
    "model.add(Conv3D(nb_filters[3], \n",
    "                 kernel_size=(1,3,3), \n",
    "                 padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv3D(nb_filters[4], \n",
    "                 kernel_size=(1,3,3), \n",
    "                 padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(MaxPooling3D(pool_size=(2,2,2)))\n",
    "\n",
    "\n",
    "#Flatten Layers\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(nb_dense[0], activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(nb_dense[1], activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "#softmax layer\n",
    "model.add(Dense(nb_dense[2], activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimiser = optimizers.Adam() #write your optimizer\n",
    "model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "print (model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = generator(train_path, train_doc, batch_size)\n",
    "val_generator = generator(val_path, val_doc, batch_size,validation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'model_init_Conv3D' + '_' + str(curr_dt_time).replace(' ','').replace(':','_') + '/'\n",
    "    \n",
    "if not os.path.exists(model_name):\n",
    "    os.mkdir(model_name)\n",
    "        \n",
    "filepath = model_name + 'model-{epoch:05d}-{loss:.5f}-{categorical_accuracy:.5f}-{val_loss:.5f}-{val_categorical_accuracy:.5f}.h5'\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath, save_best_only=True, monitor='val_loss', verbose=1, save_weights_only=False, mode='auto', period=1)\n",
    "\n",
    "# write the Reducelronplateau code here\n",
    "LR = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, cooldown=1, verbose=1)\n",
    "callbacks_list = [checkpoint, LR]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (num_train_sequences%batch_size) == 0:\n",
    "    steps_per_epoch = int(num_train_sequences/batch_size)\n",
    "else:\n",
    "    steps_per_epoch = (num_train_sequences//batch_size) + 1\n",
    "\n",
    "if (num_val_sequences%batch_size) == 0:\n",
    "    validation_steps = int(num_val_sequences/batch_size)\n",
    "else:\n",
    "    validation_steps = (num_val_sequences//batch_size) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 10\n",
    "num_epochs = 20\n",
    "model_history = model.fit_generator(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
    "                   callbacks=callbacks_list, validation_data=val_generator, \n",
    "                   validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(model_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding one more layer with BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes= 5\n",
    "input_shape = (frames, rows, cols, channels)\n",
    "\n",
    "nb_filters = [8, 16, 32, 64, 128, 256]\n",
    "nb_dense = [1000, 500, 5]\n",
    "\n",
    "# Define model\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv3D(nb_filters[0], \n",
    "                 kernel_size=(3,3,3), \n",
    "                 input_shape=input_shape,\n",
    "                 padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(MaxPooling3D(pool_size=(2,2,2)))\n",
    "\n",
    "model.add(Conv3D(nb_filters[1], \n",
    "                 kernel_size=(3,3,3), \n",
    "                 padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(MaxPooling3D(pool_size=(2,2,2)))\n",
    "\n",
    "model.add(Conv3D(nb_filters[2], \n",
    "                 kernel_size=(1,3,3), \n",
    "                 padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Conv3D(nb_filters[3], \n",
    "                 kernel_size=(1,3,3), \n",
    "                 padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(MaxPooling3D(pool_size=(2,2,2)))\n",
    "\n",
    "model.add(Conv3D(nb_filters[4], \n",
    "                 kernel_size=(1,3,3), \n",
    "                 padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv3D(nb_filters[5], \n",
    "                 kernel_size=(1,3,3), \n",
    "                 padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(MaxPooling3D(pool_size=(2,2,2)))\n",
    "\n",
    "\n",
    "#Flatten Layers\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(nb_dense[0], activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(nb_dense[1], activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "#softmax layer\n",
    "model.add(Dense(nb_dense[2], activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimiser = optimizers.Adam() #write your optimizer\n",
    "model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "print (model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = generator(train_path, train_doc, batch_size)\n",
    "val_generator = generator(val_path, val_doc, batch_size,validation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'model_init_Conv3D' + '_' + str(curr_dt_time).replace(' ','').replace(':','_') + '/'\n",
    "    \n",
    "if not os.path.exists(model_name):\n",
    "    os.mkdir(model_name)\n",
    "        \n",
    "filepath = model_name + 'model-{epoch:05d}-{loss:.5f}-{categorical_accuracy:.5f}-{val_loss:.5f}-{val_categorical_accuracy:.5f}.h5'\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath, save_best_only=True, monitor='val_loss', verbose=1, save_weights_only=False, mode='auto', period=1)\n",
    "\n",
    "# write the Reducelronplateau code here\n",
    "LR = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, cooldown=1, verbose=1)\n",
    "callbacks_list = [checkpoint, LR]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (num_train_sequences%batch_size) == 0:\n",
    "    steps_per_epoch = int(num_train_sequences/batch_size)\n",
    "else:\n",
    "    steps_per_epoch = (num_train_sequences//batch_size) + 1\n",
    "\n",
    "if (num_val_sequences%batch_size) == 0:\n",
    "    validation_steps = int(num_val_sequences/batch_size)\n",
    "else:\n",
    "    validation_steps = (num_val_sequences//batch_size) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 10\n",
    "num_epochs = 20\n",
    "model_history = model.fit_generator(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
    "                   callbacks=callbacks_list, validation_data=val_generator, \n",
    "                   validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(model_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Neural_Nets_Project_Starter_Code.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
