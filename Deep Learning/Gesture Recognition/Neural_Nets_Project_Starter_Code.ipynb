{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VDqMakhdmxeZ"
   },
   "source": [
    "# Gesture Recognition\n",
    "In this group project, you are going to build a 3D Conv model that will be able to predict the 5 gestures correctly. Please import the following libraries to get started."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1264,
     "status": "ok",
     "timestamp": 1604436124652,
     "user": {
      "displayName": "Amit Chawla",
      "photoUrl": "",
      "userId": "06080236380106251748"
     },
     "user_tz": -330
    },
    "id": "BTT3MufZmxeZ",
    "outputId": "202516b5-292f-4a5e-faeb-b3e5f5bbdc16"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 1905,
     "status": "ok",
     "timestamp": 1604436125310,
     "user": {
      "displayName": "Amit Chawla",
      "photoUrl": "",
      "userId": "06080236380106251748"
     },
     "user_tz": -330
    },
    "id": "ObsTCqZGmxef"
   },
   "outputs": [],
   "source": [
    "# import os\n",
    "# os.environ['KAGGLE_CONFIG_DIR'] = \"/content/gdrive/My Drive/Colab Notebooks\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1893,
     "status": "ok",
     "timestamp": 1604436125311,
     "user": {
      "displayName": "Amit Chawla",
      "photoUrl": "",
      "userId": "06080236380106251748"
     },
     "user_tz": -330
    },
    "id": "5uHfxQ0amxeh",
    "outputId": "0263a77f-532a-4474-8514-fb75cc4c17fb"
   },
   "outputs": [],
   "source": [
    "# %cd /content/gdrive/My Drive/Colab Notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 3407,
     "status": "ok",
     "timestamp": 1604436126836,
     "user": {
      "displayName": "Amit Chawla",
      "photoUrl": "",
      "userId": "06080236380106251748"
     },
     "user_tz": -330
    },
    "id": "TQBPqv4tmxek"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# import libraries\n",
    "import numpy as np\n",
    "import os\n",
    "import datetime\n",
    "import os\n",
    "import keras\n",
    "from skimage import io\n",
    "from skimage.transform import rescale, resize\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter \n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tGWWjZmWmxem"
   },
   "source": [
    "We set the random seed so that the results don't vary drastically."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uIgjhwHP1K4S"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 3405,
     "status": "ok",
     "timestamp": 1604436126840,
     "user": {
      "displayName": "Amit Chawla",
      "photoUrl": "",
      "userId": "06080236380106251748"
     },
     "user_tz": -330
    },
    "id": "WMQ8D_b7mxen"
   },
   "outputs": [],
   "source": [
    "np.random.seed(30)\n",
    "import random as rn\n",
    "rn.seed(30) #disabled for experimenting\n",
    "from keras import backend as K\n",
    "import tensorflow as tf\n",
    "tf.set_random_seed(30)\n",
    "# tf.random.set_seed(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ElbM_EOhmxep"
   },
   "source": [
    "In this block, you read the folder names for training and validation. You also set the `batch_size` here. Note that you set the batch size in such a way that you are able to use the GPU in full capacity. You keep increasing the batch size until the machine throws an error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 3398,
     "status": "ok",
     "timestamp": 1604436126840,
     "user": {
      "displayName": "Amit Chawla",
      "photoUrl": "",
      "userId": "06080236380106251748"
     },
     "user_tz": -330
    },
    "id": "Ktl51Bgjmxeq"
   },
   "outputs": [],
   "source": [
    "train_doc = np.random.permutation(open('Project_data/train.csv').readlines())\n",
    "val_doc = np.random.permutation(open('Project_data/val.csv').readlines())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 3392,
     "status": "ok",
     "timestamp": 1604436126841,
     "user": {
      "displayName": "Amit Chawla",
      "photoUrl": "",
      "userId": "06080236380106251748"
     },
     "user_tz": -330
    },
    "id": "iXpH5G_Zmxes"
   },
   "outputs": [],
   "source": [
    "# we started with batch size = 663 and slowly optimised it to fit into our resources \n",
    "batch_size = 30 #experiment with the batch size\n",
    "frames = 30 #number of frames in each video \n",
    "# we start with 120*120 images and adjust these later for model building process\n",
    "rows = 120 # final image height to be decided\n",
    "cols = 120 # final image width to be decided\n",
    "channels = 3\n",
    "step_size = 1 #this will help in customising the frames chosen from the video for model building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 3381,
     "status": "ok",
     "timestamp": 1604436126841,
     "user": {
      "displayName": "Amit Chawla",
      "photoUrl": "",
      "userId": "06080236380106251748"
     },
     "user_tz": -330
    },
    "id": "13E1RyUxmxew"
   },
   "outputs": [],
   "source": [
    "# we distribute the images on the basis of size. This is just done for experiment puroposes later.\n",
    "# outpaths = [train_path] #val_path\n",
    "def image_segregation(path='train'):\n",
    "    final_120 =[]\n",
    "    final_360=[]\n",
    "    doc = ''\n",
    "    if(path=='train'):\n",
    "        op = 'Project_data/train/'\n",
    "        doc = train_doc\n",
    "    else:\n",
    "        op = 'Project_data/val/'\n",
    "        doc = val_doc\n",
    "    for f in doc:\n",
    "        path = f.split(';')[0]\n",
    "        imgs = os.listdir(op+path)\n",
    "        for img in imgs:\n",
    "            image = io.imread(op+path+'/'+img)\n",
    "            if(image.shape[0]==360):\n",
    "                final_120.append(op+path+'/'+img) \n",
    "\n",
    "            if(image.shape[0]==120):\n",
    "                final_360.append(op+path+'/'+img)\n",
    "    return (final_120, final_360)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 3376,
     "status": "ok",
     "timestamp": 1604436126842,
     "user": {
      "displayName": "Amit Chawla",
      "photoUrl": "",
      "userId": "06080236380106251748"
     },
     "user_tz": -330
    },
    "id": "HXYE041rmxey"
   },
   "outputs": [],
   "source": [
    "# make list of images with corresponding sizes\n",
    "# final_120, final_360 = image_segregation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 3370,
     "status": "ok",
     "timestamp": 1604436126842,
     "user": {
      "displayName": "Amit Chawla",
      "photoUrl": "",
      "userId": "06080236380106251748"
     },
     "user_tz": -330
    },
    "id": "wNbx3UeNmxe1"
   },
   "outputs": [],
   "source": [
    "# view random imagees\n",
    "#selectedIndexes  = []\n",
    "#for i in range(3):\n",
    "#    selectedIndexes.append(rn.randint(0,5520))\n",
    "\n",
    "\n",
    "#s_im_120 = [final_120[i] for i in selectedIndexes]\n",
    "#s_im_360 = [final_360[i] for i in selectedIndexes]\n",
    "#print(s_im_120)\n",
    "#print(s_im_360)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VwHEJ0ajmxe4"
   },
   "source": [
    "## Generator\n",
    "This is one of the most important part of the code. The overall structure of the generator has been given. In the generator, you are going to preprocess the images as you have images of 2 different dimensions as well as create a batch of video frames. You have to experiment with `img_idx`, `y`,`z` and normalization such that you get high accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 3362,
     "status": "ok",
     "timestamp": 1604436126842,
     "user": {
      "displayName": "Amit Chawla",
      "photoUrl": "",
      "userId": "06080236380106251748"
     },
     "user_tz": -330
    },
    "id": "bZVAwtRLmxe4"
   },
   "outputs": [],
   "source": [
    "# we have looked at random images from the set and decided the following dimensions for the images. This has helped to \n",
    "# remove the edges and preserve the center of the image where gesture data is present. \n",
    "def cropImage(image):\n",
    "    (image_h, image_w, _) = image.shape\n",
    "    print(image.shape)\n",
    "    h_start=0\n",
    "    h_end = image_h\n",
    "    w_start=0\n",
    "    w_end = image_w\n",
    "    # for images 120*160\n",
    "    if(image_h==120):\n",
    "        h_start=20\n",
    "        w_start=10\n",
    "        w_end = 120\n",
    "    # for images of size 360*360\n",
    "    elif image_h==360:\n",
    "        h_start=30\n",
    "        w_start=30\n",
    "        w_end = 320\n",
    "    return image[h_start:h_end, w_start:w_end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 3351,
     "status": "ok",
     "timestamp": 1604436126843,
     "user": {
      "displayName": "Amit Chawla",
      "photoUrl": "",
      "userId": "06080236380106251748"
     },
     "user_tz": -330
    },
    "id": "iPDq9Y_qmxe7"
   },
   "outputs": [],
   "source": [
    "# this method will adjust the size of the image to given dimensions. The appropriate size will be found through experments.\n",
    "def resize_image(image, height=rows, width=cols):\n",
    "    return  resize(image, (height, width),anti_aliasing=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "executionInfo": {
     "elapsed": 3344,
     "status": "ok",
     "timestamp": 1604436126844,
     "user": {
      "displayName": "Amit Chawla",
      "photoUrl": "",
      "userId": "06080236380106251748"
     },
     "user_tz": -330
    },
    "id": "VtA2DmeHmxe9"
   },
   "outputs": [],
   "source": [
    "# we try different normalization technique\n",
    "def normalize_image(image):\n",
    "    norm_image = image - np.min(image)/np.max(image) - np.min(image)\n",
    "#     norm_image = image - np.percentile(image,5)/ np.percentile(image,95) - np.percentile(image,5)\n",
    "    return norm_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "executionInfo": {
     "elapsed": 3334,
     "status": "ok",
     "timestamp": 1604436126844,
     "user": {
      "displayName": "Amit Chawla",
      "photoUrl": "",
      "userId": "06080236380106251748"
     },
     "user_tz": -330
    },
    "id": "qZT62WCDmxfA"
   },
   "outputs": [],
   "source": [
    "#utility to show processed images\n",
    "def showImage(array, idx):\n",
    "    a = array[idx]\n",
    "    image = io.imread(a)\n",
    "    plt.subplot(2, 2,1)\n",
    "    plt.imshow(image)\n",
    "\n",
    "    cropped = cropImage(image)\n",
    "    plt.subplot(2,2,2)\n",
    "    plt.imshow(cropped)\n",
    "\n",
    "    resized = resize_image(cropped)\n",
    "    plt.subplot(2, 2,3)\n",
    "    plt.imshow(resized)\n",
    "\n",
    "    \n",
    "    normalized = normalize_image(resized)\n",
    "    plt.subplot(2, 2,4)\n",
    "    plt.imshow(normalized)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "executionInfo": {
     "elapsed": 3327,
     "status": "ok",
     "timestamp": 1604436126845,
     "user": {
      "displayName": "Amit Chawla",
      "photoUrl": "",
      "userId": "06080236380106251748"
     },
     "user_tz": -330
    },
    "id": "K7tnO7qMmxfE"
   },
   "outputs": [],
   "source": [
    "#plt.figure(figsize=(300,300))\n",
    "#showImage(s_im_360, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "executionInfo": {
     "elapsed": 3320,
     "status": "ok",
     "timestamp": 1604436126845,
     "user": {
      "displayName": "Amit Chawla",
      "photoUrl": "",
      "userId": "06080236380106251748"
     },
     "user_tz": -330
    },
    "id": "BsJO0HlMmxfG"
   },
   "outputs": [],
   "source": [
    "# view random images\n",
    "#plt.figure(figsize=(300,300))\n",
    "#showImage(s_im_120, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to generate a random affine transform on the iamge\n",
    "def get_random_affine():\n",
    "    dx, dy = np.random.randint(-1.7, 1.8, 2)\n",
    "    M = np.float32([[1, 0, dx], [0, 1, dy]])\n",
    "    return M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to initialize all the batch image data and labels\n",
    "def init_batch_data(batch_size):\n",
    "    batch_data = np.zeros((batch_size, frames, rows, cols, channels)) \n",
    "    batch_labels = np.zeros((batch_size,5)) # batch_labels is the one hot representation of the output\n",
    "    return batch_data, batch_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "executionInfo": {
     "elapsed": 3313,
     "status": "ok",
     "timestamp": 1604436126846,
     "user": {
      "displayName": "Amit Chawla",
      "photoUrl": "",
      "userId": "06080236380106251748"
     },
     "user_tz": -330
    },
    "id": "d6X9RiBtmSxp"
   },
   "outputs": [],
   "source": [
    "# internal function to generate augmented data. \n",
    "# We have done 2 types of augmentation to prevent overfitting of data- flipping of the images and affine transformation. \n",
    "def fetch_aug_batchdata(source_path, folder_list, batch_num, batch_size, t,validation):\n",
    "    \n",
    "    batch_data,batch_labels = init_batch_data(batch_size)\n",
    "    \n",
    "    # We will also build an augumented batch data with affine transformation\n",
    "    batch_data_aug,batch_labels_aug = init_batch_data(batch_size)\n",
    "    \n",
    "    # We will also build an augmented batch data with horizontal flip\n",
    "    batch_data_flip,batch_labels_flip = init_batch_data(batch_size)\n",
    "    \n",
    "    #create a list of image numbers you want to use for a particular video using full frames\n",
    "    img_idx = [x for x in range(0, frames)] \n",
    "\n",
    "    for folder in range(batch_size): # iterate over the batch_size\n",
    "        # read all the images in the folder\n",
    "        imgs = sorted(os.listdir(source_path+'/'+ t[folder + (batch_num*batch_size)].split(';')[0])) \n",
    "        # Generate a random affine to be used in image transformation for buidling agumented data set\n",
    "        M = get_random_affine()\n",
    "        \n",
    "        #  Iterate over the frames/images of a folder to read them in\n",
    "        for idx, item in enumerate(img_idx): \n",
    "            ## image = imread(source_path+'/'+ t[folder + (batch_num*batch_size)].strip().split(';')[0]+'/'+imgs[item]).astype(np.float32)\n",
    "            image = cv2.imread(source_path+'/'+ t[folder + (batch_num*batch_size)].strip().split(';')[0]+'/'+imgs[item], cv2.IMREAD_COLOR)\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "            \n",
    "            # Cropping non symmetric frames\n",
    "            if image.shape[0] != image.shape[1]:\n",
    "                image=image[0:120,20:140]\n",
    "            \n",
    "            #crop the images and resize them. Note that the images are of 2 different shape \n",
    "            #and the conv3D will throw error if the inputs in a batch have different shapes   \n",
    "            resized = cv2.resize(image, (rows, cols), interpolation = cv2.INTER_AREA)\n",
    "            #Normal data\n",
    "            batch_data[folder,idx] = (resized)\n",
    "            \n",
    "            #Data with affine transformation\n",
    "            batch_data_aug[folder,idx] = (cv2.warpAffine(resized, M, (resized.shape[0], resized.shape[1])))\n",
    "            \n",
    "            # Data with horizontal flip\n",
    "            batch_data_flip[folder,idx]= np.flip(resized,1)\n",
    "\n",
    "        batch_labels[folder, int(t[folder + (batch_num*batch_size)].strip().split(';')[2])] = 1\n",
    "        batch_labels_aug[folder, int(t[folder + (batch_num*batch_size)].strip().split(';')[2])] = 1\n",
    "        \n",
    "        # Labeling data with horizobtal flip, right swipe becomes left swipe and viceversa\n",
    "        if int(t[folder + (batch_num*batch_size)].strip().split(';')[2])==0:\n",
    "                    batch_labels_flip[folder, 1] = 1\n",
    "        elif int(t[folder + (batch_num*batch_size)].strip().split(';')[2])==1:\n",
    "                    batch_labels_flip[folder, 0] = 1\n",
    "                    \n",
    "        else:\n",
    "                    batch_labels_flip[folder, int(t[folder + (batch_num*batch_size)].strip().split(';')[2])] = 1\n",
    "                  \n",
    "    \n",
    "    batch_data_final = np.append(batch_data, batch_data_aug, axis = 0)\n",
    "    batch_data_final = np.append(batch_data_final, batch_data_flip, axis = 0)\n",
    "\n",
    "    batch_labels_final = np.append(batch_labels, batch_labels_aug, axis = 0) \n",
    "    batch_labels_final = np.append(batch_labels_final, batch_labels_flip, axis = 0)\n",
    "    \n",
    "    if validation:\n",
    "        batch_data_final=batch_data\n",
    "        batch_labels_final= batch_labels\n",
    "        \n",
    "    return batch_data_final,batch_labels_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "executionInfo": {
     "elapsed": 3304,
     "status": "ok",
     "timestamp": 1604436126846,
     "user": {
      "displayName": "Amit Chawla",
      "photoUrl": "",
      "userId": "06080236380106251748"
     },
     "user_tz": -330
    },
    "id": "Sjjx0Zt6mxfI"
   },
   "outputs": [],
   "source": [
    "# wrapper generator function. it supports ablation experiment and a flag to decide between training and validation folder\n",
    "def generator(source_path, folder_list, batch_size, validation=False,ablation=None):\n",
    "    print( 'Source path = ', source_path, '; batch size =', batch_size)\n",
    "    if(ablation!=None):\n",
    "        folder_list=folder_list[:ablation]\n",
    "    while True:\n",
    "        t = np.random.permutation(folder_list)\n",
    "        num_batches = len(folder_list)//batch_size # calculate the number of batches\n",
    "        for batch in range(num_batches): # we iterate over the number of batches\n",
    "            # you yield the batch_data and the batch_labels, remember what does yield do\n",
    "            yield fetch_aug_batchdata(source_path, folder_list, batch, batch_size, t,validation)\n",
    "            \n",
    "        \n",
    "        # Code for the remaining data points which are left after full batches\n",
    "        if (len(folder_list) != batch_size*num_batches):\n",
    "            batch_size = len(folder_list) - (batch_size*num_batches)\n",
    "            yield fetch_aug_batchdata(source_path, folder_list, batch, batch_size, t,validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vS7SH2h6mxfK"
   },
   "source": [
    "Note here that a video is represented above in the generator as (number of images, height, width, number of channels). Take this into consideration while creating the model architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3297,
     "status": "ok",
     "timestamp": 1604436126847,
     "user": {
      "displayName": "Amit Chawla",
      "photoUrl": "",
      "userId": "06080236380106251748"
     },
     "user_tz": -330
    },
    "id": "1lAO-MjDmxfK",
    "outputId": "d71f8854-2608-4939-ebd4-42f6d0b4aa7a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# training sequences = 663\n",
      "# validation sequences = 100\n",
      "# epochs = 10\n"
     ]
    }
   ],
   "source": [
    "# path to images folders\n",
    "train_path = 'Project_data/train'\n",
    "val_path = 'Project_data/val'\n",
    "\n",
    "num_train_sequences = len(train_doc)\n",
    "print('# training sequences =', num_train_sequences)\n",
    "\n",
    "num_val_sequences = len(val_doc)\n",
    "print('# validation sequences =', num_val_sequences)\n",
    "\n",
    "num_epochs = 10 # choose the number of epochs\n",
    "print ('# epochs =', num_epochs)\n",
    "\n",
    "classes= 5 # output classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0pSW5czRmxfO"
   },
   "source": [
    "## Model\n",
    "Here you make the model using different functionalities that Keras provides. Remember to use `Conv3D` and `MaxPooling3D` and not `Conv2D` and `Maxpooling2D` for a 3D convolution model. You would want to use `TimeDistributed` while building a Conv2D + RNN model. Also remember that the last layer is the softmax. Design the network in such a way that the model is able to give good accuracy on the least number of parameters so that it can fit in the memory of the webcam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "executionInfo": {
     "elapsed": 3291,
     "status": "ok",
     "timestamp": 1604436126847,
     "user": {
      "displayName": "Amit Chawla",
      "photoUrl": "",
      "userId": "06080236380106251748"
     },
     "user_tz": -330
    },
    "id": "oomrFBismxfO"
   },
   "outputs": [],
   "source": [
    "# keras related imports\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, GRU, Flatten, TimeDistributed, Flatten, BatchNormalization, Activation, Dropout, LSTM, ZeroPadding3D\n",
    "from keras.layers.convolutional import Conv3D, MaxPooling3D, Conv2D, MaxPooling2D\n",
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras import optimizers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we have decided to experiment with this optimizer first. So keeping it in common place\n",
    "optimiser = optimizers.Adam(0.001) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_map=[8, 16, 32, 64, 128] # we will expirment with different number of features for different layers\n",
    "dense_layer_size = [1000,500,5]\n",
    "num_epochs = 10\n",
    "batch_size = 10\n",
    "input_shape = (frames, rows, cols, channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write your model here\n",
    "model = Sequential()\n",
    "# add multiple convulation layers\n",
    "model.add(TimeDistributed(Conv2D(feature_map[0], (3, 3), strides=(2, 2),activation='relu', padding='same'), input_shape=input_shape))\n",
    "\n",
    "model.add(TimeDistributed(Conv2D(feature_map[1], (3,3),padding='same', activation='relu')))\n",
    "model.add(TimeDistributed(MaxPooling2D((2, 2), strides=(2, 2))))\n",
    "\n",
    "model.add(TimeDistributed(Conv2D(feature_map[2], (3,3),padding='same', activation='relu')))\n",
    "model.add(TimeDistributed(MaxPooling2D((2, 2), strides=(2, 2))))\n",
    "\n",
    "model.add(TimeDistributed(Conv2D(feature_map[3], (2,2),padding='same', activation='relu')))\n",
    "model.add(TimeDistributed(MaxPooling2D((2, 2), strides=(2, 2))))\n",
    "\n",
    "\n",
    "model.add(TimeDistributed(BatchNormalization()))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(TimeDistributed(Flatten()))\n",
    "\n",
    "model.add(Dense(dense_layer_size[0], activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(dense_layer_size[1], activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "## using LSTM as the RNN model along with softmax as our last layer.\n",
    "model.add(LSTM(128, return_sequences=False))\n",
    "model.add(Dense(classes, activation='softmax')) # using Softmax as last layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "time_distributed_1 (TimeDist (None, 30, 60, 60, 8)     224       \n",
      "_________________________________________________________________\n",
      "time_distributed_2 (TimeDist (None, 30, 60, 60, 16)    1168      \n",
      "_________________________________________________________________\n",
      "time_distributed_3 (TimeDist (None, 30, 30, 30, 16)    0         \n",
      "_________________________________________________________________\n",
      "time_distributed_4 (TimeDist (None, 30, 30, 30, 32)    4640      \n",
      "_________________________________________________________________\n",
      "time_distributed_5 (TimeDist (None, 30, 15, 15, 32)    0         \n",
      "_________________________________________________________________\n",
      "time_distributed_6 (TimeDist (None, 30, 15, 15, 64)    8256      \n",
      "_________________________________________________________________\n",
      "time_distributed_7 (TimeDist (None, 30, 7, 7, 64)      0         \n",
      "_________________________________________________________________\n",
      "time_distributed_8 (TimeDist (None, 30, 7, 7, 64)      256       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 30, 7, 7, 64)      0         \n",
      "_________________________________________________________________\n",
      "time_distributed_9 (TimeDist (None, 30, 3136)          0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 30, 256)           803072    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 30, 256)           0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 30, 128)           32896     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 30, 128)           0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 128)               131584    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 5)                 645       \n",
      "=================================================================\n",
      "Total params: 982,741\n",
      "Trainable params: 982,613\n",
      "Non-trainable params: 128\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "print (model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/keras/callbacks.py:999: UserWarning: `epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n",
      "  warnings.warn('`epsilon` argument is deprecated and '\n"
     ]
    }
   ],
   "source": [
    "# timestamp to use in model name. \n",
    "curr_dt_time = datetime.datetime.now()\n",
    "\n",
    "model_name = 'model_init_lstm' + '_' + str(curr_dt_time).replace(' ','').replace(':','_') + '/'\n",
    "    \n",
    "if not os.path.exists(model_name):\n",
    "    os.mkdir(model_name)\n",
    "        \n",
    "filepath = model_name + 'model-{epoch:05d}-{loss:.5f}-{categorical_accuracy:.5f}-{val_loss:.5f}-{val_categorical_accuracy:.5f}.h5'\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath, save_best_only=True, monitor='val_loss', verbose=1, save_weights_only=False, mode='auto', period=1)\n",
    "\n",
    "LR = ReduceLROnPlateau(monitor='val_loss', factor=0.001, patience=5, cooldown=4, verbose=1,mode='auto',epsilon=0.0001)# write the REducelronplateau code here\n",
    "callbacks_list = [checkpoint, LR]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = generator(train_path, train_doc, batch_size)\n",
    "val_generator = generator(val_path, val_doc, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (num_train_sequences%batch_size) == 0:\n",
    "    steps_per_epoch = int(num_train_sequences/batch_size)\n",
    "else:\n",
    "    steps_per_epoch = (num_train_sequences//batch_size) + 1\n",
    "\n",
    "if (num_val_sequences%batch_size) == 0:\n",
    "    validation_steps = int(num_val_sequences/batch_size)\n",
    "else:\n",
    "    validation_steps = (num_val_sequences//batch_size) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source path =  Project_data/val ; batch size = 30\n",
      "Source path =  Project_data/train ; batch size = 30\n",
      "Epoch 1/10\n",
      "23/23 [==============================] - 215s 9s/step - loss: 1.2777 - categorical_accuracy: 0.4541 - val_loss: 1.1535 - val_categorical_accuracy: 0.5700\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.15351, saving model to model_init_lstm_2020-11-0709_28_02.025517/model-00001-1.27666-0.45450-1.15351-0.57000.h5\n",
      "Epoch 2/10\n",
      "23/23 [==============================] - 12s 501ms/step - loss: 1.2065 - categorical_accuracy: 0.5217 - val_loss: 2.0083 - val_categorical_accuracy: 0.3583\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 1.15351\n",
      "Epoch 3/10\n",
      "23/23 [==============================] - 16s 691ms/step - loss: 1.2278 - categorical_accuracy: 0.5459 - val_loss: 1.2475 - val_categorical_accuracy: 0.4333\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1.15351\n",
      "Epoch 4/10\n",
      "23/23 [==============================] - 17s 722ms/step - loss: 1.4947 - categorical_accuracy: 0.2754 - val_loss: 1.4052 - val_categorical_accuracy: 0.5750\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.15351\n",
      "Epoch 5/10\n",
      "23/23 [==============================] - 16s 677ms/step - loss: 1.3544 - categorical_accuracy: 0.4734 - val_loss: 1.7331 - val_categorical_accuracy: 0.3167\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1.15351\n",
      "Epoch 6/10\n",
      "23/23 [==============================] - 18s 766ms/step - loss: 1.3053 - categorical_accuracy: 0.4831 - val_loss: 1.5113 - val_categorical_accuracy: 0.4583\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.15351\n",
      "\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 1.0000000474974512e-06.\n",
      "Epoch 7/10\n",
      "23/23 [==============================] - 17s 742ms/step - loss: 1.2250 - categorical_accuracy: 0.5411 - val_loss: 1.4084 - val_categorical_accuracy: 0.4250\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1.15351\n",
      "Epoch 8/10\n",
      "23/23 [==============================] - 17s 728ms/step - loss: 1.2784 - categorical_accuracy: 0.5072 - val_loss: 1.2493 - val_categorical_accuracy: 0.4833\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1.15351\n",
      "Epoch 9/10\n",
      "23/23 [==============================] - 15s 664ms/step - loss: 1.2478 - categorical_accuracy: 0.4589 - val_loss: 1.3444 - val_categorical_accuracy: 0.3833\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 1.15351\n",
      "Epoch 10/10\n",
      "23/23 [==============================] - 14s 601ms/step - loss: 1.1919 - categorical_accuracy: 0.5797 - val_loss: 1.3613 - val_categorical_accuracy: 0.4333\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 1.15351\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f11f8fb4c50>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
    "                  callbacks=callbacks_list, validation_data=val_generator, \n",
    "                  validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We add batch normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_map=[8, 16, 32, 64, 128] # we will expirment with different number of features for different layers\n",
    "dense_layer_size = [1000,500,5]\n",
    "num_epochs = 10\n",
    "batch_size = 10\n",
    "input_shape = (frames, rows, cols, channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write your model here\n",
    "model = Sequential()\n",
    "# add multiple convulation layers\n",
    "model.add(TimeDistributed(Conv2D(feature_map[0], (3, 3), strides=(2, 2),activation='relu', padding='same'), input_shape=input_shape))\n",
    "\n",
    "model.add(TimeDistributed(Conv2D(feature_map[1], (3,3),padding='same', activation='relu')))\n",
    "model.add(TimeDistributed(MaxPooling2D((2, 2), strides=(2, 2))))\n",
    "model.add(TimeDistributed(BatchNormalization()))\n",
    "\n",
    "\n",
    "model.add(TimeDistributed(Conv2D(feature_map[2], (3,3),padding='same', activation='relu')))\n",
    "model.add(TimeDistributed(MaxPooling2D((2, 2), strides=(2, 2))))\n",
    "model.add(TimeDistributed(BatchNormalization()))\n",
    "\n",
    "model.add(TimeDistributed(Conv2D(feature_map[3], (2,2),padding='same', activation='relu')))\n",
    "model.add(TimeDistributed(MaxPooling2D((2, 2), strides=(2, 2))))\n",
    "\n",
    "\n",
    "model.add(TimeDistributed(BatchNormalization()))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(TimeDistributed(Flatten()))\n",
    "\n",
    "model.add(Dense(dense_layer_size[0], activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(dense_layer_size[1], activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "## using LSTM as the RNN model along with softmax as our last layer.\n",
    "model.add(LSTM(128, return_sequences=False))\n",
    "model.add(Dense(classes, activation='softmax')) # using Softmax as last layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "time_distributed_10 (TimeDis (None, 30, 60, 60, 8)     224       \n",
      "_________________________________________________________________\n",
      "time_distributed_11 (TimeDis (None, 30, 60, 60, 16)    1168      \n",
      "_________________________________________________________________\n",
      "time_distributed_12 (TimeDis (None, 30, 30, 30, 16)    0         \n",
      "_________________________________________________________________\n",
      "time_distributed_13 (TimeDis (None, 30, 30, 30, 32)    4640      \n",
      "_________________________________________________________________\n",
      "time_distributed_14 (TimeDis (None, 30, 15, 15, 32)    0         \n",
      "_________________________________________________________________\n",
      "time_distributed_15 (TimeDis (None, 30, 15, 15, 64)    8256      \n",
      "_________________________________________________________________\n",
      "time_distributed_16 (TimeDis (None, 30, 7, 7, 64)      0         \n",
      "_________________________________________________________________\n",
      "time_distributed_17 (TimeDis (None, 30, 7, 7, 64)      256       \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 30, 7, 7, 64)      0         \n",
      "_________________________________________________________________\n",
      "time_distributed_18 (TimeDis (None, 30, 3136)          0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 30, 1000)          3137000   \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 30, 1000)          0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 30, 500)           500500    \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 30, 500)           0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 128)               322048    \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 5)                 645       \n",
      "=================================================================\n",
      "Total params: 3,974,737\n",
      "Trainable params: 3,974,609\n",
      "Non-trainable params: 128\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "print (model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/keras/callbacks.py:999: UserWarning: `epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n",
      "  warnings.warn('`epsilon` argument is deprecated and '\n"
     ]
    }
   ],
   "source": [
    "# timestamp to use in model name. \n",
    "curr_dt_time = datetime.datetime.now()\n",
    "\n",
    "model_name = 'model_init_lstm' + '_' + str(curr_dt_time).replace(' ','').replace(':','_') + '/'\n",
    "    \n",
    "if not os.path.exists(model_name):\n",
    "    os.mkdir(model_name)\n",
    "        \n",
    "filepath = model_name + 'model-{epoch:05d}-{loss:.5f}-{categorical_accuracy:.5f}-{val_loss:.5f}-{val_categorical_accuracy:.5f}.h5'\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath, save_best_only=True, monitor='val_loss', verbose=1, save_weights_only=False, mode='auto', period=1)\n",
    "\n",
    "LR = ReduceLROnPlateau(monitor='val_loss', factor=0.001, patience=5, cooldown=4, verbose=1,mode='auto',epsilon=0.0001)# write the REducelronplateau code here\n",
    "callbacks_list = [checkpoint, LR]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (num_train_sequences%batch_size) == 0:\n",
    "    steps_per_epoch = int(num_train_sequences/batch_size)\n",
    "else:\n",
    "    steps_per_epoch = (num_train_sequences//batch_size) + 1\n",
    "\n",
    "if (num_val_sequences%batch_size) == 0:\n",
    "    validation_steps = int(num_val_sequences/batch_size)\n",
    "else:\n",
    "    validation_steps = (num_val_sequences//batch_size) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = generator(train_path, train_doc, batch_size)\n",
    "val_generator = generator(val_path, val_doc, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source path =  Project_data/val ; batch size = Source path =  Project_data/train ; batch size = 30\n",
      "30\n",
      "Epoch 1/10\n",
      "23/23 [==============================] - 123s 5s/step - loss: 1.6733 - categorical_accuracy: 0.1853 - val_loss: 1.6663 - val_categorical_accuracy: 0.1867\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.66629, saving model to model_init_lstm_2020-11-0709_34_02.147293/model-00001-1.66894-0.19256-1.66629-0.18667.h5\n",
      "Epoch 2/10\n",
      "23/23 [==============================] - 12s 529ms/step - loss: 1.6427 - categorical_accuracy: 0.1884 - val_loss: 1.5818 - val_categorical_accuracy: 0.2417\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.66629 to 1.58178, saving model to model_init_lstm_2020-11-0709_34_02.147293/model-00002-1.64273-0.18841-1.58178-0.24167.h5\n",
      "Epoch 3/10\n",
      "23/23 [==============================] - 15s 673ms/step - loss: 1.6063 - categorical_accuracy: 0.2754 - val_loss: 1.6405 - val_categorical_accuracy: 0.1917\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1.58178\n",
      "Epoch 4/10\n",
      "23/23 [==============================] - 16s 685ms/step - loss: 1.5947 - categorical_accuracy: 0.2802 - val_loss: 1.5647 - val_categorical_accuracy: 0.2917\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.58178 to 1.56469, saving model to model_init_lstm_2020-11-0709_34_02.147293/model-00004-1.59469-0.28019-1.56469-0.29167.h5\n",
      "Epoch 5/10\n",
      "23/23 [==============================] - 16s 694ms/step - loss: 1.5874 - categorical_accuracy: 0.2802 - val_loss: 1.5910 - val_categorical_accuracy: 0.3083\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1.56469\n",
      "Epoch 6/10\n",
      "23/23 [==============================] - 14s 609ms/step - loss: 1.6084 - categorical_accuracy: 0.2464 - val_loss: 1.6189 - val_categorical_accuracy: 0.2583\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.56469\n",
      "Epoch 7/10\n",
      "23/23 [==============================] - 17s 722ms/step - loss: 1.6172 - categorical_accuracy: 0.2174 - val_loss: 1.6008 - val_categorical_accuracy: 0.2833\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1.56469\n",
      "Epoch 8/10\n",
      "23/23 [==============================] - 15s 666ms/step - loss: 1.5994 - categorical_accuracy: 0.2367 - val_loss: 1.5474 - val_categorical_accuracy: 0.3167\n",
      "\n",
      "Epoch 00008: val_loss improved from 1.56469 to 1.54740, saving model to model_init_lstm_2020-11-0709_34_02.147293/model-00008-1.59945-0.23671-1.54740-0.31667.h5\n",
      "Epoch 9/10\n",
      "23/23 [==============================] - 17s 727ms/step - loss: 1.6030 - categorical_accuracy: 0.2271 - val_loss: 1.5572 - val_categorical_accuracy: 0.3250\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 1.54740\n",
      "Epoch 10/10\n",
      "23/23 [==============================] - 17s 729ms/step - loss: 1.6136 - categorical_accuracy: 0.1981 - val_loss: 1.5583 - val_categorical_accuracy: 0.2917\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 1.54740\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f11ea2f1ac8>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
    "                  callbacks=callbacks_list, validation_data=val_generator, \n",
    "                  validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Increase the learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_map=[8, 16, 32, 64, 128] \n",
    "dense_layer_size = [256,128,5] # we reduce the dense layer neurons\n",
    "num_epochs = 10\n",
    "batch_size = 10\n",
    "input_shape = (frames, rows, cols, channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = Sequential()\n",
    "# add multiple convulation layers\n",
    "model.add(TimeDistributed(Conv2D(feature_map[0], (3, 3), strides=(2, 2),activation='relu', padding='same'), input_shape=input_shape))\n",
    "\n",
    "model.add(TimeDistributed(Conv2D(feature_map[1], (3,3),padding='same', activation='relu')))\n",
    "model.add(TimeDistributed(MaxPooling2D((2, 2), strides=(2, 2))))\n",
    "model.add(TimeDistributed(BatchNormalization()))\n",
    "\n",
    "# model.add(keras.layers.Dropout(0.4))\n",
    "\n",
    "model.add(TimeDistributed(Conv2D(feature_map[2], (3,3),padding='same', activation='relu')))\n",
    "model.add(TimeDistributed(MaxPooling2D((2, 2), strides=(2, 2))))\n",
    "# model.add(keras.layers.Dropout(0.4))\n",
    "model.add(TimeDistributed(BatchNormalization()))\n",
    "\n",
    "model.add(TimeDistributed(Conv2D(feature_map[3], (2,2),padding='same', activation='relu')))\n",
    "model.add(TimeDistributed(MaxPooling2D((2, 2), strides=(2, 2))))\n",
    "\n",
    "\n",
    "model.add(TimeDistributed(BatchNormalization()))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(TimeDistributed(Flatten()))\n",
    "\n",
    "model.add(Dense(dense_layer_size[0], activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(dense_layer_size[1], activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "## using LSTM as the RNN model along with softmax as our last layer.\n",
    "model.add(LSTM(128, return_sequences=False))\n",
    "model.add(Dense(classes, activation='softmax')) # using Softmax as last layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "time_distributed_19 (TimeDis (None, 30, 60, 60, 8)     224       \n",
      "_________________________________________________________________\n",
      "time_distributed_20 (TimeDis (None, 30, 60, 60, 16)    1168      \n",
      "_________________________________________________________________\n",
      "time_distributed_21 (TimeDis (None, 30, 30, 30, 16)    0         \n",
      "_________________________________________________________________\n",
      "time_distributed_22 (TimeDis (None, 30, 30, 30, 16)    64        \n",
      "_________________________________________________________________\n",
      "time_distributed_23 (TimeDis (None, 30, 30, 30, 32)    4640      \n",
      "_________________________________________________________________\n",
      "time_distributed_24 (TimeDis (None, 30, 15, 15, 32)    0         \n",
      "_________________________________________________________________\n",
      "time_distributed_25 (TimeDis (None, 30, 15, 15, 32)    128       \n",
      "_________________________________________________________________\n",
      "time_distributed_26 (TimeDis (None, 30, 15, 15, 64)    8256      \n",
      "_________________________________________________________________\n",
      "time_distributed_27 (TimeDis (None, 30, 7, 7, 64)      0         \n",
      "_________________________________________________________________\n",
      "time_distributed_28 (TimeDis (None, 30, 7, 7, 64)      256       \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 30, 7, 7, 64)      0         \n",
      "_________________________________________________________________\n",
      "time_distributed_29 (TimeDis (None, 30, 3136)          0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 30, 1000)          3137000   \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 30, 1000)          0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 30, 500)           500500    \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 30, 500)           0         \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 128)               322048    \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 5)                 645       \n",
      "=================================================================\n",
      "Total params: 3,974,929\n",
      "Trainable params: 3,974,705\n",
      "Non-trainable params: 224\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "print (model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/keras/callbacks.py:999: UserWarning: `epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n",
      "  warnings.warn('`epsilon` argument is deprecated and '\n"
     ]
    }
   ],
   "source": [
    "# timestamp to use in model name. \n",
    "curr_dt_time = datetime.datetime.now()\n",
    "\n",
    "model_name = 'model_init_lstm' + '_' + str(curr_dt_time).replace(' ','').replace(':','_') + '/'\n",
    "    \n",
    "if not os.path.exists(model_name):\n",
    "    os.mkdir(model_name)\n",
    "        \n",
    "filepath = model_name + 'model-{epoch:05d}-{loss:.5f}-{categorical_accuracy:.5f}-{val_loss:.5f}-{val_categorical_accuracy:.5f}.h5'\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath, save_best_only=True, monitor='val_loss', verbose=1, save_weights_only=False, mode='auto', period=1)\n",
    "\n",
    "LR = ReduceLROnPlateau(monitor='val_loss', factor=0.001, patience=2, cooldown=4, verbose=1,mode='auto',epsilon=0.0001)# write the REducelronplateau code here\n",
    "callbacks_list = [checkpoint, LR]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (num_train_sequences%batch_size) == 0:\n",
    "    steps_per_epoch = int(num_train_sequences/batch_size)\n",
    "else:\n",
    "    steps_per_epoch = (num_train_sequences//batch_size) + 1\n",
    "\n",
    "if (num_val_sequences%batch_size) == 0:\n",
    "    validation_steps = int(num_val_sequences/batch_size)\n",
    "else:\n",
    "    validation_steps = (num_val_sequences//batch_size) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = generator(train_path, train_doc, batch_size)\n",
    "val_generator = generator(val_path, val_doc, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source path =  Project_data/val ; batch size = 30\n",
      "Source path =  Project_data/train ; batch size = 30\n",
      "Epoch 1/20\n",
      "23/23 [==============================] - 125s 5s/step - loss: 1.7123 - categorical_accuracy: 0.1964 - val_loss: 1.6057 - val_categorical_accuracy: 0.2100\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.60572, saving model to model_init_lstm_2020-11-0709_38_30.050657/model-00001-1.71878-0.19105-1.60572-0.21000.h5\n",
      "Epoch 2/20\n",
      "23/23 [==============================] - 13s 556ms/step - loss: 1.6829 - categorical_accuracy: 0.1981 - val_loss: 1.5462 - val_categorical_accuracy: 0.2833\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.60572 to 1.54617, saving model to model_init_lstm_2020-11-0709_38_30.050657/model-00002-1.68285-0.19807-1.54617-0.28333.h5\n",
      "Epoch 3/20\n",
      "23/23 [==============================] - 15s 654ms/step - loss: 1.6182 - categorical_accuracy: 0.2029 - val_loss: 1.5778 - val_categorical_accuracy: 0.2417\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1.54617\n",
      "Epoch 4/20\n",
      "23/23 [==============================] - 17s 719ms/step - loss: 1.6327 - categorical_accuracy: 0.2367 - val_loss: 1.5562 - val_categorical_accuracy: 0.2333\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.54617\n",
      "Epoch 5/20\n",
      "23/23 [==============================] - 16s 715ms/step - loss: 1.6197 - categorical_accuracy: 0.2126 - val_loss: 1.5263 - val_categorical_accuracy: 0.3083\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.54617 to 1.52634, saving model to model_init_lstm_2020-11-0709_38_30.050657/model-00005-1.61965-0.21256-1.52634-0.30833.h5\n",
      "Epoch 6/20\n",
      "23/23 [==============================] - 16s 686ms/step - loss: 1.5612 - categorical_accuracy: 0.2850 - val_loss: 1.5456 - val_categorical_accuracy: 0.2250\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.52634\n",
      "Epoch 7/20\n",
      "23/23 [==============================] - 15s 644ms/step - loss: 1.6487 - categorical_accuracy: 0.2464 - val_loss: 1.5777 - val_categorical_accuracy: 0.2167\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1.52634\n",
      "Epoch 8/20\n",
      "23/23 [==============================] - 17s 759ms/step - loss: 1.6166 - categorical_accuracy: 0.2415 - val_loss: 1.5262 - val_categorical_accuracy: 0.3083\n",
      "\n",
      "Epoch 00008: val_loss improved from 1.52634 to 1.52618, saving model to model_init_lstm_2020-11-0709_38_30.050657/model-00008-1.61661-0.24155-1.52618-0.30833.h5\n",
      "Epoch 9/20\n",
      "23/23 [==============================] - 16s 689ms/step - loss: 1.5753 - categorical_accuracy: 0.2174 - val_loss: 1.5033 - val_categorical_accuracy: 0.3167\n",
      "\n",
      "Epoch 00009: val_loss improved from 1.52618 to 1.50335, saving model to model_init_lstm_2020-11-0709_38_30.050657/model-00009-1.57534-0.21739-1.50335-0.31667.h5\n",
      "Epoch 10/20\n",
      "23/23 [==============================] - 15s 672ms/step - loss: 1.5429 - categorical_accuracy: 0.3188 - val_loss: 1.5181 - val_categorical_accuracy: 0.3083\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 1.50335\n",
      "Epoch 11/20\n",
      "23/23 [==============================] - 15s 658ms/step - loss: 1.5687 - categorical_accuracy: 0.2947 - val_loss: 1.5245 - val_categorical_accuracy: 0.2667\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 1.50335\n",
      "Epoch 12/20\n",
      "23/23 [==============================] - 17s 731ms/step - loss: 1.5435 - categorical_accuracy: 0.3430 - val_loss: 1.5218 - val_categorical_accuracy: 0.2667\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 1.50335\n",
      "Epoch 13/20\n",
      "23/23 [==============================] - 15s 643ms/step - loss: 1.5712 - categorical_accuracy: 0.2802 - val_loss: 1.4829 - val_categorical_accuracy: 0.3417\n",
      "\n",
      "Epoch 00013: val_loss improved from 1.50335 to 1.48288, saving model to model_init_lstm_2020-11-0709_38_30.050657/model-00013-1.57117-0.28019-1.48288-0.34167.h5\n",
      "Epoch 14/20\n",
      "23/23 [==============================] - 16s 712ms/step - loss: 1.5681 - categorical_accuracy: 0.2464 - val_loss: 1.5156 - val_categorical_accuracy: 0.2833\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 1.48288\n",
      "Epoch 15/20\n",
      "23/23 [==============================] - 15s 660ms/step - loss: 1.5495 - categorical_accuracy: 0.2657 - val_loss: 1.4874 - val_categorical_accuracy: 0.3583\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 1.48288\n",
      "Epoch 16/20\n",
      "23/23 [==============================] - 15s 650ms/step - loss: 1.5459 - categorical_accuracy: 0.3092 - val_loss: 1.5062 - val_categorical_accuracy: 0.3500\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 1.48288\n",
      "Epoch 17/20\n",
      "23/23 [==============================] - 17s 729ms/step - loss: 1.5704 - categorical_accuracy: 0.2995 - val_loss: 1.5049 - val_categorical_accuracy: 0.3583\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 1.48288\n",
      "Epoch 18/20\n",
      "23/23 [==============================] - 17s 724ms/step - loss: 1.6027 - categorical_accuracy: 0.2657 - val_loss: 1.4743 - val_categorical_accuracy: 0.3750\n",
      "\n",
      "Epoch 00018: val_loss improved from 1.48288 to 1.47435, saving model to model_init_lstm_2020-11-0709_38_30.050657/model-00018-1.60270-0.26570-1.47435-0.37500.h5\n",
      "Epoch 19/20\n",
      "23/23 [==============================] - 17s 733ms/step - loss: 1.5153 - categorical_accuracy: 0.3285 - val_loss: 1.4747 - val_categorical_accuracy: 0.3667\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 1.47435\n",
      "Epoch 20/20\n",
      "23/23 [==============================] - 17s 743ms/step - loss: 1.5513 - categorical_accuracy: 0.3043 - val_loss: 1.5143 - val_categorical_accuracy: 0.3167\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 1.47435\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f11ea2f1518>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
    "                  callbacks=callbacks_list, validation_data=val_generator, \n",
    "                  validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We reduce the dense layer neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_map=[8, 16, 32, 64, 128] \n",
    "dense_layer_size = [256,128,5] # we reduce the dense layer neurons\n",
    "num_epochs = 10\n",
    "batch_size = 10\n",
    "input_shape = (frames, rows, cols, channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = Sequential()\n",
    "# add multiple convulation layers\n",
    "model.add(TimeDistributed(Conv2D(feature_map[0], (3, 3), strides=(2, 2),activation='relu', padding='same'), input_shape=input_shape))\n",
    "\n",
    "model.add(TimeDistributed(Conv2D(feature_map[1], (3,3),padding='same', activation='relu')))\n",
    "model.add(TimeDistributed(MaxPooling2D((2, 2), strides=(2, 2))))\n",
    "model.add(TimeDistributed(BatchNormalization()))\n",
    "\n",
    "# model.add(keras.layers.Dropout(0.4))\n",
    "\n",
    "model.add(TimeDistributed(Conv2D(feature_map[2], (3,3),padding='same', activation='relu')))\n",
    "model.add(TimeDistributed(MaxPooling2D((2, 2), strides=(2, 2))))\n",
    "# model.add(keras.layers.Dropout(0.4))\n",
    "model.add(TimeDistributed(BatchNormalization()))\n",
    "\n",
    "model.add(TimeDistributed(Conv2D(feature_map[3], (2,2),padding='same', activation='relu')))\n",
    "model.add(TimeDistributed(MaxPooling2D((2, 2), strides=(2, 2))))\n",
    "\n",
    "\n",
    "model.add(TimeDistributed(BatchNormalization()))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(TimeDistributed(Flatten()))\n",
    "\n",
    "model.add(Dense(dense_layer_size[0], activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(dense_layer_size[1], activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "## using LSTM as the RNN model along with softmax as our last layer.\n",
    "model.add(LSTM(128, return_sequences=False))\n",
    "model.add(Dense(classes, activation='softmax')) # using Softmax as last layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "time_distributed_19 (TimeDis (None, 30, 60, 60, 8)     224       \n",
      "_________________________________________________________________\n",
      "time_distributed_20 (TimeDis (None, 30, 60, 60, 16)    1168      \n",
      "_________________________________________________________________\n",
      "time_distributed_21 (TimeDis (None, 30, 30, 30, 16)    0         \n",
      "_________________________________________________________________\n",
      "time_distributed_22 (TimeDis (None, 30, 30, 30, 16)    64        \n",
      "_________________________________________________________________\n",
      "time_distributed_23 (TimeDis (None, 30, 30, 30, 32)    4640      \n",
      "_________________________________________________________________\n",
      "time_distributed_24 (TimeDis (None, 30, 15, 15, 32)    0         \n",
      "_________________________________________________________________\n",
      "time_distributed_25 (TimeDis (None, 30, 15, 15, 32)    128       \n",
      "_________________________________________________________________\n",
      "time_distributed_26 (TimeDis (None, 30, 15, 15, 64)    8256      \n",
      "_________________________________________________________________\n",
      "time_distributed_27 (TimeDis (None, 30, 7, 7, 64)      0         \n",
      "_________________________________________________________________\n",
      "time_distributed_28 (TimeDis (None, 30, 7, 7, 64)      256       \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 30, 7, 7, 64)      0         \n",
      "_________________________________________________________________\n",
      "time_distributed_29 (TimeDis (None, 30, 3136)          0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 30, 1000)          3137000   \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 30, 1000)          0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 30, 500)           500500    \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 30, 500)           0         \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 128)               322048    \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 5)                 645       \n",
      "=================================================================\n",
      "Total params: 3,974,929\n",
      "Trainable params: 3,974,705\n",
      "Non-trainable params: 224\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "print (model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/keras/callbacks.py:999: UserWarning: `epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n",
      "  warnings.warn('`epsilon` argument is deprecated and '\n"
     ]
    }
   ],
   "source": [
    "# timestamp to use in model name. \n",
    "curr_dt_time = datetime.datetime.now()\n",
    "\n",
    "model_name = 'model_init_lstm' + '_' + str(curr_dt_time).replace(' ','').replace(':','_') + '/'\n",
    "    \n",
    "if not os.path.exists(model_name):\n",
    "    os.mkdir(model_name)\n",
    "        \n",
    "filepath = model_name + 'model-{epoch:05d}-{loss:.5f}-{categorical_accuracy:.5f}-{val_loss:.5f}-{val_categorical_accuracy:.5f}.h5'\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath, save_best_only=True, monitor='val_loss', verbose=1, save_weights_only=False, mode='auto', period=1)\n",
    "\n",
    "LR = ReduceLROnPlateau(monitor='val_loss', factor=0.001, patience=5, cooldown=4, verbose=1,mode='auto',epsilon=0.0001)# write the REducelronplateau code here\n",
    "callbacks_list = [checkpoint, LR]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (num_train_sequences%batch_size) == 0:\n",
    "    steps_per_epoch = int(num_train_sequences/batch_size)\n",
    "else:\n",
    "    steps_per_epoch = (num_train_sequences//batch_size) + 1\n",
    "\n",
    "if (num_val_sequences%batch_size) == 0:\n",
    "    validation_steps = int(num_val_sequences/batch_size)\n",
    "else:\n",
    "    validation_steps = (num_val_sequences//batch_size) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = generator(train_path, train_doc, batch_size)\n",
    "val_generator = generator(val_path, val_doc, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source path =  Project_data/val ; batch size = 30\n",
      "Source path =  Project_data/train ; batch size = 30\n",
      "Epoch 1/20\n",
      "23/23 [==============================] - 125s 5s/step - loss: 1.7123 - categorical_accuracy: 0.1964 - val_loss: 1.6057 - val_categorical_accuracy: 0.2100\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.60572, saving model to model_init_lstm_2020-11-0709_38_30.050657/model-00001-1.71878-0.19105-1.60572-0.21000.h5\n",
      "Epoch 2/20\n",
      "23/23 [==============================] - 13s 556ms/step - loss: 1.6829 - categorical_accuracy: 0.1981 - val_loss: 1.5462 - val_categorical_accuracy: 0.2833\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.60572 to 1.54617, saving model to model_init_lstm_2020-11-0709_38_30.050657/model-00002-1.68285-0.19807-1.54617-0.28333.h5\n",
      "Epoch 3/20\n",
      "23/23 [==============================] - 15s 654ms/step - loss: 1.6182 - categorical_accuracy: 0.2029 - val_loss: 1.5778 - val_categorical_accuracy: 0.2417\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1.54617\n",
      "Epoch 4/20\n",
      "23/23 [==============================] - 17s 719ms/step - loss: 1.6327 - categorical_accuracy: 0.2367 - val_loss: 1.5562 - val_categorical_accuracy: 0.2333\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.54617\n",
      "Epoch 5/20\n",
      "23/23 [==============================] - 16s 715ms/step - loss: 1.6197 - categorical_accuracy: 0.2126 - val_loss: 1.5263 - val_categorical_accuracy: 0.3083\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.54617 to 1.52634, saving model to model_init_lstm_2020-11-0709_38_30.050657/model-00005-1.61965-0.21256-1.52634-0.30833.h5\n",
      "Epoch 6/20\n",
      "23/23 [==============================] - 16s 686ms/step - loss: 1.5612 - categorical_accuracy: 0.2850 - val_loss: 1.5456 - val_categorical_accuracy: 0.2250\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.52634\n",
      "Epoch 7/20\n",
      "23/23 [==============================] - 15s 644ms/step - loss: 1.6487 - categorical_accuracy: 0.2464 - val_loss: 1.5777 - val_categorical_accuracy: 0.2167\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1.52634\n",
      "Epoch 8/20\n",
      "23/23 [==============================] - 17s 759ms/step - loss: 1.6166 - categorical_accuracy: 0.2415 - val_loss: 1.5262 - val_categorical_accuracy: 0.3083\n",
      "\n",
      "Epoch 00008: val_loss improved from 1.52634 to 1.52618, saving model to model_init_lstm_2020-11-0709_38_30.050657/model-00008-1.61661-0.24155-1.52618-0.30833.h5\n",
      "Epoch 9/20\n",
      "23/23 [==============================] - 16s 689ms/step - loss: 1.5753 - categorical_accuracy: 0.2174 - val_loss: 1.5033 - val_categorical_accuracy: 0.3167\n",
      "\n",
      "Epoch 00009: val_loss improved from 1.52618 to 1.50335, saving model to model_init_lstm_2020-11-0709_38_30.050657/model-00009-1.57534-0.21739-1.50335-0.31667.h5\n",
      "Epoch 10/20\n",
      "23/23 [==============================] - 15s 672ms/step - loss: 1.5429 - categorical_accuracy: 0.3188 - val_loss: 1.5181 - val_categorical_accuracy: 0.3083\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 1.50335\n",
      "Epoch 11/20\n",
      "23/23 [==============================] - 15s 658ms/step - loss: 1.5687 - categorical_accuracy: 0.2947 - val_loss: 1.5245 - val_categorical_accuracy: 0.2667\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 1.50335\n",
      "Epoch 12/20\n",
      "23/23 [==============================] - 17s 731ms/step - loss: 1.5435 - categorical_accuracy: 0.3430 - val_loss: 1.5218 - val_categorical_accuracy: 0.2667\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 1.50335\n",
      "Epoch 13/20\n",
      "23/23 [==============================] - 15s 643ms/step - loss: 1.5712 - categorical_accuracy: 0.2802 - val_loss: 1.4829 - val_categorical_accuracy: 0.3417\n",
      "\n",
      "Epoch 00013: val_loss improved from 1.50335 to 1.48288, saving model to model_init_lstm_2020-11-0709_38_30.050657/model-00013-1.57117-0.28019-1.48288-0.34167.h5\n",
      "Epoch 14/20\n",
      "23/23 [==============================] - 16s 712ms/step - loss: 1.5681 - categorical_accuracy: 0.2464 - val_loss: 1.5156 - val_categorical_accuracy: 0.2833\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 1.48288\n",
      "Epoch 15/20\n",
      "23/23 [==============================] - 15s 660ms/step - loss: 1.5495 - categorical_accuracy: 0.2657 - val_loss: 1.4874 - val_categorical_accuracy: 0.3583\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 1.48288\n",
      "Epoch 16/20\n",
      "23/23 [==============================] - 15s 650ms/step - loss: 1.5459 - categorical_accuracy: 0.3092 - val_loss: 1.5062 - val_categorical_accuracy: 0.3500\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 1.48288\n",
      "Epoch 17/20\n",
      "23/23 [==============================] - 17s 729ms/step - loss: 1.5704 - categorical_accuracy: 0.2995 - val_loss: 1.5049 - val_categorical_accuracy: 0.3583\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 1.48288\n",
      "Epoch 18/20\n",
      "23/23 [==============================] - 17s 724ms/step - loss: 1.6027 - categorical_accuracy: 0.2657 - val_loss: 1.4743 - val_categorical_accuracy: 0.3750\n",
      "\n",
      "Epoch 00018: val_loss improved from 1.48288 to 1.47435, saving model to model_init_lstm_2020-11-0709_38_30.050657/model-00018-1.60270-0.26570-1.47435-0.37500.h5\n",
      "Epoch 19/20\n",
      "23/23 [==============================] - 17s 733ms/step - loss: 1.5153 - categorical_accuracy: 0.3285 - val_loss: 1.4747 - val_categorical_accuracy: 0.3667\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 1.47435\n",
      "Epoch 20/20\n",
      "23/23 [==============================] - 17s 743ms/step - loss: 1.5513 - categorical_accuracy: 0.3043 - val_loss: 1.5143 - val_categorical_accuracy: 0.3167\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 1.47435\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f11ea2f1518>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
    "                  callbacks=callbacks_list, validation_data=val_generator, \n",
    "                  validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GRU MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "executionInfo": {
     "elapsed": 4564,
     "status": "ok",
     "timestamp": 1604436128129,
     "user": {
      "displayName": "Amit Chawla",
      "photoUrl": "",
      "userId": "06080236380106251748"
     },
     "user_tz": -330
    },
    "id": "-Tlfx79bmxfR"
   },
   "outputs": [],
   "source": [
    "#write your model here\n",
    "feature_map=[8, 16, 32, 64, 128, 256] # we will expirment with different number of features for different layers\n",
    "dense_layer_size = [1000,500,5] # \n",
    "classes= 5\n",
    "input_shape = (frames, rows, cols, channels)\n",
    "model = Sequential()\n",
    "# add multiple convulation layers\n",
    "model.add(TimeDistributed(Conv2D(feature_map[0], (3, 3), strides=(2, 2),activation='relu', padding='same'), input_shape=input_shape))\n",
    "\n",
    "model.add(TimeDistributed(Conv2D(feature_map[1], (3,3),padding='same', activation='relu')))\n",
    "model.add(TimeDistributed(MaxPooling2D((2, 2), strides=(2, 2))))\n",
    "model.add(TimeDistributed(BatchNormalization()))\n",
    "\n",
    "model.add(TimeDistributed(Conv2D(feature_map[2], (3,3),padding='same', activation='relu')))\n",
    "model.add(TimeDistributed(MaxPooling2D((2, 2), strides=(2, 2))))\n",
    "model.add(TimeDistributed(BatchNormalization()))\n",
    "\n",
    "model.add(TimeDistributed(Conv2D(feature_map[3], (2,2),padding='same', activation='relu')))\n",
    "model.add(TimeDistributed(MaxPooling2D((2, 2), strides=(2, 2))))\n",
    "model.add(TimeDistributed(BatchNormalization()))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(TimeDistributed(Conv2D(feature_map[4], (2,2),padding='same', activation='relu')))\n",
    "model.add(TimeDistributed(MaxPooling2D((2, 2), strides=(2, 2))))\n",
    "model.add(TimeDistributed(BatchNormalization()))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(TimeDistributed(Flatten()))\n",
    "\n",
    "model.add(Dense(dense_layer_size[0], activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(dense_layer_size[1], activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "## using GRU as the RNN model along with softmax as our last layer.\n",
    "model.add(GRU(128, return_sequences=False))\n",
    "model.add(Dense(classes, activation='softmax')) # using Softmax as last layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jKpo5LkKmxfT"
   },
   "source": [
    "Now that you have written the model, the next step is to `compile` the model. When you print the `summary` of the model, you'll see the total number of parameters you have to train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4560,
     "status": "ok",
     "timestamp": 1604436128130,
     "user": {
      "displayName": "Amit Chawla",
      "photoUrl": "",
      "userId": "06080236380106251748"
     },
     "user_tz": -330
    },
    "id": "NaRv2AivmxfU",
    "outputId": "44e90e46-23c6-4207-8810-a0dfbff59b37",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "time_distributed_30 (TimeDis (None, 30, 60, 60, 8)     224       \n",
      "_________________________________________________________________\n",
      "time_distributed_31 (TimeDis (None, 30, 60, 60, 16)    1168      \n",
      "_________________________________________________________________\n",
      "time_distributed_32 (TimeDis (None, 30, 30, 30, 16)    0         \n",
      "_________________________________________________________________\n",
      "time_distributed_33 (TimeDis (None, 30, 30, 30, 16)    64        \n",
      "_________________________________________________________________\n",
      "time_distributed_34 (TimeDis (None, 30, 30, 30, 32)    4640      \n",
      "_________________________________________________________________\n",
      "time_distributed_35 (TimeDis (None, 30, 15, 15, 32)    0         \n",
      "_________________________________________________________________\n",
      "time_distributed_36 (TimeDis (None, 30, 15, 15, 32)    128       \n",
      "_________________________________________________________________\n",
      "time_distributed_37 (TimeDis (None, 30, 15, 15, 64)    8256      \n",
      "_________________________________________________________________\n",
      "time_distributed_38 (TimeDis (None, 30, 7, 7, 64)      0         \n",
      "_________________________________________________________________\n",
      "time_distributed_39 (TimeDis (None, 30, 7, 7, 64)      256       \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 30, 7, 7, 64)      0         \n",
      "_________________________________________________________________\n",
      "time_distributed_40 (TimeDis (None, 30, 7, 7, 128)     32896     \n",
      "_________________________________________________________________\n",
      "time_distributed_41 (TimeDis (None, 30, 3, 3, 128)     0         \n",
      "_________________________________________________________________\n",
      "time_distributed_42 (TimeDis (None, 30, 3, 3, 128)     512       \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 30, 3, 3, 128)     0         \n",
      "_________________________________________________________________\n",
      "time_distributed_43 (TimeDis (None, 30, 1152)          0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 30, 1000)          1153000   \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 30, 1000)          0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 30, 500)           500500    \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 30, 500)           0         \n",
      "_________________________________________________________________\n",
      "gru_1 (GRU)                  (None, 128)               241536    \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 5)                 645       \n",
      "=================================================================\n",
      "Total params: 1,943,825\n",
      "Trainable params: 1,943,345\n",
      "Non-trainable params: 480\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "optimiser = optimizers.Adam(0.001) #write your optimizer\n",
    "model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "print (model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MqlBfwFtmxfW"
   },
   "source": [
    "Let us create the `train_generator` and the `val_generator` which will be used in `.fit_generator`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "executionInfo": {
     "elapsed": 4551,
     "status": "ok",
     "timestamp": 1604436128132,
     "user": {
      "displayName": "Amit Chawla",
      "photoUrl": "",
      "userId": "06080236380106251748"
     },
     "user_tz": -330
    },
    "id": "c45IEYaZmxfX"
   },
   "outputs": [],
   "source": [
    "train_generator = generator(train_path, train_doc, batch_size)\n",
    "val_generator = generator(val_path, val_doc, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4544,
     "status": "ok",
     "timestamp": 1604436128132,
     "user": {
      "displayName": "Amit Chawla",
      "photoUrl": "",
      "userId": "06080236380106251748"
     },
     "user_tz": -330
    },
    "id": "c6E-9uGqmxfZ",
    "outputId": "59d5557a-1311-4c21-ec60-8e3a5b71cadb"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/keras/callbacks.py:999: UserWarning: `epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n",
      "  warnings.warn('`epsilon` argument is deprecated and '\n"
     ]
    }
   ],
   "source": [
    "model_name = 'model_init_CNN' + '_' + str(curr_dt_time).replace(' ','').replace(':','_') + '/'\n",
    "    \n",
    "if not os.path.exists(model_name):\n",
    "    os.mkdir(model_name)\n",
    "        \n",
    "filepath = model_name + 'model-{epoch:05d}-{loss:.5f}-{categorical_accuracy:.5f}-{val_loss:.5f}-{val_categorical_accuracy:.5f}.h5'\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath, save_best_only=True, monitor='val_loss', verbose=1, save_weights_only=False, mode='auto', period=1)\n",
    "\n",
    "LR = ReduceLROnPlateau(monitor='val_loss', factor=0.001, patience=5, cooldown=4, verbose=1,mode='auto',epsilon=0.0001)# write the REducelronplateau code here\n",
    "callbacks_list = [checkpoint, LR]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hErw7p94mxfb"
   },
   "source": [
    "The `steps_per_epoch` and `validation_steps` are used by `fit_generator` to decide the number of next() calls it need to make."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "executionInfo": {
     "elapsed": 4538,
     "status": "ok",
     "timestamp": 1604436128133,
     "user": {
      "displayName": "Amit Chawla",
      "photoUrl": "",
      "userId": "06080236380106251748"
     },
     "user_tz": -330
    },
    "id": "iCuo6cpBmxfc"
   },
   "outputs": [],
   "source": [
    "if (num_train_sequences%batch_size) == 0:\n",
    "    steps_per_epoch = int(num_train_sequences/batch_size)\n",
    "else:\n",
    "    steps_per_epoch = (num_train_sequences//batch_size) + 1\n",
    "\n",
    "if (num_val_sequences%batch_size) == 0:\n",
    "    validation_steps = int(num_val_sequences/batch_size)\n",
    "else:\n",
    "    validation_steps = (num_val_sequences//batch_size) + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xj_F8IVMmxff"
   },
   "source": [
    "Let us now fit the model. This will start training the model and with the help of the checkpoints, you'll be able to save the model at the end of each epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QYF2SSQtmxfh",
    "outputId": "5e024d26-ac4d-4614-a8c8-a8477b53f1b7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source path =  Project_data/valSource path =  Project_data/train ; batch size = 30\n",
      "Epoch 1/10\n",
      " ; batch size = 30\n",
      "23/23 [==============================] - 125s 5s/step - loss: 1.3112 - categorical_accuracy: 0.4532 - val_loss: 1.0593 - val_categorical_accuracy: 0.6133\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.05934, saving model to model_init_CNN_2020-11-0709_38_30.050657/model-00001-1.28882-0.46657-1.05934-0.61333.h5\n",
      "Epoch 2/10\n",
      "23/23 [==============================] - 10s 456ms/step - loss: 1.2311 - categorical_accuracy: 0.4783 - val_loss: 0.9083 - val_categorical_accuracy: 0.6250\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.05934 to 0.90826, saving model to model_init_CNN_2020-11-0709_38_30.050657/model-00002-1.23114-0.47826-0.90826-0.62500.h5\n",
      "Epoch 3/10\n",
      "23/23 [==============================] - 15s 651ms/step - loss: 1.6802 - categorical_accuracy: 0.3913 - val_loss: 1.4239 - val_categorical_accuracy: 0.3917\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.90826\n",
      "Epoch 4/10\n",
      "23/23 [==============================] - 16s 707ms/step - loss: 1.2627 - categorical_accuracy: 0.4879 - val_loss: 1.4351 - val_categorical_accuracy: 0.3750\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.90826\n",
      "Epoch 5/10\n",
      "23/23 [==============================] - 16s 676ms/step - loss: 1.3372 - categorical_accuracy: 0.5169 - val_loss: 1.1487 - val_categorical_accuracy: 0.6083\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.90826\n",
      "Epoch 6/10\n",
      "23/23 [==============================] - 17s 736ms/step - loss: 1.2366 - categorical_accuracy: 0.5072 - val_loss: 1.1106 - val_categorical_accuracy: 0.5250\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.90826\n",
      "Epoch 7/10\n",
      "23/23 [==============================] - 15s 668ms/step - loss: 1.1251 - categorical_accuracy: 0.5411 - val_loss: 1.1303 - val_categorical_accuracy: 0.5667\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.90826\n",
      "\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 1.0000000474974512e-06.\n",
      "Epoch 8/10\n",
      "23/23 [==============================] - 16s 700ms/step - loss: 1.3423 - categorical_accuracy: 0.5314 - val_loss: 0.9172 - val_categorical_accuracy: 0.6500\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.90826\n",
      "Epoch 9/10\n",
      "23/23 [==============================] - 17s 735ms/step - loss: 1.0951 - categorical_accuracy: 0.5314 - val_loss: 1.1511 - val_categorical_accuracy: 0.5083\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.90826\n",
      "Epoch 10/10\n",
      "23/23 [==============================] - 15s 664ms/step - loss: 1.3290 - categorical_accuracy: 0.4976 - val_loss: 0.9955 - val_categorical_accuracy: 0.6417\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.90826\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f11b54fefd0>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 10\n",
    "num_epochs = 10\n",
    "model.fit_generator(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
    "                  callbacks=callbacks_list, validation_data=val_generator, \n",
    "                  validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing dropout layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write your model here\n",
    "feature_map=[8, 16, 32, 64, 128, 256] # we will expirment with different number of features for different layers\n",
    "dense_layer_size = [1000,500,5] # \n",
    "classes= 5\n",
    "input_shape = (frames, rows, cols, channels)\n",
    "model = Sequential()\n",
    "# add multiple convulation layers\n",
    "model.add(TimeDistributed(Conv2D(feature_map[0], (3, 3), strides=(2, 2),activation='relu', padding='same'), input_shape=input_shape))\n",
    "\n",
    "model.add(TimeDistributed(Conv2D(feature_map[1], (3,3),padding='same', activation='relu')))\n",
    "model.add(TimeDistributed(MaxPooling2D((2, 2), strides=(2, 2))))\n",
    "model.add(TimeDistributed(BatchNormalization()))\n",
    "\n",
    "model.add(TimeDistributed(Conv2D(feature_map[2], (3,3),padding='same', activation='relu')))\n",
    "model.add(TimeDistributed(MaxPooling2D((2, 2), strides=(2, 2))))\n",
    "model.add(TimeDistributed(BatchNormalization()))\n",
    "\n",
    "model.add(TimeDistributed(Conv2D(feature_map[3], (2,2),padding='same', activation='relu')))\n",
    "model.add(TimeDistributed(MaxPooling2D((2, 2), strides=(2, 2))))\n",
    "model.add(TimeDistributed(BatchNormalization()))\n",
    "\n",
    "model.add(TimeDistributed(Conv2D(feature_map[4], (2,2),padding='same', activation='relu')))\n",
    "model.add(TimeDistributed(MaxPooling2D((2, 2), strides=(2, 2))))\n",
    "model.add(TimeDistributed(BatchNormalization()))\n",
    "\n",
    "model.add(TimeDistributed(Flatten()))\n",
    "\n",
    "model.add(Dense(dense_layer_size[0], activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(dense_layer_size[1], activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "## using GRU as the RNN model along with softmax as our last layer.\n",
    "model.add(GRU(128, return_sequences=False))\n",
    "model.add(Dense(classes, activation='softmax')) # using Softmax as last layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "time_distributed_44 (TimeDis (None, 30, 60, 60, 8)     224       \n",
      "_________________________________________________________________\n",
      "time_distributed_45 (TimeDis (None, 30, 60, 60, 16)    1168      \n",
      "_________________________________________________________________\n",
      "time_distributed_46 (TimeDis (None, 30, 30, 30, 16)    0         \n",
      "_________________________________________________________________\n",
      "time_distributed_47 (TimeDis (None, 30, 30, 30, 16)    64        \n",
      "_________________________________________________________________\n",
      "time_distributed_48 (TimeDis (None, 30, 30, 30, 32)    4640      \n",
      "_________________________________________________________________\n",
      "time_distributed_49 (TimeDis (None, 30, 15, 15, 32)    0         \n",
      "_________________________________________________________________\n",
      "time_distributed_50 (TimeDis (None, 30, 15, 15, 32)    128       \n",
      "_________________________________________________________________\n",
      "time_distributed_51 (TimeDis (None, 30, 15, 15, 64)    8256      \n",
      "_________________________________________________________________\n",
      "time_distributed_52 (TimeDis (None, 30, 7, 7, 64)      0         \n",
      "_________________________________________________________________\n",
      "time_distributed_53 (TimeDis (None, 30, 7, 7, 64)      256       \n",
      "_________________________________________________________________\n",
      "time_distributed_54 (TimeDis (None, 30, 7, 7, 128)     32896     \n",
      "_________________________________________________________________\n",
      "time_distributed_55 (TimeDis (None, 30, 3, 3, 128)     0         \n",
      "_________________________________________________________________\n",
      "time_distributed_56 (TimeDis (None, 30, 3, 3, 128)     512       \n",
      "_________________________________________________________________\n",
      "time_distributed_57 (TimeDis (None, 30, 1152)          0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 30, 1000)          1153000   \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 30, 1000)          0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 30, 500)           500500    \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 30, 500)           0         \n",
      "_________________________________________________________________\n",
      "gru_2 (GRU)                  (None, 128)               241536    \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 5)                 645       \n",
      "=================================================================\n",
      "Total params: 1,943,825\n",
      "Trainable params: 1,943,345\n",
      "Non-trainable params: 480\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "optimiser = optimizers.Adam(0.001) #write your optimizer\n",
    "model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "print (model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = generator(train_path, train_doc, batch_size)\n",
    "val_generator = generator(val_path, val_doc, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/keras/callbacks.py:999: UserWarning: `epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n",
      "  warnings.warn('`epsilon` argument is deprecated and '\n"
     ]
    }
   ],
   "source": [
    "model_name = 'model_init_CNN' + '_' + str(curr_dt_time).replace(' ','').replace(':','_') + '/'\n",
    "    \n",
    "if not os.path.exists(model_name):\n",
    "    os.mkdir(model_name)\n",
    "        \n",
    "filepath = model_name + 'model-{epoch:05d}-{loss:.5f}-{categorical_accuracy:.5f}-{val_loss:.5f}-{val_categorical_accuracy:.5f}.h5'\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath, save_best_only=True, monitor='val_loss', verbose=1, save_weights_only=False, mode='auto', period=1)\n",
    "\n",
    "LR = ReduceLROnPlateau(monitor='val_loss', factor=0.001, patience=5, cooldown=4, verbose=1,mode='auto',epsilon=0.0001)# write the REducelronplateau code here\n",
    "callbacks_list = [checkpoint, LR]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (num_train_sequences%batch_size) == 0:\n",
    "    steps_per_epoch = int(num_train_sequences/batch_size)\n",
    "else:\n",
    "    steps_per_epoch = (num_train_sequences//batch_size) + 1\n",
    "\n",
    "if (num_val_sequences%batch_size) == 0:\n",
    "    validation_steps = int(num_val_sequences/batch_size)\n",
    "else:\n",
    "    validation_steps = (num_val_sequences//batch_size) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source path =  Project_data/val ; batch size = 10\n",
      "Source path =  Project_data/train Epoch 1/20\n",
      "; batch size = 10\n",
      "67/67 [==============================] - 124s 2s/step - loss: 1.2078 - categorical_accuracy: 0.5205 - val_loss: 1.4374 - val_categorical_accuracy: 0.4833\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.43737, saving model to model_init_CNN_2020-11-0709_38_30.050657/model-00001-1.21494-0.51785-1.43737-0.48333.h5\n",
      "Epoch 2/20\n",
      "67/67 [==============================] - 40s 592ms/step - loss: 1.2385 - categorical_accuracy: 0.5506 - val_loss: 1.3015 - val_categorical_accuracy: 0.5033\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.43737 to 1.30148, saving model to model_init_CNN_2020-11-0709_38_30.050657/model-00002-1.23845-0.55058-1.30148-0.50333.h5\n",
      "Epoch 3/20\n",
      "67/67 [==============================] - 44s 652ms/step - loss: 1.0254 - categorical_accuracy: 0.6053 - val_loss: 1.6796 - val_categorical_accuracy: 0.3400\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1.30148\n",
      "Epoch 4/20\n",
      "67/67 [==============================] - 46s 688ms/step - loss: 1.1438 - categorical_accuracy: 0.5705 - val_loss: 1.2130 - val_categorical_accuracy: 0.5167\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.30148 to 1.21302, saving model to model_init_CNN_2020-11-0709_38_30.050657/model-00004-1.14380-0.57048-1.21302-0.51667.h5\n",
      "Epoch 5/20\n",
      "67/67 [==============================] - 45s 676ms/step - loss: 0.9033 - categorical_accuracy: 0.6750 - val_loss: 0.8917 - val_categorical_accuracy: 0.6600\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.21302 to 0.89166, saving model to model_init_CNN_2020-11-0709_38_30.050657/model-00005-0.90329-0.67496-0.89166-0.66000.h5\n",
      "Epoch 6/20\n",
      "67/67 [==============================] - 43s 649ms/step - loss: 0.8974 - categorical_accuracy: 0.6633 - val_loss: 0.8734 - val_categorical_accuracy: 0.7233\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.89166 to 0.87341, saving model to model_init_CNN_2020-11-0709_38_30.050657/model-00006-0.89743-0.66335-0.87341-0.72333.h5\n",
      "Epoch 7/20\n",
      "67/67 [==============================] - 44s 662ms/step - loss: 0.8698 - categorical_accuracy: 0.6799 - val_loss: 1.0827 - val_categorical_accuracy: 0.5900\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.87341\n",
      "Epoch 8/20\n",
      "67/67 [==============================] - 46s 682ms/step - loss: 0.8217 - categorical_accuracy: 0.6899 - val_loss: 1.0128 - val_categorical_accuracy: 0.6067\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.87341\n",
      "Epoch 9/20\n",
      "67/67 [==============================] - 45s 674ms/step - loss: 0.8683 - categorical_accuracy: 0.6567 - val_loss: 0.9591 - val_categorical_accuracy: 0.6467\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.87341\n",
      "Epoch 10/20\n",
      "67/67 [==============================] - 45s 670ms/step - loss: 0.6967 - categorical_accuracy: 0.7678 - val_loss: 1.2681 - val_categorical_accuracy: 0.5100\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.87341\n",
      "Epoch 11/20\n",
      "67/67 [==============================] - 43s 647ms/step - loss: 0.8759 - categorical_accuracy: 0.7048 - val_loss: 0.7231 - val_categorical_accuracy: 0.7500\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.87341 to 0.72313, saving model to model_init_CNN_2020-11-0709_38_30.050657/model-00011-0.87590-0.70481-0.72313-0.75000.h5\n",
      "Epoch 12/20\n",
      "67/67 [==============================] - 45s 676ms/step - loss: 0.5730 - categorical_accuracy: 0.8159 - val_loss: 0.8050 - val_categorical_accuracy: 0.6967\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.72313\n",
      "Epoch 13/20\n",
      "67/67 [==============================] - 44s 660ms/step - loss: 0.7516 - categorical_accuracy: 0.7612 - val_loss: 1.1016 - val_categorical_accuracy: 0.6100\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.72313\n",
      "Epoch 14/20\n",
      "67/67 [==============================] - 46s 684ms/step - loss: 0.6927 - categorical_accuracy: 0.7529 - val_loss: 0.7662 - val_categorical_accuracy: 0.7333\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.72313\n",
      "Epoch 15/20\n",
      "67/67 [==============================] - 43s 643ms/step - loss: 0.5996 - categorical_accuracy: 0.7927 - val_loss: 0.8508 - val_categorical_accuracy: 0.6900\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.72313\n",
      "Epoch 16/20\n",
      "67/67 [==============================] - 47s 694ms/step - loss: 0.6098 - categorical_accuracy: 0.7993 - val_loss: 1.1002 - val_categorical_accuracy: 0.6300\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.72313\n",
      "\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 1.0000000474974512e-06.\n",
      "Epoch 17/20\n",
      "67/67 [==============================] - 43s 637ms/step - loss: 0.7787 - categorical_accuracy: 0.7114 - val_loss: 0.9370 - val_categorical_accuracy: 0.6600\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.72313\n",
      "Epoch 18/20\n",
      "67/67 [==============================] - 44s 659ms/step - loss: 0.6341 - categorical_accuracy: 0.7479 - val_loss: 0.8274 - val_categorical_accuracy: 0.6767\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.72313\n",
      "Epoch 19/20\n",
      "67/67 [==============================] - 45s 673ms/step - loss: 0.6332 - categorical_accuracy: 0.7745 - val_loss: 0.8051 - val_categorical_accuracy: 0.7033\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.72313\n",
      "Epoch 20/20\n",
      "67/67 [==============================] - 43s 639ms/step - loss: 0.6403 - categorical_accuracy: 0.7711 - val_loss: 0.7981 - val_categorical_accuracy: 0.7067\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.72313\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f11afa292e8>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 10\n",
    "num_epochs = 20\n",
    "model.fit_generator(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
    "                  callbacks=callbacks_list, validation_data=val_generator, \n",
    "                  validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### change image size to 84X84"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write your model here\n",
    "feature_map=[8, 16, 32, 64, 128, 256] # we will expirment with different number of features for different layers\n",
    "dense_layer_size = [1000,500,5] # \n",
    "classes= 5\n",
    "rows = 84\n",
    "cols = 84\n",
    "\n",
    "input_shape = (frames, rows, cols, channels)\n",
    "\n",
    "model = Sequential()\n",
    "# add multiple convulation layers\n",
    "model.add(TimeDistributed(Conv2D(feature_map[0], (3, 3), strides=(2, 2),activation='relu', padding='same'), input_shape=input_shape))\n",
    "\n",
    "model.add(TimeDistributed(Conv2D(feature_map[1], (3,3),padding='same', activation='relu')))\n",
    "model.add(TimeDistributed(MaxPooling2D((2, 2), strides=(2, 2))))\n",
    "model.add(TimeDistributed(BatchNormalization()))\n",
    "\n",
    "model.add(TimeDistributed(Conv2D(feature_map[2], (3,3),padding='same', activation='relu')))\n",
    "model.add(TimeDistributed(MaxPooling2D((2, 2), strides=(2, 2))))\n",
    "model.add(TimeDistributed(BatchNormalization()))\n",
    "\n",
    "model.add(TimeDistributed(Conv2D(feature_map[3], (2,2),padding='same', activation='relu')))\n",
    "model.add(TimeDistributed(MaxPooling2D((2, 2), strides=(2, 2))))\n",
    "model.add(TimeDistributed(BatchNormalization()))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(TimeDistributed(Conv2D(feature_map[4], (2,2),padding='same', activation='relu')))\n",
    "model.add(TimeDistributed(MaxPooling2D((2, 2), strides=(2, 2))))\n",
    "model.add(TimeDistributed(BatchNormalization()))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(TimeDistributed(Flatten()))\n",
    "\n",
    "model.add(Dense(dense_layer_size[0], activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(dense_layer_size[1], activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "## using GRU as the RNN model along with softmax as our last layer.\n",
    "model.add(GRU(128, return_sequences=False))\n",
    "model.add(Dense(classes, activation='softmax')) # using Softmax as last layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "time_distributed_58 (TimeDis (None, 30, 42, 42, 8)     224       \n",
      "_________________________________________________________________\n",
      "time_distributed_59 (TimeDis (None, 30, 42, 42, 16)    1168      \n",
      "_________________________________________________________________\n",
      "time_distributed_60 (TimeDis (None, 30, 21, 21, 16)    0         \n",
      "_________________________________________________________________\n",
      "time_distributed_61 (TimeDis (None, 30, 21, 21, 16)    64        \n",
      "_________________________________________________________________\n",
      "time_distributed_62 (TimeDis (None, 30, 21, 21, 32)    4640      \n",
      "_________________________________________________________________\n",
      "time_distributed_63 (TimeDis (None, 30, 10, 10, 32)    0         \n",
      "_________________________________________________________________\n",
      "time_distributed_64 (TimeDis (None, 30, 10, 10, 32)    128       \n",
      "_________________________________________________________________\n",
      "time_distributed_65 (TimeDis (None, 30, 10, 10, 64)    8256      \n",
      "_________________________________________________________________\n",
      "time_distributed_66 (TimeDis (None, 30, 5, 5, 64)      0         \n",
      "_________________________________________________________________\n",
      "time_distributed_67 (TimeDis (None, 30, 5, 5, 64)      256       \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 30, 5, 5, 64)      0         \n",
      "_________________________________________________________________\n",
      "time_distributed_68 (TimeDis (None, 30, 5, 5, 128)     32896     \n",
      "_________________________________________________________________\n",
      "time_distributed_69 (TimeDis (None, 30, 2, 2, 128)     0         \n",
      "_________________________________________________________________\n",
      "time_distributed_70 (TimeDis (None, 30, 2, 2, 128)     512       \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 30, 2, 2, 128)     0         \n",
      "_________________________________________________________________\n",
      "time_distributed_71 (TimeDis (None, 30, 512)           0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 30, 1000)          513000    \n",
      "_________________________________________________________________\n",
      "dropout_18 (Dropout)         (None, 30, 1000)          0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 30, 500)           500500    \n",
      "_________________________________________________________________\n",
      "dropout_19 (Dropout)         (None, 30, 500)           0         \n",
      "_________________________________________________________________\n",
      "gru_3 (GRU)                  (None, 128)               241536    \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 5)                 645       \n",
      "=================================================================\n",
      "Total params: 1,303,825\n",
      "Trainable params: 1,303,345\n",
      "Non-trainable params: 480\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "optimiser = optimizers.Adam(0.001) #write your optimizer\n",
    "model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "print (model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = generator(train_path, train_doc, batch_size)\n",
    "val_generator = generator(val_path, val_doc, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/keras/callbacks.py:999: UserWarning: `epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n",
      "  warnings.warn('`epsilon` argument is deprecated and '\n"
     ]
    }
   ],
   "source": [
    "model_name = 'model_init_CNN' + '_' + str(curr_dt_time).replace(' ','').replace(':','_') + '/'\n",
    "    \n",
    "if not os.path.exists(model_name):\n",
    "    os.mkdir(model_name)\n",
    "        \n",
    "filepath = model_name + 'model-{epoch:05d}-{loss:.5f}-{categorical_accuracy:.5f}-{val_loss:.5f}-{val_categorical_accuracy:.5f}.h5'\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath, save_best_only=True, monitor='val_loss', verbose=1, save_weights_only=False, mode='auto', period=1)\n",
    "\n",
    "LR = ReduceLROnPlateau(monitor='val_loss', factor=0.001, patience=5, cooldown=4, verbose=1,mode='auto',epsilon=0.0001)# write the REducelronplateau code here\n",
    "callbacks_list = [checkpoint, LR]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (num_train_sequences%batch_size) == 0:\n",
    "    steps_per_epoch = int(num_train_sequences/batch_size)\n",
    "else:\n",
    "    steps_per_epoch = (num_train_sequences//batch_size) + 1\n",
    "\n",
    "if (num_val_sequences%batch_size) == 0:\n",
    "    validation_steps = int(num_val_sequences/batch_size)\n",
    "else:\n",
    "    validation_steps = (num_val_sequences//batch_size) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source path =  Project_data/val ; batch size = 10\n",
      "Source path =  Project_data/train ; batch size = 10\n",
      "Epoch 1/20\n",
      "67/67 [==============================] - 96s 1s/step - loss: 1.3398 - categorical_accuracy: 0.4580 - val_loss: 1.1101 - val_categorical_accuracy: 0.6100\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.11010, saving model to model_init_CNN_2020-11-0709_38_30.050657/model-00001-1.34024-0.45701-1.11010-0.61000.h5\n",
      "Epoch 2/20\n",
      "67/67 [==============================] - 31s 466ms/step - loss: 1.2500 - categorical_accuracy: 0.5423 - val_loss: 1.4793 - val_categorical_accuracy: 0.4300\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 1.11010\n",
      "Epoch 3/20\n",
      "67/67 [==============================] - 34s 512ms/step - loss: 1.1572 - categorical_accuracy: 0.5638 - val_loss: 1.1234 - val_categorical_accuracy: 0.5500\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1.11010\n",
      "Epoch 4/20\n",
      "67/67 [==============================] - 36s 532ms/step - loss: 1.1537 - categorical_accuracy: 0.5638 - val_loss: 0.9708 - val_categorical_accuracy: 0.6300\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.11010 to 0.97082, saving model to model_init_CNN_2020-11-0709_38_30.050657/model-00004-1.15372-0.56385-0.97082-0.63000.h5\n",
      "Epoch 5/20\n",
      "67/67 [==============================] - 33s 496ms/step - loss: 1.0833 - categorical_accuracy: 0.5390 - val_loss: 0.8937 - val_categorical_accuracy: 0.6767\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.97082 to 0.89370, saving model to model_init_CNN_2020-11-0709_38_30.050657/model-00005-1.08330-0.53897-0.89370-0.67667.h5\n",
      "Epoch 6/20\n",
      "67/67 [==============================] - 33s 497ms/step - loss: 0.8315 - categorical_accuracy: 0.6965 - val_loss: 0.8906 - val_categorical_accuracy: 0.6733\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.89370 to 0.89060, saving model to model_init_CNN_2020-11-0709_38_30.050657/model-00006-0.83149-0.69652-0.89060-0.67333.h5\n",
      "Epoch 7/20\n",
      "67/67 [==============================] - 36s 542ms/step - loss: 0.8179 - categorical_accuracy: 0.7048 - val_loss: 0.7705 - val_categorical_accuracy: 0.7133\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.89060 to 0.77050, saving model to model_init_CNN_2020-11-0709_38_30.050657/model-00007-0.81786-0.70481-0.77050-0.71333.h5\n",
      "Epoch 8/20\n",
      "67/67 [==============================] - 36s 531ms/step - loss: 0.7867 - categorical_accuracy: 0.7032 - val_loss: 1.3618 - val_categorical_accuracy: 0.5200\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.77050\n",
      "Epoch 9/20\n",
      "67/67 [==============================] - 35s 526ms/step - loss: 0.6913 - categorical_accuracy: 0.7662 - val_loss: 1.6345 - val_categorical_accuracy: 0.4633\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.77050\n",
      "Epoch 10/20\n",
      "67/67 [==============================] - 36s 540ms/step - loss: 0.8210 - categorical_accuracy: 0.6915 - val_loss: 0.8187 - val_categorical_accuracy: 0.6833\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.77050\n",
      "Epoch 11/20\n",
      "67/67 [==============================] - 34s 512ms/step - loss: 0.7259 - categorical_accuracy: 0.7380 - val_loss: 1.4881 - val_categorical_accuracy: 0.4200\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.77050\n",
      "Epoch 12/20\n",
      "67/67 [==============================] - 36s 536ms/step - loss: 0.5887 - categorical_accuracy: 0.7662 - val_loss: 1.3031 - val_categorical_accuracy: 0.5533\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.77050\n",
      "\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 1.0000000474974512e-06.\n",
      "Epoch 13/20\n",
      "67/67 [==============================] - 32s 483ms/step - loss: 0.5037 - categorical_accuracy: 0.8143 - val_loss: 0.8421 - val_categorical_accuracy: 0.7033\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.77050\n",
      "Epoch 14/20\n",
      "67/67 [==============================] - 37s 557ms/step - loss: 0.5827 - categorical_accuracy: 0.7927 - val_loss: 0.6786 - val_categorical_accuracy: 0.7767\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.77050 to 0.67859, saving model to model_init_CNN_2020-11-0709_38_30.050657/model-00014-0.58268-0.79270-0.67859-0.77667.h5\n",
      "Epoch 15/20\n",
      "67/67 [==============================] - 35s 517ms/step - loss: 0.5096 - categorical_accuracy: 0.8242 - val_loss: 0.6440 - val_categorical_accuracy: 0.7667\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.67859 to 0.64405, saving model to model_init_CNN_2020-11-0709_38_30.050657/model-00015-0.50958-0.82421-0.64405-0.76667.h5\n",
      "Epoch 16/20\n",
      "67/67 [==============================] - 35s 529ms/step - loss: 0.4915 - categorical_accuracy: 0.8325 - val_loss: 0.6351 - val_categorical_accuracy: 0.7833\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.64405 to 0.63513, saving model to model_init_CNN_2020-11-0709_38_30.050657/model-00016-0.49148-0.83250-0.63513-0.78333.h5\n",
      "Epoch 17/20\n",
      "67/67 [==============================] - 36s 530ms/step - loss: 0.5194 - categorical_accuracy: 0.8176 - val_loss: 0.6219 - val_categorical_accuracy: 0.7700\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.63513 to 0.62193, saving model to model_init_CNN_2020-11-0709_38_30.050657/model-00017-0.51938-0.81758-0.62193-0.77000.h5\n",
      "Epoch 18/20\n",
      "67/67 [==============================] - 34s 500ms/step - loss: 0.4670 - categorical_accuracy: 0.8474 - val_loss: 0.6160 - val_categorical_accuracy: 0.7567\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.62193 to 0.61599, saving model to model_init_CNN_2020-11-0709_38_30.050657/model-00018-0.46702-0.84743-0.61599-0.75667.h5\n",
      "Epoch 19/20\n",
      "67/67 [==============================] - 33s 492ms/step - loss: 0.5533 - categorical_accuracy: 0.7927 - val_loss: 0.6150 - val_categorical_accuracy: 0.7633\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.61599 to 0.61501, saving model to model_init_CNN_2020-11-0709_38_30.050657/model-00019-0.55330-0.79270-0.61501-0.76333.h5\n",
      "Epoch 20/20\n",
      "67/67 [==============================] - 35s 526ms/step - loss: 0.5008 - categorical_accuracy: 0.8358 - val_loss: 0.6299 - val_categorical_accuracy: 0.7433\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.61501\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f1197d32eb8>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 10\n",
    "num_epochs = 20\n",
    "model.fit_generator(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
    "                  callbacks=callbacks_list, validation_data=val_generator, \n",
    "                  validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding one more dense layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    " # reset image size to 120*120\n",
    "rows = 120\n",
    "cols = 120"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write your model here\n",
    "feature_map=[8, 16, 32, 64, 128, 256] # we will expirment with different number of features for different layers\n",
    "dense_layer_size = [1000, 500, 250, 5] # \n",
    "classes= 5\n",
    "\n",
    "input_shape = (frames, rows, cols, channels)\n",
    "\n",
    "model = Sequential()\n",
    "# add multiple convulation layers\n",
    "model.add(TimeDistributed(Conv2D(feature_map[0], (3, 3), strides=(2, 2),activation='relu', padding='same'), input_shape=input_shape))\n",
    "\n",
    "model.add(TimeDistributed(Conv2D(feature_map[1], (3,3),padding='same', activation='relu')))\n",
    "model.add(TimeDistributed(MaxPooling2D((2, 2), strides=(2, 2))))\n",
    "model.add(TimeDistributed(BatchNormalization()))\n",
    "\n",
    "model.add(TimeDistributed(Conv2D(feature_map[2], (3,3),padding='same', activation='relu')))\n",
    "model.add(TimeDistributed(MaxPooling2D((2, 2), strides=(2, 2))))\n",
    "model.add(TimeDistributed(BatchNormalization()))\n",
    "\n",
    "model.add(TimeDistributed(Conv2D(feature_map[3], (2,2),padding='same', activation='relu')))\n",
    "model.add(TimeDistributed(MaxPooling2D((2, 2), strides=(2, 2))))\n",
    "model.add(TimeDistributed(BatchNormalization()))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(TimeDistributed(Conv2D(feature_map[4], (2,2),padding='same', activation='relu')))\n",
    "model.add(TimeDistributed(MaxPooling2D((2, 2), strides=(2, 2))))\n",
    "model.add(TimeDistributed(BatchNormalization()))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(TimeDistributed(Flatten()))\n",
    "\n",
    "model.add(Dense(dense_layer_size[0], activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(dense_layer_size[1], activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(dense_layer_size[2], activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "## using GRU as the RNN model along with softmax as our last layer.\n",
    "model.add(GRU(128, return_sequences=False))\n",
    "model.add(Dense(classes, activation='softmax')) # using Softmax as last layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "time_distributed_72 (TimeDis (None, 30, 60, 60, 8)     224       \n",
      "_________________________________________________________________\n",
      "time_distributed_73 (TimeDis (None, 30, 60, 60, 16)    1168      \n",
      "_________________________________________________________________\n",
      "time_distributed_74 (TimeDis (None, 30, 30, 30, 16)    0         \n",
      "_________________________________________________________________\n",
      "time_distributed_75 (TimeDis (None, 30, 30, 30, 16)    64        \n",
      "_________________________________________________________________\n",
      "time_distributed_76 (TimeDis (None, 30, 30, 30, 32)    4640      \n",
      "_________________________________________________________________\n",
      "time_distributed_77 (TimeDis (None, 30, 15, 15, 32)    0         \n",
      "_________________________________________________________________\n",
      "time_distributed_78 (TimeDis (None, 30, 15, 15, 32)    128       \n",
      "_________________________________________________________________\n",
      "time_distributed_79 (TimeDis (None, 30, 15, 15, 64)    8256      \n",
      "_________________________________________________________________\n",
      "time_distributed_80 (TimeDis (None, 30, 7, 7, 64)      0         \n",
      "_________________________________________________________________\n",
      "time_distributed_81 (TimeDis (None, 30, 7, 7, 64)      256       \n",
      "_________________________________________________________________\n",
      "dropout_20 (Dropout)         (None, 30, 7, 7, 64)      0         \n",
      "_________________________________________________________________\n",
      "time_distributed_82 (TimeDis (None, 30, 7, 7, 128)     32896     \n",
      "_________________________________________________________________\n",
      "time_distributed_83 (TimeDis (None, 30, 3, 3, 128)     0         \n",
      "_________________________________________________________________\n",
      "time_distributed_84 (TimeDis (None, 30, 3, 3, 128)     512       \n",
      "_________________________________________________________________\n",
      "dropout_21 (Dropout)         (None, 30, 3, 3, 128)     0         \n",
      "_________________________________________________________________\n",
      "time_distributed_85 (TimeDis (None, 30, 1152)          0         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 30, 1000)          1153000   \n",
      "_________________________________________________________________\n",
      "dropout_22 (Dropout)         (None, 30, 1000)          0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 30, 500)           500500    \n",
      "_________________________________________________________________\n",
      "dropout_23 (Dropout)         (None, 30, 500)           0         \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 30, 250)           125250    \n",
      "_________________________________________________________________\n",
      "dropout_24 (Dropout)         (None, 30, 250)           0         \n",
      "_________________________________________________________________\n",
      "gru_4 (GRU)                  (None, 128)               145536    \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 5)                 645       \n",
      "=================================================================\n",
      "Total params: 1,973,075\n",
      "Trainable params: 1,972,595\n",
      "Non-trainable params: 480\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "optimiser = optimizers.Adam(0.001) #write your optimizer\n",
    "model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "print (model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = generator(train_path, train_doc, batch_size)\n",
    "val_generator = generator(val_path, val_doc, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/keras/callbacks.py:999: UserWarning: `epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n",
      "  warnings.warn('`epsilon` argument is deprecated and '\n"
     ]
    }
   ],
   "source": [
    "model_name = 'model_init_CNN' + '_' + str(curr_dt_time).replace(' ','').replace(':','_') + '/'\n",
    "    \n",
    "if not os.path.exists(model_name):\n",
    "    os.mkdir(model_name)\n",
    "        \n",
    "filepath = model_name + 'model-{epoch:05d}-{loss:.5f}-{categorical_accuracy:.5f}-{val_loss:.5f}-{val_categorical_accuracy:.5f}.h5'\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath, save_best_only=True, monitor='val_loss', verbose=1, save_weights_only=False, mode='auto', period=1)\n",
    "\n",
    "LR = ReduceLROnPlateau(monitor='val_loss', factor=0.001, patience=5, cooldown=4, verbose=1,mode='auto',epsilon=0.0001)# write the REducelronplateau code here\n",
    "callbacks_list = [checkpoint, LR]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (num_train_sequences%batch_size) == 0:\n",
    "    steps_per_epoch = int(num_train_sequences/batch_size)\n",
    "else:\n",
    "    steps_per_epoch = (num_train_sequences//batch_size) + 1\n",
    "\n",
    "if (num_val_sequences%batch_size) == 0:\n",
    "    validation_steps = int(num_val_sequences/batch_size)\n",
    "else:\n",
    "    validation_steps = (num_val_sequences//batch_size) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source path = Source path =  Project_data/train Epoch 1/20\n",
      " Project_data/val ; batch size = 10\n",
      "; batch size = 10\n",
      "67/67 [==============================] - 123s 2s/step - loss: 1.2514 - categorical_accuracy: 0.4749 - val_loss: 1.2791 - val_categorical_accuracy: 0.6167\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.27908, saving model to model_init_CNN_2020-11-0709_38_30.050657/model-00001-1.26011-0.47059-1.27908-0.61667.h5\n",
      "Epoch 2/20\n",
      "67/67 [==============================] - 41s 615ms/step - loss: 1.3051 - categorical_accuracy: 0.5456 - val_loss: 1.4970 - val_categorical_accuracy: 0.3667\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 1.27908\n",
      "Epoch 3/20\n",
      "67/67 [==============================] - 44s 653ms/step - loss: 1.2339 - categorical_accuracy: 0.4959 - val_loss: 1.2382 - val_categorical_accuracy: 0.4633\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.27908 to 1.23815, saving model to model_init_CNN_2020-11-0709_38_30.050657/model-00003-1.23393-0.49585-1.23815-0.46333.h5\n",
      "Epoch 4/20\n",
      "67/67 [==============================] - 45s 668ms/step - loss: 1.1072 - categorical_accuracy: 0.5605 - val_loss: 1.5207 - val_categorical_accuracy: 0.3767\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.23815\n",
      "Epoch 5/20\n",
      "67/67 [==============================] - 41s 618ms/step - loss: 1.0898 - categorical_accuracy: 0.5788 - val_loss: 1.3999 - val_categorical_accuracy: 0.4500\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1.23815\n",
      "Epoch 6/20\n",
      "67/67 [==============================] - 45s 668ms/step - loss: 1.0637 - categorical_accuracy: 0.6020 - val_loss: 1.1233 - val_categorical_accuracy: 0.6000\n",
      "\n",
      "Epoch 00006: val_loss improved from 1.23815 to 1.12328, saving model to model_init_CNN_2020-11-0709_38_30.050657/model-00006-1.06371-0.60199-1.12328-0.60000.h5\n",
      "Epoch 7/20\n",
      "67/67 [==============================] - 44s 652ms/step - loss: 1.0048 - categorical_accuracy: 0.6401 - val_loss: 0.8931 - val_categorical_accuracy: 0.6633\n",
      "\n",
      "Epoch 00007: val_loss improved from 1.12328 to 0.89314, saving model to model_init_CNN_2020-11-0709_38_30.050657/model-00007-1.00478-0.64013-0.89314-0.66333.h5\n",
      "Epoch 8/20\n",
      "67/67 [==============================] - 44s 663ms/step - loss: 0.9124 - categorical_accuracy: 0.6401 - val_loss: 1.0192 - val_categorical_accuracy: 0.6400\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.89314\n",
      "Epoch 9/20\n",
      "67/67 [==============================] - 45s 675ms/step - loss: 0.8266 - categorical_accuracy: 0.6949 - val_loss: 0.9891 - val_categorical_accuracy: 0.6500\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.89314\n",
      "Epoch 10/20\n",
      "67/67 [==============================] - 47s 701ms/step - loss: 0.9131 - categorical_accuracy: 0.6700 - val_loss: 1.3168 - val_categorical_accuracy: 0.5200\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.89314\n",
      "Epoch 11/20\n",
      "67/67 [==============================] - 44s 664ms/step - loss: 0.8134 - categorical_accuracy: 0.6998 - val_loss: 1.1792 - val_categorical_accuracy: 0.5467\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.89314\n",
      "Epoch 12/20\n",
      "67/67 [==============================] - 45s 671ms/step - loss: 0.6752 - categorical_accuracy: 0.7678 - val_loss: 1.0334 - val_categorical_accuracy: 0.6067\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.89314\n",
      "\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 1.0000000474974512e-06.\n",
      "Epoch 13/20\n",
      "67/67 [==============================] - 43s 646ms/step - loss: 0.6632 - categorical_accuracy: 0.7562 - val_loss: 0.9138 - val_categorical_accuracy: 0.6533\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.89314\n",
      "Epoch 14/20\n",
      "67/67 [==============================] - 45s 668ms/step - loss: 0.7058 - categorical_accuracy: 0.7396 - val_loss: 0.8800 - val_categorical_accuracy: 0.6567\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.89314 to 0.87998, saving model to model_init_CNN_2020-11-0709_38_30.050657/model-00014-0.70577-0.73964-0.87998-0.65667.h5\n",
      "Epoch 15/20\n",
      "67/67 [==============================] - 45s 676ms/step - loss: 0.7131 - categorical_accuracy: 0.7280 - val_loss: 0.8682 - val_categorical_accuracy: 0.6567\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.87998 to 0.86819, saving model to model_init_CNN_2020-11-0709_38_30.050657/model-00015-0.71311-0.72803-0.86819-0.65667.h5\n",
      "Epoch 16/20\n",
      "67/67 [==============================] - 43s 647ms/step - loss: 0.5808 - categorical_accuracy: 0.8126 - val_loss: 0.8579 - val_categorical_accuracy: 0.6633\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.86819 to 0.85794, saving model to model_init_CNN_2020-11-0709_38_30.050657/model-00016-0.58083-0.81260-0.85794-0.66333.h5\n",
      "Epoch 17/20\n",
      "67/67 [==============================] - 44s 651ms/step - loss: 0.6864 - categorical_accuracy: 0.7264 - val_loss: 0.8512 - val_categorical_accuracy: 0.6767\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.85794 to 0.85119, saving model to model_init_CNN_2020-11-0709_38_30.050657/model-00017-0.68643-0.72637-0.85119-0.67667.h5\n",
      "Epoch 18/20\n",
      "67/67 [==============================] - 44s 658ms/step - loss: 0.6366 - categorical_accuracy: 0.7695 - val_loss: 0.8446 - val_categorical_accuracy: 0.6767\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.85119 to 0.84459, saving model to model_init_CNN_2020-11-0709_38_30.050657/model-00018-0.63663-0.76949-0.84459-0.67667.h5\n",
      "Epoch 19/20\n",
      "67/67 [==============================] - 46s 691ms/step - loss: 0.6729 - categorical_accuracy: 0.7662 - val_loss: 0.8393 - val_categorical_accuracy: 0.6733\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.84459 to 0.83932, saving model to model_init_CNN_2020-11-0709_38_30.050657/model-00019-0.67291-0.76617-0.83932-0.67333.h5\n",
      "Epoch 20/20\n",
      "67/67 [==============================] - 43s 643ms/step - loss: 0.6762 - categorical_accuracy: 0.7695 - val_loss: 0.8439 - val_categorical_accuracy: 0.6733\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.83932\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f11ae0cb8d0>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 10\n",
    "num_epochs = 20\n",
    "model.fit_generator(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
    "                  callbacks=callbacks_list, validation_data=val_generator, \n",
    "                  validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0eCOFgTUmxfj"
   },
   "source": [
    "## Conv3D model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimiser SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filters = [8,16,32,64]\n",
    "dense = [256, 128, 5]\n",
    "\n",
    "# Input\n",
    "input_shape=(frames, rows, cols, channels)\n",
    "\n",
    "# Define model\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv3D(filters[0], \n",
    "                 kernel_size=(3,3,3), \n",
    "                 input_shape=input_shape,\n",
    "                 padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(MaxPooling3D(pool_size=(2,2,2)))\n",
    "\n",
    "model.add(Conv3D(filters[1], \n",
    "                 kernel_size=(3,3,3), \n",
    "                 padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(MaxPooling3D(pool_size=(2,2,2)))\n",
    "\n",
    "model.add(Conv3D(filters[2], \n",
    "                 kernel_size=(1,3,3), \n",
    "                 padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(MaxPooling3D(pool_size=(2,2,2)))\n",
    "\n",
    "model.add(Conv3D(filters[3], \n",
    "                 kernel_size=(1,3,3), \n",
    "                 padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(MaxPooling3D(pool_size=(2,2,2)))\n",
    "\n",
    "#Flatten Layers\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(dense[0], activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(dense[1], activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "#softmax layer\n",
    "model.add(Dense(dense[2], activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimiser = optimizers.SGD() #write your optimizer\n",
    "model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "print (model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = generator(train_path, train_doc, batch_size)\n",
    "val_generator = generator(val_path, val_doc, batch_size,validation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'model_init_Conv3D' + '_' + str(curr_dt_time).replace(' ','').replace(':','_') + '/'\n",
    "    \n",
    "if not os.path.exists(model_name):\n",
    "    os.mkdir(model_name)\n",
    "        \n",
    "filepath = model_name + 'model-{epoch:05d}-{loss:.5f}-{categorical_accuracy:.5f}-{val_loss:.5f}-{val_categorical_accuracy:.5f}.h5'\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath, save_best_only=True, monitor='val_loss', verbose=1, save_weights_only=False, mode='auto', period=1)\n",
    "\n",
    "# write the Reducelronplateau code here\n",
    "LR = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, cooldown=1, verbose=1)\n",
    "callbacks_list = [checkpoint, LR]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (num_train_sequences%batch_size) == 0:\n",
    "    steps_per_epoch = int(num_train_sequences/batch_size)\n",
    "else:\n",
    "    steps_per_epoch = (num_train_sequences//batch_size) + 1\n",
    "\n",
    "if (num_val_sequences%batch_size) == 0:\n",
    "    validation_steps = int(num_val_sequences/batch_size)\n",
    "else:\n",
    "    validation_steps = (num_val_sequences//batch_size) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 10\n",
    "num_epochs = 10\n",
    "#model.fit_generator(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
    " #                   callbacks=callbacks_list, validation_data=val_generator, \n",
    "  #                  validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Increased Epochs and Adam optimiser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y6zFhT4ugNe6"
   },
   "outputs": [],
   "source": [
    "filters = [8,16,32,64]\n",
    "dense = [256, 128, 5]\n",
    "\n",
    "# Input\n",
    "input_shape=(frames, rows, cols, channels)\n",
    "\n",
    "# Define model\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv3D(filters[0], \n",
    "                 kernel_size=(3,3,3), \n",
    "                 input_shape=input_shape,\n",
    "                 padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(MaxPooling3D(pool_size=(2,2,2)))\n",
    "\n",
    "model.add(Conv3D(filters[1], \n",
    "                 kernel_size=(3,3,3), \n",
    "                 padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(MaxPooling3D(pool_size=(2,2,2)))\n",
    "\n",
    "model.add(Conv3D(filters[2], \n",
    "                 kernel_size=(1,3,3), \n",
    "                 padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(MaxPooling3D(pool_size=(2,2,2)))\n",
    "\n",
    "model.add(Conv3D(filters[3], \n",
    "                 kernel_size=(1,3,3), \n",
    "                 padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(MaxPooling3D(pool_size=(2,2,2)))\n",
    "\n",
    "#Flatten Layers\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(dense[0], activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(dense[1], activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "#softmax layer\n",
    "model.add(Dense(dense[2], activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimiser = optimizers.Adam() #write your optimizer\n",
    "model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "print (model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = generator(train_path, train_doc, batch_size)\n",
    "val_generator = generator(val_path, val_doc, batch_size,validation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'model_init_Conv3D' + '_' + str(curr_dt_time).replace(' ','').replace(':','_') + '/'\n",
    "    \n",
    "if not os.path.exists(model_name):\n",
    "    os.mkdir(model_name)\n",
    "        \n",
    "filepath = model_name + 'model-{epoch:05d}-{loss:.5f}-{categorical_accuracy:.5f}-{val_loss:.5f}-{val_categorical_accuracy:.5f}.h5'\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath, save_best_only=True, monitor='val_loss', verbose=1, save_weights_only=False, mode='auto', period=1)\n",
    "\n",
    "# write the Reducelronplateau code here\n",
    "LR = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, cooldown=1, verbose=1)\n",
    "callbacks_list = [checkpoint, LR]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (num_train_sequences%batch_size) == 0:\n",
    "    steps_per_epoch = int(num_train_sequences/batch_size)\n",
    "else:\n",
    "    steps_per_epoch = (num_train_sequences//batch_size) + 1\n",
    "\n",
    "if (num_val_sequences%batch_size) == 0:\n",
    "    validation_steps = int(num_val_sequences/batch_size)\n",
    "else:\n",
    "    validation_steps = (num_val_sequences//batch_size) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 10\n",
    "num_epochs = 20\n",
    "#model.fit_generator(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
    " #                   callbacks=callbacks_list, validation_data=val_generator, \n",
    "  #                  validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Increasing dense perceptrons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes= 5\n",
    "input_shape = (frames, rows, cols, channels)\n",
    "\n",
    "nb_filters = [8,16,32,64]\n",
    "nb_dense = [1000, 500, 5]\n",
    "\n",
    "# Define model\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv3D(nb_filters[0], \n",
    "                 kernel_size=(3,3,3), \n",
    "                 input_shape=input_shape,\n",
    "                 padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(MaxPooling3D(pool_size=(2,2,2)))\n",
    "\n",
    "model.add(Conv3D(nb_filters[1], \n",
    "                 kernel_size=(3,3,3), \n",
    "                 padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(MaxPooling3D(pool_size=(2,2,2)))\n",
    "\n",
    "model.add(Conv3D(nb_filters[2], \n",
    "                 kernel_size=(1,3,3), \n",
    "                 padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(MaxPooling3D(pool_size=(2,2,2)))\n",
    "\n",
    "model.add(Conv3D(nb_filters[3], \n",
    "                 kernel_size=(1,3,3), \n",
    "                 padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(MaxPooling3D(pool_size=(2,2,2)))\n",
    "\n",
    "#Flatten Layers\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(nb_dense[0], activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(nb_dense[1], activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "#softmax layer\n",
    "model.add(Dense(nb_dense[2], activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimiser = optimizers.Adam() #write your optimizer\n",
    "model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "print (model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = generator(train_path, train_doc, batch_size)\n",
    "val_generator = generator(val_path, val_doc, batch_size,validation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (num_train_sequences%batch_size) == 0:\n",
    "    steps_per_epoch = int(num_train_sequences/batch_size)\n",
    "else:\n",
    "    steps_per_epoch = (num_train_sequences//batch_size) + 1\n",
    "\n",
    "if (num_val_sequences%batch_size) == 0:\n",
    "    validation_steps = int(num_val_sequences/batch_size)\n",
    "else:\n",
    "    validation_steps = (num_val_sequences//batch_size) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 10\n",
    "num_epochs = 20\n",
    "#model.fit_generator(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
    " #                   callbacks=callbacks_list, validation_data=val_generator, \n",
    "  #                  validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding one extra layer with dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes= 5\n",
    "input_shape = (frames, rows, cols, channels)\n",
    "\n",
    "nb_filters = [8, 16, 32, 64, 128]\n",
    "nb_dense = [1000, 500, 5]\n",
    "\n",
    "# Define model\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv3D(nb_filters[0], \n",
    "                 kernel_size=(3,3,3), \n",
    "                 input_shape=input_shape,\n",
    "                 padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(MaxPooling3D(pool_size=(2,2,2)))\n",
    "\n",
    "model.add(Conv3D(nb_filters[1], \n",
    "                 kernel_size=(3,3,3), \n",
    "                 padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(MaxPooling3D(pool_size=(2,2,2)))\n",
    "\n",
    "model.add(Conv3D(nb_filters[2], \n",
    "                 kernel_size=(1,3,3), \n",
    "                 padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(MaxPooling3D(pool_size=(2,2,2)))\n",
    "\n",
    "model.add(Conv3D(nb_filters[3], \n",
    "                 kernel_size=(1,3,3), \n",
    "                 padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv3D(nb_filters[4], \n",
    "                 kernel_size=(1,3,3), \n",
    "                 padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(MaxPooling3D(pool_size=(2,2,2)))\n",
    "\n",
    "\n",
    "#Flatten Layers\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(nb_dense[0], activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(nb_dense[1], activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "#softmax layer\n",
    "model.add(Dense(nb_dense[2], activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimiser = optimizers.Adam() #write your optimizer\n",
    "model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "print (model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = generator(train_path, train_doc, batch_size)\n",
    "val_generator = generator(val_path, val_doc, batch_size,validation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (num_train_sequences%batch_size) == 0:\n",
    "    steps_per_epoch = int(num_train_sequences/batch_size)\n",
    "else:\n",
    "    steps_per_epoch = (num_train_sequences//batch_size) + 1\n",
    "\n",
    "if (num_val_sequences%batch_size) == 0:\n",
    "    validation_steps = int(num_val_sequences/batch_size)\n",
    "else:\n",
    "    validation_steps = (num_val_sequences//batch_size) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 10\n",
    "num_epochs = 20\n",
    "#model.fit_generator(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
    " #                   callbacks=callbacks_list, validation_data=val_generator, \n",
    "  #                  validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding one more layer with BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes= 5\n",
    "input_shape = (frames, rows, cols, channels)\n",
    "\n",
    "nb_filters = [8, 16, 32, 64, 128, 256]\n",
    "nb_dense = [1000, 500, 5]\n",
    "\n",
    "# Define model\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv3D(nb_filters[0], \n",
    "                 kernel_size=(3,3,3), \n",
    "                 input_shape=input_shape,\n",
    "                 padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(MaxPooling3D(pool_size=(2,2,2)))\n",
    "\n",
    "model.add(Conv3D(nb_filters[1], \n",
    "                 kernel_size=(3,3,3), \n",
    "                 padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(MaxPooling3D(pool_size=(2,2,2)))\n",
    "\n",
    "model.add(Conv3D(nb_filters[2], \n",
    "                 kernel_size=(1,3,3), \n",
    "                 padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Conv3D(nb_filters[3], \n",
    "                 kernel_size=(1,3,3), \n",
    "                 padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(MaxPooling3D(pool_size=(2,2,2)))\n",
    "\n",
    "model.add(Conv3D(nb_filters[4], \n",
    "                 kernel_size=(1,3,3), \n",
    "                 padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv3D(nb_filters[5], \n",
    "                 kernel_size=(1,3,3), \n",
    "                 padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(MaxPooling3D(pool_size=(2,2,2)))\n",
    "\n",
    "\n",
    "#Flatten Layers\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(nb_dense[0], activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(nb_dense[1], activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "#softmax layer\n",
    "model.add(Dense(nb_dense[2], activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimiser = optimizers.Adam() #write your optimizer\n",
    "model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "print (model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = generator(train_path, train_doc, batch_size)\n",
    "val_generator = generator(val_path, val_doc, batch_size,validation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (num_train_sequences%batch_size) == 0:\n",
    "    steps_per_epoch = int(num_train_sequences/batch_size)\n",
    "else:\n",
    "    steps_per_epoch = (num_train_sequences//batch_size) + 1\n",
    "\n",
    "if (num_val_sequences%batch_size) == 0:\n",
    "    validation_steps = int(num_val_sequences/batch_size)\n",
    "else:\n",
    "    validation_steps = (num_val_sequences//batch_size) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 10\n",
    "num_epochs = 20\n",
    "#model.fit_generator(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
    " #                   callbacks=callbacks_list, validation_data=val_generator, \n",
    "  #                  validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Neural_Nets_Project_Starter_Code.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
