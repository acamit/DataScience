{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VDqMakhdmxeZ"
   },
   "source": [
    "# Gesture Recognition\n",
    "In this group project, you are going to build a 3D Conv model that will be able to predict the 5 gestures correctly. Please import the following libraries to get started."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 3407,
     "status": "ok",
     "timestamp": 1604436126836,
     "user": {
      "displayName": "Amit Chawla",
      "photoUrl": "",
      "userId": "06080236380106251748"
     },
     "user_tz": -330
    },
    "id": "TQBPqv4tmxek"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# import libraries\n",
    "import numpy as np\n",
    "import os\n",
    "import datetime\n",
    "import os\n",
    "import keras\n",
    "from skimage import io\n",
    "from skimage.transform import rescale, resize\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter \n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tGWWjZmWmxem"
   },
   "source": [
    "We set the random seed so that the results don't vary drastically."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uIgjhwHP1K4S"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 3405,
     "status": "ok",
     "timestamp": 1604436126840,
     "user": {
      "displayName": "Amit Chawla",
      "photoUrl": "",
      "userId": "06080236380106251748"
     },
     "user_tz": -330
    },
    "id": "WMQ8D_b7mxen"
   },
   "outputs": [],
   "source": [
    "np.random.seed(30)\n",
    "import random as rn\n",
    "rn.seed(30)\n",
    "from keras import backend as K\n",
    "import tensorflow as tf\n",
    "tf.set_random_seed(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ElbM_EOhmxep"
   },
   "source": [
    "In this block, you read the folder names for training and validation. You also set the `batch_size` here. Note that you set the batch size in such a way that you are able to use the GPU in full capacity. You keep increasing the batch size until the machine throws an error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 3398,
     "status": "ok",
     "timestamp": 1604436126840,
     "user": {
      "displayName": "Amit Chawla",
      "photoUrl": "",
      "userId": "06080236380106251748"
     },
     "user_tz": -330
    },
    "id": "Ktl51Bgjmxeq"
   },
   "outputs": [],
   "source": [
    "train_doc = np.random.permutation(open('Project_data/train.csv').readlines())\n",
    "val_doc = np.random.permutation(open('Project_data/val.csv').readlines())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 3392,
     "status": "ok",
     "timestamp": 1604436126841,
     "user": {
      "displayName": "Amit Chawla",
      "photoUrl": "",
      "userId": "06080236380106251748"
     },
     "user_tz": -330
    },
    "id": "iXpH5G_Zmxes"
   },
   "outputs": [],
   "source": [
    "# we started with batch size = 663 and slowly optimised it to fit into our resources \n",
    "batch_size = 30 #experiment with the batch size\n",
    "frames = 30 #number of frames in each video \n",
    "# we start with 120*120 images and adjust these later for model building process\n",
    "rows = 120 # final image height to be decided\n",
    "cols = 120 # final image width to be decided\n",
    "channels = 3\n",
    "step_size = 1 #this will help in customising the frames chosen from the video for model building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 3381,
     "status": "ok",
     "timestamp": 1604436126841,
     "user": {
      "displayName": "Amit Chawla",
      "photoUrl": "",
      "userId": "06080236380106251748"
     },
     "user_tz": -330
    },
    "id": "13E1RyUxmxew"
   },
   "outputs": [],
   "source": [
    "# we distribute the images on the basis of size. This is just done for experiment puroposes later.\n",
    "# outpaths = [train_path] #val_path\n",
    "def image_segregation(path='train'):\n",
    "    final_120 =[]\n",
    "    final_360=[]\n",
    "    doc = ''\n",
    "    if(path=='train'):\n",
    "        op = 'Project_data/train/'\n",
    "        doc = train_doc\n",
    "    else:\n",
    "        op = 'Project_data/val/'\n",
    "        doc = val_doc\n",
    "    for f in doc:\n",
    "        path = f.split(';')[0]\n",
    "        imgs = os.listdir(op+path)\n",
    "        for img in imgs:\n",
    "            image = io.imread(op+path+'/'+img)\n",
    "            if(image.shape[0]==360):\n",
    "                final_120.append(op+path+'/'+img) \n",
    "\n",
    "            if(image.shape[0]==120):\n",
    "                final_360.append(op+path+'/'+img)\n",
    "    return (final_120, final_360)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 3376,
     "status": "ok",
     "timestamp": 1604436126842,
     "user": {
      "displayName": "Amit Chawla",
      "photoUrl": "",
      "userId": "06080236380106251748"
     },
     "user_tz": -330
    },
    "id": "HXYE041rmxey"
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-3b81c23fa536>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# make list of images with corresponding sizes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mfinal_120\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal_360\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage_segregation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-5-a0e8b1ba1faa>\u001b[0m in \u001b[0;36mimage_segregation\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mimgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mimg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mimgs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m             \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'/'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m             \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m360\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m                 \u001b[0mfinal_120\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'/'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/disks/user/anaconda3/lib/python3.6/site-packages/skimage/io/_io.py\u001b[0m in \u001b[0;36mimread\u001b[0;34m(fname, as_gray, plugin, flatten, **plugin_args)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mfile_or_url_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_plugin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'imread'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplugin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mplugin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mplugin_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ndim'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/disks/user/anaconda3/lib/python3.6/site-packages/skimage/io/manage_plugins.py\u001b[0m in \u001b[0;36mcall_plugin\u001b[0;34m(kind, *args, **kwargs)\u001b[0m\n\u001b[1;32m    212\u001b[0m                                (plugin, kind))\n\u001b[1;32m    213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 214\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    215\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/disks/user/anaconda3/lib/python3.6/site-packages/skimage/io/_plugins/pil_plugin.py\u001b[0m in \u001b[0;36mimread\u001b[0;34m(fname, dtype, img_num, **kwargs)\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstring_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m             \u001b[0mim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mpil_to_ndarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_num\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimg_num\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/disks/user/anaconda3/lib/python3.6/site-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode)\u001b[0m\n\u001b[1;32m   2641\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2642\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2643\u001b[0;31m     \u001b[0mprefix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2644\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2645\u001b[0m     \u001b[0mpreinit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# make list of images with corresponding sizes\n",
    "final_120, final_360 = image_segregation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 3370,
     "status": "ok",
     "timestamp": 1604436126842,
     "user": {
      "displayName": "Amit Chawla",
      "photoUrl": "",
      "userId": "06080236380106251748"
     },
     "user_tz": -330
    },
    "id": "wNbx3UeNmxe1"
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-12-508fdb70da94>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-12-508fdb70da94>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    view random imagees\u001b[0m\n\u001b[0m              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "view random imagees\n",
    "selectedIndexes  = []\n",
    "for i in range(3):\n",
    "    selectedIndexes.append(rn.randint(0,5520))\n",
    "\n",
    "\n",
    "s_im_120 = [final_120[i] for i in selectedIndexes]\n",
    "s_im_360 = [final_360[i] for i in selectedIndexes]\n",
    "print(s_im_120)\n",
    "print(s_im_360)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VwHEJ0ajmxe4"
   },
   "source": [
    "## Generator\n",
    "This is one of the most important part of the code. The overall structure of the generator has been given. In the generator, you are going to preprocess the images as you have images of 2 different dimensions as well as create a batch of video frames. You have to experiment with `img_idx`, `y`,`z` and normalization such that you get high accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "executionInfo": {
     "elapsed": 3362,
     "status": "ok",
     "timestamp": 1604436126842,
     "user": {
      "displayName": "Amit Chawla",
      "photoUrl": "",
      "userId": "06080236380106251748"
     },
     "user_tz": -330
    },
    "id": "bZVAwtRLmxe4"
   },
   "outputs": [],
   "source": [
    "# we have looked at random images from the set and decided the following dimensions for the images. This has helped to \n",
    "# remove the edges and preserve the center of the image where gesture data is present. \n",
    "def cropImage(image):\n",
    "    (image_h, image_w, _) = image.shape\n",
    "    print(image.shape)\n",
    "    h_start=0\n",
    "    h_end = image_h\n",
    "    w_start=0\n",
    "    w_end = image_w\n",
    "    # for images 120*160\n",
    "    if(image_h==120):\n",
    "        h_start=20\n",
    "        w_start=10\n",
    "        w_end = 120\n",
    "    # for images of size 360*360\n",
    "    elif image_h==360:\n",
    "        h_start=30\n",
    "        w_start=30\n",
    "        w_end = 320\n",
    "    return image[h_start:h_end, w_start:w_end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "executionInfo": {
     "elapsed": 3351,
     "status": "ok",
     "timestamp": 1604436126843,
     "user": {
      "displayName": "Amit Chawla",
      "photoUrl": "",
      "userId": "06080236380106251748"
     },
     "user_tz": -330
    },
    "id": "iPDq9Y_qmxe7"
   },
   "outputs": [],
   "source": [
    "# this method will adjust the size of the image to given dimensions. The appropriate size will be found through experments.\n",
    "def resize_image(image, height=rows, width=cols):\n",
    "    return  resize(image, (height, width),anti_aliasing=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "executionInfo": {
     "elapsed": 3344,
     "status": "ok",
     "timestamp": 1604436126844,
     "user": {
      "displayName": "Amit Chawla",
      "photoUrl": "",
      "userId": "06080236380106251748"
     },
     "user_tz": -330
    },
    "id": "VtA2DmeHmxe9"
   },
   "outputs": [],
   "source": [
    "# we try different normalization technique\n",
    "def normalize_image(image):\n",
    "    norm_image = image - np.min(image)/np.max(image) - np.min(image)\n",
    "#     norm_image = image - np.percentile(image,5)/ np.percentile(image,95) - np.percentile(image,5)\n",
    "    return norm_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "executionInfo": {
     "elapsed": 3334,
     "status": "ok",
     "timestamp": 1604436126844,
     "user": {
      "displayName": "Amit Chawla",
      "photoUrl": "",
      "userId": "06080236380106251748"
     },
     "user_tz": -330
    },
    "id": "qZT62WCDmxfA"
   },
   "outputs": [],
   "source": [
    "#utility to show processed images\n",
    "def showImage(array, idx):\n",
    "    a = array[idx]\n",
    "    image = io.imread(a)\n",
    "    plt.subplot(2, 2,1)\n",
    "    plt.imshow(image)\n",
    "\n",
    "    cropped = cropImage(image)\n",
    "    plt.subplot(2,2,2)\n",
    "    plt.imshow(cropped)\n",
    "\n",
    "    resized = resize_image(cropped)\n",
    "    plt.subplot(2, 2,3)\n",
    "    plt.imshow(resized)\n",
    "\n",
    "    \n",
    "    normalized = normalize_image(resized)\n",
    "    plt.subplot(2, 2,4)\n",
    "    plt.imshow(normalized)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "executionInfo": {
     "elapsed": 3327,
     "status": "ok",
     "timestamp": 1604436126845,
     "user": {
      "displayName": "Amit Chawla",
      "photoUrl": "",
      "userId": "06080236380106251748"
     },
     "user_tz": -330
    },
    "id": "K7tnO7qMmxfE"
   },
   "outputs": [],
   "source": [
    "#plt.figure(figsize=(300,300))\n",
    "#showImage(s_im_360, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "executionInfo": {
     "elapsed": 3320,
     "status": "ok",
     "timestamp": 1604436126845,
     "user": {
      "displayName": "Amit Chawla",
      "photoUrl": "",
      "userId": "06080236380106251748"
     },
     "user_tz": -330
    },
    "id": "BsJO0HlMmxfG"
   },
   "outputs": [],
   "source": [
    "# view random images\n",
    "#plt.figure(figsize=(300,300))\n",
    "#showImage(s_im_120, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to generate a random affine transform on the iamge\n",
    "def get_random_affine():\n",
    "    dx, dy = np.random.randint(-1.7, 1.8, 2)\n",
    "    M = np.float32([[1, 0, dx], [0, 1, dy]])\n",
    "    return M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to initialize all the batch image data and labels\n",
    "def init_batch_data(batch_size):\n",
    "    batch_data = np.zeros((batch_size, frames, rows, cols, channels)) \n",
    "    batch_labels = np.zeros((batch_size,5)) # batch_labels is the one hot representation of the output\n",
    "    return batch_data, batch_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "executionInfo": {
     "elapsed": 3313,
     "status": "ok",
     "timestamp": 1604436126846,
     "user": {
      "displayName": "Amit Chawla",
      "photoUrl": "",
      "userId": "06080236380106251748"
     },
     "user_tz": -330
    },
    "id": "d6X9RiBtmSxp"
   },
   "outputs": [],
   "source": [
    "# internal function to generate augmented data. \n",
    "# We have done 2 types of augmentation to prevent overfitting of data- flipping of the images and affine transformation. \n",
    "def fetch_aug_batchdata(source_path, folder_list, batch_num, batch_size, t,validation):\n",
    "    \n",
    "    batch_data,batch_labels = init_batch_data(batch_size)\n",
    "    \n",
    "    # We will also build an augumented batch data with affine transformation\n",
    "    batch_data_aug,batch_labels_aug = init_batch_data(batch_size)\n",
    "    \n",
    "    # We will also build an augmented batch data with horizontal flip\n",
    "    batch_data_flip,batch_labels_flip = init_batch_data(batch_size)\n",
    "    \n",
    "    #create a list of image numbers you want to use for a particular video using full frames\n",
    "    img_idx = [x for x in range(0, frames)] \n",
    "\n",
    "    for folder in range(batch_size): # iterate over the batch_size\n",
    "        # read all the images in the folder\n",
    "        imgs = sorted(os.listdir(source_path+'/'+ t[folder + (batch_num*batch_size)].split(';')[0])) \n",
    "        # Generate a random affine to be used in image transformation for buidling agumented data set\n",
    "        M = get_random_affine()\n",
    "        \n",
    "        #  Iterate over the frames/images of a folder to read them in\n",
    "        for idx, item in enumerate(img_idx): \n",
    "            ## image = imread(source_path+'/'+ t[folder + (batch_num*batch_size)].strip().split(';')[0]+'/'+imgs[item]).astype(np.float32)\n",
    "            image = cv2.imread(source_path+'/'+ t[folder + (batch_num*batch_size)].strip().split(';')[0]+'/'+imgs[item], cv2.IMREAD_COLOR)\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "            \n",
    "            # Cropping non symmetric frames\n",
    "            if image.shape[0] != image.shape[1]:\n",
    "                image=image[0:120,20:140]\n",
    "            \n",
    "            #crop the images and resize them. Note that the images are of 2 different shape \n",
    "            #and the conv3D will throw error if the inputs in a batch have different shapes   \n",
    "            resized = cv2.resize(image, (rows, cols), interpolation = cv2.INTER_AREA)\n",
    "            #Normal data\n",
    "            batch_data[folder,idx] = (resized)\n",
    "            \n",
    "            #Data with affine transformation\n",
    "            batch_data_aug[folder,idx] = (cv2.warpAffine(resized, M, (resized.shape[0], resized.shape[1])))\n",
    "            \n",
    "            # Data with horizontal flip\n",
    "            batch_data_flip[folder,idx]= np.flip(resized,1)\n",
    "\n",
    "        batch_labels[folder, int(t[folder + (batch_num*batch_size)].strip().split(';')[2])] = 1\n",
    "        batch_labels_aug[folder, int(t[folder + (batch_num*batch_size)].strip().split(';')[2])] = 1\n",
    "        \n",
    "        # Labeling data with horizobtal flip, right swipe becomes left swipe and viceversa\n",
    "        if int(t[folder + (batch_num*batch_size)].strip().split(';')[2])==0:\n",
    "                    batch_labels_flip[folder, 1] = 1\n",
    "        elif int(t[folder + (batch_num*batch_size)].strip().split(';')[2])==1:\n",
    "                    batch_labels_flip[folder, 0] = 1\n",
    "                    \n",
    "        else:\n",
    "                    batch_labels_flip[folder, int(t[folder + (batch_num*batch_size)].strip().split(';')[2])] = 1\n",
    "                  \n",
    "    \n",
    "    batch_data_final = np.append(batch_data, batch_data_aug, axis = 0)\n",
    "    batch_data_final = np.append(batch_data_final, batch_data_flip, axis = 0)\n",
    "\n",
    "    batch_labels_final = np.append(batch_labels, batch_labels_aug, axis = 0) \n",
    "    batch_labels_final = np.append(batch_labels_final, batch_labels_flip, axis = 0)\n",
    "    \n",
    "    if validation:\n",
    "        batch_data_final=batch_data\n",
    "        batch_labels_final= batch_labels\n",
    "        \n",
    "    return batch_data_final,batch_labels_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "executionInfo": {
     "elapsed": 3304,
     "status": "ok",
     "timestamp": 1604436126846,
     "user": {
      "displayName": "Amit Chawla",
      "photoUrl": "",
      "userId": "06080236380106251748"
     },
     "user_tz": -330
    },
    "id": "Sjjx0Zt6mxfI"
   },
   "outputs": [],
   "source": [
    "# wrapper generator function. it supports ablation experiment and a flag to decide between training and validation folder\n",
    "def generator(source_path, folder_list, batch_size, validation=False,ablation=None):\n",
    "    print( 'Source path = ', source_path, '; batch size =', batch_size)\n",
    "    if(ablation!=None):\n",
    "        folder_list=folder_list[:ablation]\n",
    "    while True:\n",
    "        t = np.random.permutation(folder_list)\n",
    "        num_batches = len(folder_list)//batch_size # calculate the number of batches\n",
    "        for batch in range(num_batches): # we iterate over the number of batches\n",
    "            # you yield the batch_data and the batch_labels, remember what does yield do\n",
    "\n",
    "            yield fetch_aug_batchdata(source_path, folder_list, batch, batch_size, t,validation)\n",
    "        \n",
    "        # Code for the remaining data points which are left after full batches\n",
    "        if (len(folder_list) != batch_size*num_batches):\n",
    "            batch_size = len(folder_list) - (batch_size*num_batches)\n",
    "            yield fetch_aug_batchdata(source_path, folder_list, batch, batch_size, t,validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vS7SH2h6mxfK"
   },
   "source": [
    "Note here that a video is represented above in the generator as (number of images, height, width, number of channels). Take this into consideration while creating the model architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3297,
     "status": "ok",
     "timestamp": 1604436126847,
     "user": {
      "displayName": "Amit Chawla",
      "photoUrl": "",
      "userId": "06080236380106251748"
     },
     "user_tz": -330
    },
    "id": "1lAO-MjDmxfK",
    "outputId": "d71f8854-2608-4939-ebd4-42f6d0b4aa7a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# training sequences = 663\n",
      "# validation sequences = 100\n",
      "# epochs = 10\n"
     ]
    }
   ],
   "source": [
    "# path to images folders\n",
    "train_path = 'Project_data/train'\n",
    "val_path = 'Project_data/val'\n",
    "\n",
    "num_train_sequences = len(train_doc)\n",
    "print('# training sequences =', num_train_sequences)\n",
    "\n",
    "num_val_sequences = len(val_doc)\n",
    "print('# validation sequences =', num_val_sequences)\n",
    "\n",
    "num_epochs = 10 # choose the number of epochs\n",
    "print ('# epochs =', num_epochs)\n",
    "\n",
    "classes= 5 # output classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to plot performance of model\n",
    "def plot(history):\n",
    "    fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(15,4))\n",
    "    axes[0].plot(history.history['loss'])   \n",
    "    axes[0].plot(history.history['val_loss'])\n",
    "    axes[0].legend(['loss','val_loss'])\n",
    "\n",
    "    axes[1].plot(history.history['categorical_accuracy'])   \n",
    "    axes[1].plot(history.history['val_categorical_accuracy'])\n",
    "    axes[1].legend(['categorical_accuracy','val_categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0pSW5czRmxfO"
   },
   "source": [
    "## Model\n",
    "Here you make the model using different functionalities that Keras provides. Remember to use `Conv3D` and `MaxPooling3D` and not `Conv2D` and `Maxpooling2D` for a 3D convolution model. You would want to use `TimeDistributed` while building a Conv2D + RNN model. Also remember that the last layer is the softmax. Design the network in such a way that the model is able to give good accuracy on the least number of parameters so that it can fit in the memory of the webcam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "executionInfo": {
     "elapsed": 3291,
     "status": "ok",
     "timestamp": 1604436126847,
     "user": {
      "displayName": "Amit Chawla",
      "photoUrl": "",
      "userId": "06080236380106251748"
     },
     "user_tz": -330
    },
    "id": "oomrFBismxfO"
   },
   "outputs": [],
   "source": [
    "# keras related imports\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, GRU, Flatten, TimeDistributed, Flatten, BatchNormalization, Activation, Dropout, LSTM, ZeroPadding3D\n",
    "from keras.layers.convolutional import Conv3D, MaxPooling3D, Conv2D, MaxPooling2D\n",
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras import optimizers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we have decided to experiment with this optimizer first. So keeping it in common place\n",
    "optimiser = optimizers.Adam(0.001) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_map=[8, 16, 32, 64, 128] # we will expirment with different number of features for different layers\n",
    "dense_layer_size = [1000,500,5]\n",
    "num_epochs = 10\n",
    "batch_size = 10\n",
    "input_shape = (frames, rows, cols, channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write your model here\n",
    "model = Sequential()\n",
    "# add multiple convulation layers\n",
    "model.add(TimeDistributed(Conv2D(feature_map[0], (3, 3), strides=(2, 2),activation='relu', padding='same'), input_shape=input_shape))\n",
    "\n",
    "model.add(TimeDistributed(Conv2D(feature_map[1], (3,3),padding='same', activation='relu')))\n",
    "model.add(TimeDistributed(MaxPooling2D((2, 2), strides=(2, 2))))\n",
    "\n",
    "model.add(TimeDistributed(Conv2D(feature_map[2], (3,3),padding='same', activation='relu')))\n",
    "model.add(TimeDistributed(MaxPooling2D((2, 2), strides=(2, 2))))\n",
    "\n",
    "model.add(TimeDistributed(Conv2D(feature_map[3], (2,2),padding='same', activation='relu')))\n",
    "model.add(TimeDistributed(MaxPooling2D((2, 2), strides=(2, 2))))\n",
    "\n",
    "\n",
    "model.add(TimeDistributed(BatchNormalization()))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(TimeDistributed(Flatten()))\n",
    "\n",
    "model.add(Dense(dense_layer_size[0], activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(dense_layer_size[1], activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "## using LSTM as the RNN model along with softmax as our last layer.\n",
    "model.add(LSTM(128, return_sequences=False))\n",
    "model.add(Dense(classes, activation='softmax')) # using Softmax as last layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "time_distributed_1 (TimeDist (None, 30, 60, 60, 8)     224       \n",
      "_________________________________________________________________\n",
      "time_distributed_2 (TimeDist (None, 30, 60, 60, 16)    1168      \n",
      "_________________________________________________________________\n",
      "time_distributed_3 (TimeDist (None, 30, 30, 30, 16)    0         \n",
      "_________________________________________________________________\n",
      "time_distributed_4 (TimeDist (None, 30, 30, 30, 32)    4640      \n",
      "_________________________________________________________________\n",
      "time_distributed_5 (TimeDist (None, 30, 15, 15, 32)    0         \n",
      "_________________________________________________________________\n",
      "time_distributed_6 (TimeDist (None, 30, 15, 15, 64)    8256      \n",
      "_________________________________________________________________\n",
      "time_distributed_7 (TimeDist (None, 30, 7, 7, 64)      0         \n",
      "_________________________________________________________________\n",
      "time_distributed_8 (TimeDist (None, 30, 7, 7, 64)      256       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 30, 7, 7, 64)      0         \n",
      "_________________________________________________________________\n",
      "time_distributed_9 (TimeDist (None, 30, 3136)          0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 30, 1000)          3137000   \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 30, 1000)          0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 30, 500)           500500    \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 30, 500)           0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 128)               322048    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 5)                 645       \n",
      "=================================================================\n",
      "Total params: 3,974,737\n",
      "Trainable params: 3,974,609\n",
      "Non-trainable params: 128\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "print (model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/keras/callbacks.py:999: UserWarning: `epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n",
      "  warnings.warn('`epsilon` argument is deprecated and '\n"
     ]
    }
   ],
   "source": [
    "# timestamp to use in model name. \n",
    "curr_dt_time = datetime.datetime.now()\n",
    "\n",
    "model_name = 'model_init_lstm' + '_' + str(curr_dt_time).replace(' ','').replace(':','_') + '/'\n",
    "    \n",
    "if not os.path.exists(model_name):\n",
    "    os.mkdir(model_name)\n",
    "        \n",
    "filepath = model_name + 'model-{epoch:05d}-{loss:.5f}-{categorical_accuracy:.5f}-{val_loss:.5f}-{val_categorical_accuracy:.5f}.h5'\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath, save_best_only=True, monitor='val_loss', verbose=1, save_weights_only=False, mode='auto', period=1)\n",
    "\n",
    "LR = ReduceLROnPlateau(monitor='val_loss', factor=0.001, patience=5, cooldown=4, verbose=1,mode='auto',epsilon=0.0001)# write the REducelronplateau code here\n",
    "callbacks_list = [checkpoint, LR]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = generator(train_path, train_doc, batch_size,validation=True) # validation=True just prevents the augmentation of data\n",
    "val_generator = generator(val_path, val_doc, batch_size, validation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (num_train_sequences%batch_size) == 0:\n",
    "    steps_per_epoch = int(num_train_sequences/batch_size)\n",
    "else:\n",
    "    steps_per_epoch = (num_train_sequences//batch_size) + 1\n",
    "\n",
    "if (num_val_sequences%batch_size) == 0:\n",
    "    validation_steps = int(num_val_sequences/batch_size)\n",
    "else:\n",
    "    validation_steps = (num_val_sequences//batch_size) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source path = Source path =  Project_data/train ; batch size = 10\n",
      "Epoch 1/10\n",
      " Project_data/val ; batch size = 10\n",
      "67/67 [==============================] - 193s 3s/step - loss: 1.3517 - categorical_accuracy: 0.4204 - val_loss: 1.2241 - val_categorical_accuracy: 0.5100\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.22408, saving model to model_init_lstm_2020-11-0811_02_37.269104/model-00001-1.35592-0.41780-1.22408-0.51000.h5\n",
      "Epoch 2/10\n",
      "67/67 [==============================] - 47s 699ms/step - loss: 1.2850 - categorical_accuracy: 0.4925 - val_loss: 1.4767 - val_categorical_accuracy: 0.4600\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 1.22408\n",
      "Epoch 3/10\n",
      "67/67 [==============================] - 47s 708ms/step - loss: 1.3040 - categorical_accuracy: 0.5025 - val_loss: 1.4456 - val_categorical_accuracy: 0.4200\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1.22408\n",
      "Epoch 4/10\n",
      "67/67 [==============================] - 45s 670ms/step - loss: 1.2247 - categorical_accuracy: 0.5224 - val_loss: 1.3635 - val_categorical_accuracy: 0.4600\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.22408\n",
      "Epoch 5/10\n",
      "67/67 [==============================] - 50s 747ms/step - loss: 1.1117 - categorical_accuracy: 0.5572 - val_loss: 1.0545 - val_categorical_accuracy: 0.6000\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.22408 to 1.05451, saving model to model_init_lstm_2020-11-0811_02_37.269104/model-00005-1.11169-0.55721-1.05451-0.60000.h5\n",
      "Epoch 6/10\n",
      "67/67 [==============================] - 46s 693ms/step - loss: 1.1221 - categorical_accuracy: 0.5871 - val_loss: 1.1117 - val_categorical_accuracy: 0.5900\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.05451\n",
      "Epoch 7/10\n",
      "67/67 [==============================] - 45s 665ms/step - loss: 1.1671 - categorical_accuracy: 0.5572 - val_loss: 1.3191 - val_categorical_accuracy: 0.4600\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1.05451\n",
      "Epoch 8/10\n",
      "67/67 [==============================] - 48s 715ms/step - loss: 1.0908 - categorical_accuracy: 0.5622 - val_loss: 1.9565 - val_categorical_accuracy: 0.3300\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1.05451\n",
      "Epoch 9/10\n",
      "67/67 [==============================] - 59s 875ms/step - loss: 1.1899 - categorical_accuracy: 0.5522 - val_loss: 2.0965 - val_categorical_accuracy: 0.2400\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 1.05451\n",
      "Epoch 10/10\n",
      "67/67 [==============================] - 40s 600ms/step - loss: 1.1772 - categorical_accuracy: 0.5821 - val_loss: 1.6759 - val_categorical_accuracy: 0.3800\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 1.05451\n",
      "\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 1.0000000474974512e-06.\n"
     ]
    }
   ],
   "source": [
    "model_history = model.fit_generator(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
    "                  callbacks=callbacks_list, validation_data=val_generator, \n",
    "                  validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot(model_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'a' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-3f786850e387>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0ma\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'a' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 1.b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We augment the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write your model here\n",
    "model = Sequential()\n",
    "# add multiple convulation layers\n",
    "model.add(TimeDistributed(Conv2D(feature_map[0], (3, 3), strides=(2, 2),activation='relu', padding='same'), input_shape=input_shape))\n",
    "\n",
    "model.add(TimeDistributed(Conv2D(feature_map[1], (3,3),padding='same', activation='relu')))\n",
    "model.add(TimeDistributed(MaxPooling2D((2, 2), strides=(2, 2))))\n",
    "\n",
    "model.add(TimeDistributed(Conv2D(feature_map[2], (3,3),padding='same', activation='relu')))\n",
    "model.add(TimeDistributed(MaxPooling2D((2, 2), strides=(2, 2))))\n",
    "\n",
    "model.add(TimeDistributed(Conv2D(feature_map[3], (2,2),padding='same', activation='relu')))\n",
    "model.add(TimeDistributed(MaxPooling2D((2, 2), strides=(2, 2))))\n",
    "\n",
    "\n",
    "model.add(TimeDistributed(BatchNormalization()))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(TimeDistributed(Flatten()))\n",
    "\n",
    "model.add(Dense(dense_layer_size[0], activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(dense_layer_size[1], activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "## using LSTM as the RNN model along with softmax as our last layer.\n",
    "model.add(LSTM(128, return_sequences=False))\n",
    "model.add(Dense(classes, activation='softmax')) # using Softmax as last layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "print (model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# timestamp to use in model name. \n",
    "curr_dt_time = datetime.datetime.now()\n",
    "\n",
    "model_name = 'model_init_lstm' + '_' + str(curr_dt_time).replace(' ','').replace(':','_') + '/'\n",
    "    \n",
    "if not os.path.exists(model_name):\n",
    "    os.mkdir(model_name)\n",
    "        \n",
    "filepath = model_name + 'model-{epoch:05d}-{loss:.5f}-{categorical_accuracy:.5f}-{val_loss:.5f}-{val_categorical_accuracy:.5f}.h5'\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath, save_best_only=True, monitor='val_loss', verbose=1, save_weights_only=False, mode='auto', period=1)\n",
    "\n",
    "LR = ReduceLROnPlateau(monitor='val_loss', factor=0.001, patience=5, cooldown=4, verbose=1,mode='auto',epsilon=0.0001)# write the REducelronplateau code here\n",
    "callbacks_list = [checkpoint, LR]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = generator(train_path, train_doc, batch_size)\n",
    "val_generator = generator(val_path, val_doc, batch_size, validation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (num_train_sequences%batch_size) == 0:\n",
    "    steps_per_epoch = int(num_train_sequences/batch_size)\n",
    "else:\n",
    "    steps_per_epoch = (num_train_sequences//batch_size) + 1\n",
    "\n",
    "if (num_val_sequences%batch_size) == 0:\n",
    "    validation_steps = int(num_val_sequences/batch_size)\n",
    "else:\n",
    "    validation_steps = (num_val_sequences//batch_size) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_history = model.fit_generator(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
    "                  callbacks=callbacks_list, validation_data=val_generator, \n",
    "                  validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(model_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We add batch normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_map=[8, 16, 32, 64, 128] # we will expirment with different number of features for different layers\n",
    "dense_layer_size = [1000,500,5]\n",
    "num_epochs = 10\n",
    "batch_size = 10\n",
    "input_shape = (frames, rows, cols, channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write your model here\n",
    "model = Sequential()\n",
    "# add multiple convulation layers\n",
    "model.add(TimeDistributed(Conv2D(feature_map[0], (3, 3), strides=(2, 2),activation='relu', padding='same'), input_shape=input_shape))\n",
    "\n",
    "model.add(TimeDistributed(Conv2D(feature_map[1], (3,3),padding='same', activation='relu')))\n",
    "model.add(TimeDistributed(MaxPooling2D((2, 2), strides=(2, 2))))\n",
    "model.add(TimeDistributed(BatchNormalization()))\n",
    "\n",
    "\n",
    "model.add(TimeDistributed(Conv2D(feature_map[2], (3,3),padding='same', activation='relu')))\n",
    "model.add(TimeDistributed(MaxPooling2D((2, 2), strides=(2, 2))))\n",
    "model.add(TimeDistributed(BatchNormalization()))\n",
    "\n",
    "model.add(TimeDistributed(Conv2D(feature_map[3], (2,2),padding='same', activation='relu')))\n",
    "model.add(TimeDistributed(MaxPooling2D((2, 2), strides=(2, 2))))\n",
    "\n",
    "\n",
    "model.add(TimeDistributed(BatchNormalization()))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(TimeDistributed(Flatten()))\n",
    "\n",
    "model.add(Dense(dense_layer_size[0], activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(dense_layer_size[1], activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "## using LSTM as the RNN model along with softmax as our last layer.\n",
    "model.add(LSTM(128, return_sequences=False))\n",
    "model.add(Dense(classes, activation='softmax')) # using Softmax as last layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "print (model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# timestamp to use in model name. \n",
    "curr_dt_time = datetime.datetime.now()\n",
    "\n",
    "model_name = 'model_init_lstm' + '_' + str(curr_dt_time).replace(' ','').replace(':','_') + '/'\n",
    "    \n",
    "if not os.path.exists(model_name):\n",
    "    os.mkdir(model_name)\n",
    "        \n",
    "filepath = model_name + 'model-{epoch:05d}-{loss:.5f}-{categorical_accuracy:.5f}-{val_loss:.5f}-{val_categorical_accuracy:.5f}.h5'\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath, save_best_only=True, monitor='val_loss', verbose=1, save_weights_only=False, mode='auto', period=1)\n",
    "\n",
    "LR = ReduceLROnPlateau(monitor='val_loss', factor=0.001, patience=5, cooldown=4, verbose=1,mode='auto',epsilon=0.0001)# write the REducelronplateau code here\n",
    "callbacks_list = [checkpoint, LR]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (num_train_sequences%batch_size) == 0:\n",
    "    steps_per_epoch = int(num_train_sequences/batch_size)\n",
    "else:\n",
    "    steps_per_epoch = (num_train_sequences//batch_size) + 1\n",
    "\n",
    "if (num_val_sequences%batch_size) == 0:\n",
    "    validation_steps = int(num_val_sequences/batch_size)\n",
    "else:\n",
    "    validation_steps = (num_val_sequences//batch_size) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = generator(train_path, train_doc, batch_size)\n",
    "val_generator = generator(val_path, val_doc, batch_size, validation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_history = model.fit_generator(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
    "                  callbacks=callbacks_list, validation_data=val_generator, \n",
    "                  validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(model_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We reduce the dense layer neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_map=[8, 16, 32, 64, 128] \n",
    "dense_layer_size = [256,128,5] # we reduce the dense layer neurons\n",
    "num_epochs = 10\n",
    "batch_size = 10\n",
    "input_shape = (frames, rows, cols, channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = Sequential()\n",
    "# add multiple convulation layers\n",
    "model.add(TimeDistributed(Conv2D(feature_map[0], (3, 3), strides=(2, 2),activation='relu', padding='same'), input_shape=input_shape))\n",
    "\n",
    "model.add(TimeDistributed(Conv2D(feature_map[1], (3,3),padding='same', activation='relu')))\n",
    "model.add(TimeDistributed(MaxPooling2D((2, 2), strides=(2, 2))))\n",
    "model.add(TimeDistributed(BatchNormalization()))\n",
    "\n",
    "# model.add(keras.layers.Dropout(0.4))\n",
    "\n",
    "model.add(TimeDistributed(Conv2D(feature_map[2], (3,3),padding='same', activation='relu')))\n",
    "model.add(TimeDistributed(MaxPooling2D((2, 2), strides=(2, 2))))\n",
    "# model.add(keras.layers.Dropout(0.4))\n",
    "model.add(TimeDistributed(BatchNormalization()))\n",
    "\n",
    "model.add(TimeDistributed(Conv2D(feature_map[3], (2,2),padding='same', activation='relu')))\n",
    "model.add(TimeDistributed(MaxPooling2D((2, 2), strides=(2, 2))))\n",
    "\n",
    "\n",
    "model.add(TimeDistributed(BatchNormalization()))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(TimeDistributed(Flatten()))\n",
    "\n",
    "model.add(Dense(dense_layer_size[0], activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(dense_layer_size[1], activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "## using LSTM as the RNN model along with softmax as our last layer.\n",
    "model.add(LSTM(128, return_sequences=False))\n",
    "model.add(Dense(classes, activation='softmax')) # using Softmax as last layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "print (model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# timestamp to use in model name. \n",
    "curr_dt_time = datetime.datetime.now()\n",
    "\n",
    "model_name = 'model_init_lstm' + '_' + str(curr_dt_time).replace(' ','').replace(':','_') + '/'\n",
    "    \n",
    "if not os.path.exists(model_name):\n",
    "    os.mkdir(model_name)\n",
    "        \n",
    "filepath = model_name + 'model-{epoch:05d}-{loss:.5f}-{categorical_accuracy:.5f}-{val_loss:.5f}-{val_categorical_accuracy:.5f}.h5'\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath, save_best_only=True, monitor='val_loss', verbose=1, save_weights_only=False, mode='auto', period=1)\n",
    "\n",
    "LR = ReduceLROnPlateau(monitor='val_loss', factor=0.001, patience=5, cooldown=4, verbose=1,mode='auto',epsilon=0.0001)# write the REducelronplateau code here\n",
    "callbacks_list = [checkpoint, LR]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (num_train_sequences%batch_size) == 0:\n",
    "    steps_per_epoch = int(num_train_sequences/batch_size)\n",
    "else:\n",
    "    steps_per_epoch = (num_train_sequences//batch_size) + 1\n",
    "\n",
    "if (num_val_sequences%batch_size) == 0:\n",
    "    validation_steps = int(num_val_sequences/batch_size)\n",
    "else:\n",
    "    validation_steps = (num_val_sequences//batch_size) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = generator(train_path, train_doc, batch_size)\n",
    "val_generator = generator(val_path, val_doc, batch_size, validation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_history = model.fit_generator(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
    "                  callbacks=callbacks_list, validation_data=val_generator, \n",
    "                  validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(model_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We increase learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_map=[8, 16, 32, 64, 128] \n",
    "dense_layer_size = [256,128,5] # we reduce the dense layer neurons\n",
    "num_epochs = 10\n",
    "batch_size = 10\n",
    "input_shape = (frames, rows, cols, channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = Sequential()\n",
    "# add multiple convulation layers\n",
    "model.add(TimeDistributed(Conv2D(feature_map[0], (3, 3), strides=(2, 2),activation='relu', padding='same'), input_shape=input_shape))\n",
    "\n",
    "model.add(TimeDistributed(Conv2D(feature_map[1], (3,3),padding='same', activation='relu')))\n",
    "model.add(TimeDistributed(MaxPooling2D((2, 2), strides=(2, 2))))\n",
    "model.add(TimeDistributed(BatchNormalization()))\n",
    "\n",
    "model.add(TimeDistributed(Conv2D(feature_map[2], (3,3),padding='same', activation='relu')))\n",
    "model.add(TimeDistributed(MaxPooling2D((2, 2), strides=(2, 2))))\n",
    "model.add(TimeDistributed(BatchNormalization()))\n",
    "\n",
    "model.add(TimeDistributed(Conv2D(feature_map[3], (2,2),padding='same', activation='relu')))\n",
    "model.add(TimeDistributed(MaxPooling2D((2, 2), strides=(2, 2))))\n",
    "\n",
    "\n",
    "model.add(TimeDistributed(BatchNormalization()))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(TimeDistributed(Flatten()))\n",
    "\n",
    "model.add(Dense(dense_layer_size[0], activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(dense_layer_size[1], activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "## using LSTM as the RNN model along with softmax as our last layer.\n",
    "model.add(LSTM(128, return_sequences=False))\n",
    "model.add(Dense(classes, activation='softmax')) # using Softmax as last layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "print (model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# timestamp to use in model name. \n",
    "curr_dt_time = datetime.datetime.now()\n",
    "\n",
    "model_name = 'model_init_lstm' + '_' + str(curr_dt_time).replace(' ','').replace(':','_') + '/'\n",
    "    \n",
    "if not os.path.exists(model_name):\n",
    "    os.mkdir(model_name)\n",
    "        \n",
    "filepath = model_name + 'model-{epoch:05d}-{loss:.5f}-{categorical_accuracy:.5f}-{val_loss:.5f}-{val_categorical_accuracy:.5f}.h5'\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath, save_best_only=True, monitor='val_loss', verbose=1, save_weights_only=False, mode='auto', period=1)\n",
    "\n",
    "LR = ReduceLROnPlateau(monitor='val_loss', factor=0.001, patience=5, cooldown=4, verbose=1,mode='auto',epsilon=0.0001)# write the REducelronplateau code here\n",
    "callbacks_list = [checkpoint, LR]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (num_train_sequences%batch_size) == 0:\n",
    "    steps_per_epoch = int(num_train_sequences/batch_size)\n",
    "else:\n",
    "    steps_per_epoch = (num_train_sequences//batch_size) + 1\n",
    "\n",
    "if (num_val_sequences%batch_size) == 0:\n",
    "    validation_steps = int(num_val_sequences/batch_size)\n",
    "else:\n",
    "    validation_steps = (num_val_sequences//batch_size) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = generator(train_path, train_doc, batch_size)\n",
    "val_generator = generator(val_path, val_doc, batch_size, validation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_history = model.fit_generator(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
    "                  callbacks=callbacks_list, validation_data=val_generator, \n",
    "                  validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(model_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GRU MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 4564,
     "status": "ok",
     "timestamp": 1604436128129,
     "user": {
      "displayName": "Amit Chawla",
      "photoUrl": "",
      "userId": "06080236380106251748"
     },
     "user_tz": -330
    },
    "id": "-Tlfx79bmxfR"
   },
   "outputs": [],
   "source": [
    "#write your model here\n",
    "feature_map=[8, 16, 32, 64, 128, 256] # we will expirment with different number of features for different layers\n",
    "dense_layer_size = [1000,500,5] # \n",
    "classes= 5\n",
    "input_shape = (frames, rows, cols, channels)\n",
    "model = Sequential()\n",
    "# add multiple convulation layers\n",
    "model.add(TimeDistributed(Conv2D(feature_map[0], (3, 3), strides=(2, 2),activation='relu', padding='same'), input_shape=input_shape))\n",
    "\n",
    "model.add(TimeDistributed(Conv2D(feature_map[1], (3,3),padding='same', activation='relu')))\n",
    "model.add(TimeDistributed(MaxPooling2D((2, 2), strides=(2, 2))))\n",
    "model.add(TimeDistributed(BatchNormalization()))\n",
    "\n",
    "model.add(TimeDistributed(Conv2D(feature_map[2], (3,3),padding='same', activation='relu')))\n",
    "model.add(TimeDistributed(MaxPooling2D((2, 2), strides=(2, 2))))\n",
    "model.add(TimeDistributed(BatchNormalization()))\n",
    "\n",
    "model.add(TimeDistributed(Conv2D(feature_map[3], (2,2),padding='same', activation='relu')))\n",
    "model.add(TimeDistributed(MaxPooling2D((2, 2), strides=(2, 2))))\n",
    "model.add(TimeDistributed(BatchNormalization()))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(TimeDistributed(Conv2D(feature_map[4], (2,2),padding='same', activation='relu')))\n",
    "model.add(TimeDistributed(MaxPooling2D((2, 2), strides=(2, 2))))\n",
    "model.add(TimeDistributed(BatchNormalization()))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(TimeDistributed(Flatten()))\n",
    "\n",
    "model.add(Dense(dense_layer_size[0], activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(dense_layer_size[1], activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "## using GRU as the RNN model along with softmax as our last layer.\n",
    "model.add(GRU(128, return_sequences=False))\n",
    "model.add(Dense(classes, activation='softmax')) # using Softmax as last layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jKpo5LkKmxfT"
   },
   "source": [
    "Now that you have written the model, the next step is to `compile` the model. When you print the `summary` of the model, you'll see the total number of parameters you have to train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4560,
     "status": "ok",
     "timestamp": 1604436128130,
     "user": {
      "displayName": "Amit Chawla",
      "photoUrl": "",
      "userId": "06080236380106251748"
     },
     "user_tz": -330
    },
    "id": "NaRv2AivmxfU",
    "outputId": "44e90e46-23c6-4207-8810-a0dfbff59b37",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "optimiser = optimizers.Adam(0.001) #write your optimizer\n",
    "model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "print (model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MqlBfwFtmxfW"
   },
   "source": [
    "Let us create the `train_generator` and the `val_generator` which will be used in `.fit_generator`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 4551,
     "status": "ok",
     "timestamp": 1604436128132,
     "user": {
      "displayName": "Amit Chawla",
      "photoUrl": "",
      "userId": "06080236380106251748"
     },
     "user_tz": -330
    },
    "id": "c45IEYaZmxfX"
   },
   "outputs": [],
   "source": [
    "train_generator = generator(train_path, train_doc, batch_size)\n",
    "val_generator = generator(val_path, val_doc, batch_size, validation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4544,
     "status": "ok",
     "timestamp": 1604436128132,
     "user": {
      "displayName": "Amit Chawla",
      "photoUrl": "",
      "userId": "06080236380106251748"
     },
     "user_tz": -330
    },
    "id": "c6E-9uGqmxfZ",
    "outputId": "59d5557a-1311-4c21-ec60-8e3a5b71cadb"
   },
   "outputs": [],
   "source": [
    "model_name = 'model_init_CNN' + '_' + str(curr_dt_time).replace(' ','').replace(':','_') + '/'\n",
    "    \n",
    "if not os.path.exists(model_name):\n",
    "    os.mkdir(model_name)\n",
    "        \n",
    "filepath = model_name + 'model-{epoch:05d}-{loss:.5f}-{categorical_accuracy:.5f}-{val_loss:.5f}-{val_categorical_accuracy:.5f}.h5'\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath, save_best_only=True, monitor='val_loss', verbose=1, save_weights_only=False, mode='auto', period=1)\n",
    "\n",
    "LR = ReduceLROnPlateau(monitor='val_loss', factor=0.001, patience=5, cooldown=4, verbose=1,mode='auto',epsilon=0.0001)# write the REducelronplateau code here\n",
    "callbacks_list = [checkpoint, LR]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hErw7p94mxfb"
   },
   "source": [
    "The `steps_per_epoch` and `validation_steps` are used by `fit_generator` to decide the number of next() calls it need to make."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 4538,
     "status": "ok",
     "timestamp": 1604436128133,
     "user": {
      "displayName": "Amit Chawla",
      "photoUrl": "",
      "userId": "06080236380106251748"
     },
     "user_tz": -330
    },
    "id": "iCuo6cpBmxfc"
   },
   "outputs": [],
   "source": [
    "if (num_train_sequences%batch_size) == 0:\n",
    "    steps_per_epoch = int(num_train_sequences/batch_size)\n",
    "else:\n",
    "    steps_per_epoch = (num_train_sequences//batch_size) + 1\n",
    "\n",
    "if (num_val_sequences%batch_size) == 0:\n",
    "    validation_steps = int(num_val_sequences/batch_size)\n",
    "else:\n",
    "    validation_steps = (num_val_sequences//batch_size) + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xj_F8IVMmxff"
   },
   "source": [
    "Let us now fit the model. This will start training the model and with the help of the checkpoints, you'll be able to save the model at the end of each epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QYF2SSQtmxfh",
    "outputId": "5e024d26-ac4d-4614-a8c8-a8477b53f1b7"
   },
   "outputs": [],
   "source": [
    "batch_size = 10\n",
    "num_epochs = 10\n",
    "model_history = model.fit_generator(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
    "                  callbacks=callbacks_list, validation_data=val_generator, \n",
    "                  validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(model_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing dropout layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write your model here\n",
    "feature_map=[8, 16, 32, 64, 128, 256] # we will expirment with different number of features for different layers\n",
    "dense_layer_size = [1000,500,5] # \n",
    "classes= 5\n",
    "input_shape = (frames, rows, cols, channels)\n",
    "model = Sequential()\n",
    "# add multiple convulation layers\n",
    "model.add(TimeDistributed(Conv2D(feature_map[0], (3, 3), strides=(2, 2),activation='relu', padding='same'), input_shape=input_shape))\n",
    "\n",
    "model.add(TimeDistributed(Conv2D(feature_map[1], (3,3),padding='same', activation='relu')))\n",
    "model.add(TimeDistributed(MaxPooling2D((2, 2), strides=(2, 2))))\n",
    "model.add(TimeDistributed(BatchNormalization()))\n",
    "\n",
    "model.add(TimeDistributed(Conv2D(feature_map[2], (3,3),padding='same', activation='relu')))\n",
    "model.add(TimeDistributed(MaxPooling2D((2, 2), strides=(2, 2))))\n",
    "model.add(TimeDistributed(BatchNormalization()))\n",
    "\n",
    "model.add(TimeDistributed(Conv2D(feature_map[3], (2,2),padding='same', activation='relu')))\n",
    "model.add(TimeDistributed(MaxPooling2D((2, 2), strides=(2, 2))))\n",
    "model.add(TimeDistributed(BatchNormalization()))\n",
    "\n",
    "model.add(TimeDistributed(Conv2D(feature_map[4], (2,2),padding='same', activation='relu')))\n",
    "model.add(TimeDistributed(MaxPooling2D((2, 2), strides=(2, 2))))\n",
    "model.add(TimeDistributed(BatchNormalization()))\n",
    "\n",
    "model.add(TimeDistributed(Flatten()))\n",
    "\n",
    "model.add(Dense(dense_layer_size[0], activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(dense_layer_size[1], activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "## using GRU as the RNN model along with softmax as our last layer.\n",
    "model.add(GRU(128, return_sequences=False))\n",
    "model.add(Dense(classes, activation='softmax')) # using Softmax as last layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimiser = optimizers.Adam(0.001) #write your optimizer\n",
    "model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "print (model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = generator(train_path, train_doc, batch_size)\n",
    "val_generator = generator(val_path, val_doc, batch_size, validation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'model_init_CNN' + '_' + str(curr_dt_time).replace(' ','').replace(':','_') + '/'\n",
    "    \n",
    "if not os.path.exists(model_name):\n",
    "    os.mkdir(model_name)\n",
    "        \n",
    "filepath = model_name + 'model-{epoch:05d}-{loss:.5f}-{categorical_accuracy:.5f}-{val_loss:.5f}-{val_categorical_accuracy:.5f}.h5'\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath, save_best_only=True, monitor='val_loss', verbose=1, save_weights_only=False, mode='auto', period=1)\n",
    "\n",
    "LR = ReduceLROnPlateau(monitor='val_loss', factor=0.001, patience=5, cooldown=4, verbose=1,mode='auto',epsilon=0.0001)# write the REducelronplateau code here\n",
    "callbacks_list = [checkpoint, LR]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (num_train_sequences%batch_size) == 0:\n",
    "    steps_per_epoch = int(num_train_sequences/batch_size)\n",
    "else:\n",
    "    steps_per_epoch = (num_train_sequences//batch_size) + 1\n",
    "\n",
    "if (num_val_sequences%batch_size) == 0:\n",
    "    validation_steps = int(num_val_sequences/batch_size)\n",
    "else:\n",
    "    validation_steps = (num_val_sequences//batch_size) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 10\n",
    "num_epochs = 20\n",
    "model_history = model.fit_generator(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
    "                  callbacks=callbacks_list, validation_data=val_generator, \n",
    "                  validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(model_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### change image size to 84X84"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write your model here\n",
    "feature_map=[8, 16, 32, 64, 128, 256] # we will expirment with different number of features for different layers\n",
    "dense_layer_size = [1000,500,5] # \n",
    "classes= 5\n",
    "rows = 84\n",
    "cols = 84\n",
    "\n",
    "input_shape = (frames, rows, cols, channels)\n",
    "\n",
    "model = Sequential()\n",
    "# add multiple convulation layers\n",
    "model.add(TimeDistributed(Conv2D(feature_map[0], (3, 3), strides=(2, 2),activation='relu', padding='same'), input_shape=input_shape))\n",
    "\n",
    "model.add(TimeDistributed(Conv2D(feature_map[1], (3,3),padding='same', activation='relu')))\n",
    "model.add(TimeDistributed(MaxPooling2D((2, 2), strides=(2, 2))))\n",
    "model.add(TimeDistributed(BatchNormalization()))\n",
    "\n",
    "model.add(TimeDistributed(Conv2D(feature_map[2], (3,3),padding='same', activation='relu')))\n",
    "model.add(TimeDistributed(MaxPooling2D((2, 2), strides=(2, 2))))\n",
    "model.add(TimeDistributed(BatchNormalization()))\n",
    "\n",
    "model.add(TimeDistributed(Conv2D(feature_map[3], (2,2),padding='same', activation='relu')))\n",
    "model.add(TimeDistributed(MaxPooling2D((2, 2), strides=(2, 2))))\n",
    "model.add(TimeDistributed(BatchNormalization()))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(TimeDistributed(Conv2D(feature_map[4], (2,2),padding='same', activation='relu')))\n",
    "model.add(TimeDistributed(MaxPooling2D((2, 2), strides=(2, 2))))\n",
    "model.add(TimeDistributed(BatchNormalization()))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(TimeDistributed(Flatten()))\n",
    "\n",
    "model.add(Dense(dense_layer_size[0], activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(dense_layer_size[1], activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "## using GRU as the RNN model along with softmax as our last layer.\n",
    "model.add(GRU(128, return_sequences=False))\n",
    "model.add(Dense(classes, activation='softmax')) # using Softmax as last layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimiser = optimizers.Adam(0.001) #write your optimizer\n",
    "model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "print (model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = generator(train_path, train_doc, batch_size)\n",
    "val_generator = generator(val_path, val_doc, batch_size, validation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'model_init_CNN' + '_' + str(curr_dt_time).replace(' ','').replace(':','_') + '/'\n",
    "    \n",
    "if not os.path.exists(model_name):\n",
    "    os.mkdir(model_name)\n",
    "        \n",
    "filepath = model_name + 'model-{epoch:05d}-{loss:.5f}-{categorical_accuracy:.5f}-{val_loss:.5f}-{val_categorical_accuracy:.5f}.h5'\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath, save_best_only=True, monitor='val_loss', verbose=1, save_weights_only=False, mode='auto', period=1)\n",
    "\n",
    "LR = ReduceLROnPlateau(monitor='val_loss', factor=0.001, patience=5, cooldown=4, verbose=1,mode='auto',epsilon=0.0001)# write the REducelronplateau code here\n",
    "callbacks_list = [checkpoint, LR]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (num_train_sequences%batch_size) == 0:\n",
    "    steps_per_epoch = int(num_train_sequences/batch_size)\n",
    "else:\n",
    "    steps_per_epoch = (num_train_sequences//batch_size) + 1\n",
    "\n",
    "if (num_val_sequences%batch_size) == 0:\n",
    "    validation_steps = int(num_val_sequences/batch_size)\n",
    "else:\n",
    "    validation_steps = (num_val_sequences//batch_size) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 10\n",
    "num_epochs = 20\n",
    "model_history = model.fit_generator(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
    "                  callbacks=callbacks_list, validation_data=val_generator, \n",
    "                  validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(model_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding one more dense layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # reset image size to 120*120\n",
    "rows = 120\n",
    "cols = 120"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write your model here\n",
    "feature_map=[8, 16, 32, 64, 128, 256] # we will expirment with different number of features for different layers\n",
    "dense_layer_size = [1000, 500, 250, 5] # \n",
    "classes= 5\n",
    "\n",
    "input_shape = (frames, rows, cols, channels)\n",
    "\n",
    "model = Sequential()\n",
    "# add multiple convulation layers\n",
    "model.add(TimeDistributed(Conv2D(feature_map[0], (3, 3), strides=(2, 2),activation='relu', padding='same'), input_shape=input_shape))\n",
    "\n",
    "model.add(TimeDistributed(Conv2D(feature_map[1], (3,3),padding='same', activation='relu')))\n",
    "model.add(TimeDistributed(MaxPooling2D((2, 2), strides=(2, 2))))\n",
    "model.add(TimeDistributed(BatchNormalization()))\n",
    "\n",
    "model.add(TimeDistributed(Conv2D(feature_map[2], (3,3),padding='same', activation='relu')))\n",
    "model.add(TimeDistributed(MaxPooling2D((2, 2), strides=(2, 2))))\n",
    "model.add(TimeDistributed(BatchNormalization()))\n",
    "\n",
    "model.add(TimeDistributed(Conv2D(feature_map[3], (2,2),padding='same', activation='relu')))\n",
    "model.add(TimeDistributed(MaxPooling2D((2, 2), strides=(2, 2))))\n",
    "model.add(TimeDistributed(BatchNormalization()))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(TimeDistributed(Conv2D(feature_map[4], (2,2),padding='same', activation='relu')))\n",
    "model.add(TimeDistributed(MaxPooling2D((2, 2), strides=(2, 2))))\n",
    "model.add(TimeDistributed(BatchNormalization()))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(TimeDistributed(Flatten()))\n",
    "\n",
    "model.add(Dense(dense_layer_size[0], activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(dense_layer_size[1], activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(dense_layer_size[2], activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "## using GRU as the RNN model along with softmax as our last layer.\n",
    "model.add(GRU(128, return_sequences=False))\n",
    "model.add(Dense(classes, activation='softmax')) # using Softmax as last layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimiser = optimizers.Adam(0.001) #write your optimizer\n",
    "model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "print (model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = generator(train_path, train_doc, batch_size)\n",
    "val_generator = generator(val_path, val_doc, batch_size, validation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'model_init_CNN' + '_' + str(curr_dt_time).replace(' ','').replace(':','_') + '/'\n",
    "    \n",
    "if not os.path.exists(model_name):\n",
    "    os.mkdir(model_name)\n",
    "        \n",
    "filepath = model_name + 'model-{epoch:05d}-{loss:.5f}-{categorical_accuracy:.5f}-{val_loss:.5f}-{val_categorical_accuracy:.5f}.h5'\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath, save_best_only=True, monitor='val_loss', verbose=1, save_weights_only=False, mode='auto', period=1)\n",
    "\n",
    "LR = ReduceLROnPlateau(monitor='val_loss', factor=0.001, patience=5, cooldown=4, verbose=1,mode='auto',epsilon=0.0001)# write the REducelronplateau code here\n",
    "callbacks_list = [checkpoint, LR]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (num_train_sequences%batch_size) == 0:\n",
    "    steps_per_epoch = int(num_train_sequences/batch_size)\n",
    "else:\n",
    "    steps_per_epoch = (num_train_sequences//batch_size) + 1\n",
    "\n",
    "if (num_val_sequences%batch_size) == 0:\n",
    "    validation_steps = int(num_val_sequences/batch_size)\n",
    "else:\n",
    "    validation_steps = (num_val_sequences//batch_size) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 10\n",
    "num_epochs = 20\n",
    "model_history = model.fit_generator(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
    "                  callbacks=callbacks_list, validation_data=val_generator, \n",
    "                  validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(model_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0eCOFgTUmxfj"
   },
   "source": [
    "## Conv3D model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimiser SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filters = [8,16,32,64]\n",
    "dense = [256, 128, 5]\n",
    "\n",
    "# Input\n",
    "input_shape=(frames, rows, cols, channels)\n",
    "\n",
    "# Define model\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv3D(filters[0], \n",
    "                 kernel_size=(3,3,3), \n",
    "                 input_shape=input_shape,\n",
    "                 padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(MaxPooling3D(pool_size=(2,2,2)))\n",
    "\n",
    "model.add(Conv3D(filters[1], \n",
    "                 kernel_size=(3,3,3), \n",
    "                 padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(MaxPooling3D(pool_size=(2,2,2)))\n",
    "\n",
    "model.add(Conv3D(filters[2], \n",
    "                 kernel_size=(1,3,3), \n",
    "                 padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(MaxPooling3D(pool_size=(2,2,2)))\n",
    "\n",
    "model.add(Conv3D(filters[3], \n",
    "                 kernel_size=(1,3,3), \n",
    "                 padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(MaxPooling3D(pool_size=(2,2,2)))\n",
    "\n",
    "#Flatten Layers\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(dense[0], activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(dense[1], activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "#softmax layer\n",
    "model.add(Dense(dense[2], activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimiser = optimizers.SGD() #write your optimizer\n",
    "model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "print (model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = generator(train_path, train_doc, batch_size)\n",
    "val_generator = generator(val_path, val_doc, batch_size,validation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'model_init_Conv3D' + '_' + str(curr_dt_time).replace(' ','').replace(':','_') + '/'\n",
    "    \n",
    "if not os.path.exists(model_name):\n",
    "    os.mkdir(model_name)\n",
    "        \n",
    "filepath = model_name + 'model-{epoch:05d}-{loss:.5f}-{categorical_accuracy:.5f}-{val_loss:.5f}-{val_categorical_accuracy:.5f}.h5'\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath, save_best_only=True, monitor='val_loss', verbose=1, save_weights_only=False, mode='auto', period=1)\n",
    "\n",
    "# write the Reducelronplateau code here\n",
    "LR = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, cooldown=1, verbose=1)\n",
    "callbacks_list = [checkpoint, LR]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (num_train_sequences%batch_size) == 0:\n",
    "    steps_per_epoch = int(num_train_sequences/batch_size)\n",
    "else:\n",
    "    steps_per_epoch = (num_train_sequences//batch_size) + 1\n",
    "\n",
    "if (num_val_sequences%batch_size) == 0:\n",
    "    validation_steps = int(num_val_sequences/batch_size)\n",
    "else:\n",
    "    validation_steps = (num_val_sequences//batch_size) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 10\n",
    "num_epochs = 10\n",
    "model_history = model.fit_generator(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
    "                   callbacks=callbacks_list, validation_data=val_generator, \n",
    "                   validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(model_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Increased Epochs and Adam optimiser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y6zFhT4ugNe6"
   },
   "outputs": [],
   "source": [
    "filters = [8,16,32,64]\n",
    "dense = [256, 128, 5]\n",
    "\n",
    "# Input\n",
    "input_shape=(frames, rows, cols, channels)\n",
    "\n",
    "# Define model\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv3D(filters[0], \n",
    "                 kernel_size=(3,3,3), \n",
    "                 input_shape=input_shape,\n",
    "                 padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(MaxPooling3D(pool_size=(2,2,2)))\n",
    "\n",
    "model.add(Conv3D(filters[1], \n",
    "                 kernel_size=(3,3,3), \n",
    "                 padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(MaxPooling3D(pool_size=(2,2,2)))\n",
    "\n",
    "model.add(Conv3D(filters[2], \n",
    "                 kernel_size=(1,3,3), \n",
    "                 padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(MaxPooling3D(pool_size=(2,2,2)))\n",
    "\n",
    "model.add(Conv3D(filters[3], \n",
    "                 kernel_size=(1,3,3), \n",
    "                 padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(MaxPooling3D(pool_size=(2,2,2)))\n",
    "\n",
    "#Flatten Layers\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(dense[0], activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(dense[1], activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "#softmax layer\n",
    "model.add(Dense(dense[2], activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimiser = optimizers.Adam() #write your optimizer\n",
    "model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "print (model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = generator(train_path, train_doc, batch_size)\n",
    "val_generator = generator(val_path, val_doc, batch_size,validation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'model_init_Conv3D' + '_' + str(curr_dt_time).replace(' ','').replace(':','_') + '/'\n",
    "    \n",
    "if not os.path.exists(model_name):\n",
    "    os.mkdir(model_name)\n",
    "        \n",
    "filepath = model_name + 'model-{epoch:05d}-{loss:.5f}-{categorical_accuracy:.5f}-{val_loss:.5f}-{val_categorical_accuracy:.5f}.h5'\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath, save_best_only=True, monitor='val_loss', verbose=1, save_weights_only=False, mode='auto', period=1)\n",
    "\n",
    "# write the Reducelronplateau code here\n",
    "LR = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, cooldown=1, verbose=1)\n",
    "callbacks_list = [checkpoint, LR]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (num_train_sequences%batch_size) == 0:\n",
    "    steps_per_epoch = int(num_train_sequences/batch_size)\n",
    "else:\n",
    "    steps_per_epoch = (num_train_sequences//batch_size) + 1\n",
    "\n",
    "if (num_val_sequences%batch_size) == 0:\n",
    "    validation_steps = int(num_val_sequences/batch_size)\n",
    "else:\n",
    "    validation_steps = (num_val_sequences//batch_size) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 10\n",
    "num_epochs = 20\n",
    "model_history = model.fit_generator(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
    "                   callbacks=callbacks_list, validation_data=val_generator, \n",
    "                   validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(model_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Increasing dense perceptrons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes= 5\n",
    "input_shape = (frames, rows, cols, channels)\n",
    "\n",
    "nb_filters = [8,16,32,64]\n",
    "nb_dense = [1000, 500, 5]\n",
    "\n",
    "# Define model\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv3D(nb_filters[0], \n",
    "                 kernel_size=(3,3,3), \n",
    "                 input_shape=input_shape,\n",
    "                 padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(MaxPooling3D(pool_size=(2,2,2)))\n",
    "\n",
    "model.add(Conv3D(nb_filters[1], \n",
    "                 kernel_size=(3,3,3), \n",
    "                 padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(MaxPooling3D(pool_size=(2,2,2)))\n",
    "\n",
    "model.add(Conv3D(nb_filters[2], \n",
    "                 kernel_size=(1,3,3), \n",
    "                 padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(MaxPooling3D(pool_size=(2,2,2)))\n",
    "\n",
    "model.add(Conv3D(nb_filters[3], \n",
    "                 kernel_size=(1,3,3), \n",
    "                 padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(MaxPooling3D(pool_size=(2,2,2)))\n",
    "\n",
    "#Flatten Layers\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(nb_dense[0], activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(nb_dense[1], activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "#softmax layer\n",
    "model.add(Dense(nb_dense[2], activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimiser = optimizers.Adam() #write your optimizer\n",
    "model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "print (model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = generator(train_path, train_doc, batch_size)\n",
    "val_generator = generator(val_path, val_doc, batch_size,validation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'model_init_Conv3D' + '_' + str(curr_dt_time).replace(' ','').replace(':','_') + '/'\n",
    "    \n",
    "if not os.path.exists(model_name):\n",
    "    os.mkdir(model_name)\n",
    "        \n",
    "filepath = model_name + 'model-{epoch:05d}-{loss:.5f}-{categorical_accuracy:.5f}-{val_loss:.5f}-{val_categorical_accuracy:.5f}.h5'\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath, save_best_only=True, monitor='val_loss', verbose=1, save_weights_only=False, mode='auto', period=1)\n",
    "\n",
    "# write the Reducelronplateau code here\n",
    "LR = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, cooldown=1, verbose=1)\n",
    "callbacks_list = [checkpoint, LR]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (num_train_sequences%batch_size) == 0:\n",
    "    steps_per_epoch = int(num_train_sequences/batch_size)\n",
    "else:\n",
    "    steps_per_epoch = (num_train_sequences//batch_size) + 1\n",
    "\n",
    "if (num_val_sequences%batch_size) == 0:\n",
    "    validation_steps = int(num_val_sequences/batch_size)\n",
    "else:\n",
    "    validation_steps = (num_val_sequences//batch_size) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 10\n",
    "num_epochs = 20\n",
    "model_history = model.fit_generator(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
    "                   callbacks=callbacks_list, validation_data=val_generator, \n",
    "                   validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(model_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding one extra layer with dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes= 5\n",
    "input_shape = (frames, rows, cols, channels)\n",
    "\n",
    "nb_filters = [8, 16, 32, 64, 128]\n",
    "nb_dense = [1000, 500, 5]\n",
    "\n",
    "# Define model\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv3D(nb_filters[0], \n",
    "                 kernel_size=(3,3,3), \n",
    "                 input_shape=input_shape,\n",
    "                 padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(MaxPooling3D(pool_size=(2,2,2)))\n",
    "\n",
    "model.add(Conv3D(nb_filters[1], \n",
    "                 kernel_size=(3,3,3), \n",
    "                 padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(MaxPooling3D(pool_size=(2,2,2)))\n",
    "\n",
    "model.add(Conv3D(nb_filters[2], \n",
    "                 kernel_size=(1,3,3), \n",
    "                 padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(MaxPooling3D(pool_size=(2,2,2)))\n",
    "\n",
    "model.add(Conv3D(nb_filters[3], \n",
    "                 kernel_size=(1,3,3), \n",
    "                 padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv3D(nb_filters[4], \n",
    "                 kernel_size=(1,3,3), \n",
    "                 padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(MaxPooling3D(pool_size=(2,2,2)))\n",
    "\n",
    "\n",
    "#Flatten Layers\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(nb_dense[0], activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(nb_dense[1], activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "#softmax layer\n",
    "model.add(Dense(nb_dense[2], activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimiser = optimizers.Adam() #write your optimizer\n",
    "model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "print (model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = generator(train_path, train_doc, batch_size)\n",
    "val_generator = generator(val_path, val_doc, batch_size,validation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'model_init_Conv3D' + '_' + str(curr_dt_time).replace(' ','').replace(':','_') + '/'\n",
    "    \n",
    "if not os.path.exists(model_name):\n",
    "    os.mkdir(model_name)\n",
    "        \n",
    "filepath = model_name + 'model-{epoch:05d}-{loss:.5f}-{categorical_accuracy:.5f}-{val_loss:.5f}-{val_categorical_accuracy:.5f}.h5'\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath, save_best_only=True, monitor='val_loss', verbose=1, save_weights_only=False, mode='auto', period=1)\n",
    "\n",
    "# write the Reducelronplateau code here\n",
    "LR = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, cooldown=1, verbose=1)\n",
    "callbacks_list = [checkpoint, LR]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (num_train_sequences%batch_size) == 0:\n",
    "    steps_per_epoch = int(num_train_sequences/batch_size)\n",
    "else:\n",
    "    steps_per_epoch = (num_train_sequences//batch_size) + 1\n",
    "\n",
    "if (num_val_sequences%batch_size) == 0:\n",
    "    validation_steps = int(num_val_sequences/batch_size)\n",
    "else:\n",
    "    validation_steps = (num_val_sequences//batch_size) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 10\n",
    "num_epochs = 20\n",
    "model_history = model.fit_generator(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
    "                   callbacks=callbacks_list, validation_data=val_generator, \n",
    "                   validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(model_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding one more layer with BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes= 5\n",
    "input_shape = (frames, rows, cols, channels)\n",
    "\n",
    "nb_filters = [8, 16, 32, 64, 128, 256]\n",
    "nb_dense = [1000, 500, 5]\n",
    "\n",
    "# Define model\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv3D(nb_filters[0], \n",
    "                 kernel_size=(3,3,3), \n",
    "                 input_shape=input_shape,\n",
    "                 padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(MaxPooling3D(pool_size=(2,2,2)))\n",
    "\n",
    "model.add(Conv3D(nb_filters[1], \n",
    "                 kernel_size=(3,3,3), \n",
    "                 padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(MaxPooling3D(pool_size=(2,2,2)))\n",
    "\n",
    "model.add(Conv3D(nb_filters[2], \n",
    "                 kernel_size=(1,3,3), \n",
    "                 padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Conv3D(nb_filters[3], \n",
    "                 kernel_size=(1,3,3), \n",
    "                 padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(MaxPooling3D(pool_size=(2,2,2)))\n",
    "\n",
    "model.add(Conv3D(nb_filters[4], \n",
    "                 kernel_size=(1,3,3), \n",
    "                 padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv3D(nb_filters[5], \n",
    "                 kernel_size=(1,3,3), \n",
    "                 padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(MaxPooling3D(pool_size=(2,2,2)))\n",
    "\n",
    "\n",
    "#Flatten Layers\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(nb_dense[0], activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(nb_dense[1], activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "#softmax layer\n",
    "model.add(Dense(nb_dense[2], activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimiser = optimizers.Adam() #write your optimizer\n",
    "model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "print (model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = generator(train_path, train_doc, batch_size)\n",
    "val_generator = generator(val_path, val_doc, batch_size,validation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'model_init_Conv3D' + '_' + str(curr_dt_time).replace(' ','').replace(':','_') + '/'\n",
    "    \n",
    "if not os.path.exists(model_name):\n",
    "    os.mkdir(model_name)\n",
    "        \n",
    "filepath = model_name + 'model-{epoch:05d}-{loss:.5f}-{categorical_accuracy:.5f}-{val_loss:.5f}-{val_categorical_accuracy:.5f}.h5'\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath, save_best_only=True, monitor='val_loss', verbose=1, save_weights_only=False, mode='auto', period=1)\n",
    "\n",
    "# write the Reducelronplateau code here\n",
    "LR = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, cooldown=1, verbose=1)\n",
    "callbacks_list = [checkpoint, LR]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (num_train_sequences%batch_size) == 0:\n",
    "    steps_per_epoch = int(num_train_sequences/batch_size)\n",
    "else:\n",
    "    steps_per_epoch = (num_train_sequences//batch_size) + 1\n",
    "\n",
    "if (num_val_sequences%batch_size) == 0:\n",
    "    validation_steps = int(num_val_sequences/batch_size)\n",
    "else:\n",
    "    validation_steps = (num_val_sequences//batch_size) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 10\n",
    "num_epochs = 20\n",
    "model_history = model.fit_generator(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
    "                   callbacks=callbacks_list, validation_data=val_generator, \n",
    "                   validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(model_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reduce the filter size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes= 5\n",
    "input_shape = (frames, rows, cols, channels)\n",
    "\n",
    "nb_filters = [8, 16, 32, 64, 128, 256]\n",
    "nb_dense = [1000, 500, 5]\n",
    "\n",
    "# Define model\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv3D(nb_filters[0], \n",
    "                 kernel_size=(2,2,2), \n",
    "                 input_shape=input_shape,\n",
    "                 padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(MaxPooling3D(pool_size=(2,2,2)))\n",
    "\n",
    "model.add(Conv3D(nb_filters[1], \n",
    "                 kernel_size=(2,2,2), \n",
    "                 padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(MaxPooling3D(pool_size=(2,2,2)))\n",
    "\n",
    "model.add(Conv3D(nb_filters[2], \n",
    "                 kernel_size=(1,3,3), \n",
    "                 padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Conv3D(nb_filters[3], \n",
    "                 kernel_size=(1,3,3), \n",
    "                 padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(MaxPooling3D(pool_size=(2,2,2)))\n",
    "\n",
    "model.add(Conv3D(nb_filters[4], \n",
    "                 kernel_size=(1,3,3), \n",
    "                 padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv3D(nb_filters[5], \n",
    "                 kernel_size=(1,3,3), \n",
    "                 padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(MaxPooling3D(pool_size=(2,2,2)))\n",
    "\n",
    "\n",
    "#Flatten Layers\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(nb_dense[0], activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(nb_dense[1], activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "#softmax layer\n",
    "model.add(Dense(nb_dense[2], activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimiser = optimizers.Adam() #write your optimizer\n",
    "model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "print (model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = generator(train_path, train_doc, batch_size)\n",
    "val_generator = generator(val_path, val_doc, batch_size,validation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'model_init_Conv3D' + '_' + str(curr_dt_time).replace(' ','').replace(':','_') + '/'\n",
    "    \n",
    "if not os.path.exists(model_name):\n",
    "    os.mkdir(model_name)\n",
    "        \n",
    "filepath = model_name + 'model-{epoch:05d}-{loss:.5f}-{categorical_accuracy:.5f}-{val_loss:.5f}-{val_categorical_accuracy:.5f}.h5'\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath, save_best_only=True, monitor='val_loss', verbose=1, save_weights_only=False, mode='auto', period=1)\n",
    "\n",
    "# write the Reducelronplateau code here\n",
    "LR = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, cooldown=1, verbose=1)\n",
    "callbacks_list = [checkpoint, LR]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (num_train_sequences%batch_size) == 0:\n",
    "    steps_per_epoch = int(num_train_sequences/batch_size)\n",
    "else:\n",
    "    steps_per_epoch = (num_train_sequences//batch_size) + 1\n",
    "\n",
    "if (num_val_sequences%batch_size) == 0:\n",
    "    validation_steps = int(num_val_sequences/batch_size)\n",
    "else:\n",
    "    validation_steps = (num_val_sequences//batch_size) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 10\n",
    "num_epochs = 20\n",
    "model_history = model.fit_generator(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
    "                   callbacks=callbacks_list, validation_data=val_generator, \n",
    "                   validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(model_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reduce the filter size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes= 5\n",
    "input_shape = (frames, rows, cols, channels)\n",
    "\n",
    "nb_filters = [8, 16, 32, 64, 128, 256]\n",
    "nb_dense = [1000, 500, 5]\n",
    "\n",
    "# Define model\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv3D(nb_filters[0], \n",
    "                 kernel_size=(2,2,2), \n",
    "                 input_shape=input_shape,\n",
    "                 padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(MaxPooling3D(pool_size=(2,2,2)))\n",
    "\n",
    "model.add(Conv3D(nb_filters[1], \n",
    "                 kernel_size=(2,2,2), \n",
    "                 padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(MaxPooling3D(pool_size=(2,2,2)))\n",
    "\n",
    "model.add(Conv3D(nb_filters[2], \n",
    "                 kernel_size=(1,3,3), \n",
    "                 padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Conv3D(nb_filters[3], \n",
    "                 kernel_size=(1,3,3), \n",
    "                 padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(MaxPooling3D(pool_size=(2,2,2)))\n",
    "\n",
    "model.add(Conv3D(nb_filters[4], \n",
    "                 kernel_size=(1,3,3), \n",
    "                 padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv3D(nb_filters[5], \n",
    "                 kernel_size=(1,3,3), \n",
    "                 padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(MaxPooling3D(pool_size=(2,2,2)))\n",
    "\n",
    "\n",
    "#Flatten Layers\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(nb_dense[0], activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(nb_dense[1], activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "#softmax layer\n",
    "model.add(Dense(nb_dense[2], activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv3d_7 (Conv3D)            (None, 30, 120, 120, 8)   200       \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 30, 120, 120, 8)   32        \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 30, 120, 120, 8)   0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_5 (MaxPooling3 (None, 15, 60, 60, 8)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_8 (Conv3D)            (None, 15, 60, 60, 16)    1040      \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 15, 60, 60, 16)    64        \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 15, 60, 60, 16)    0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_6 (MaxPooling3 (None, 7, 30, 30, 16)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_9 (Conv3D)            (None, 7, 30, 30, 32)     4640      \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 7, 30, 30, 32)     128       \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 7, 30, 30, 32)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_10 (Conv3D)           (None, 7, 30, 30, 64)     18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 7, 30, 30, 64)     256       \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 7, 30, 30, 64)     0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_7 (MaxPooling3 (None, 3, 15, 15, 64)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_11 (Conv3D)           (None, 3, 15, 15, 128)    73856     \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 3, 15, 15, 128)    0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 3, 15, 15, 128)    0         \n",
      "_________________________________________________________________\n",
      "conv3d_12 (Conv3D)           (None, 3, 15, 15, 256)    295168    \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 3, 15, 15, 256)    0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 3, 15, 15, 256)    0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_8 (MaxPooling3 (None, 1, 7, 7, 256)      0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 12544)             0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1000)              12545000  \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 500)               500500    \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 5)                 2505      \n",
      "=================================================================\n",
      "Total params: 13,441,885\n",
      "Trainable params: 13,441,645\n",
      "Non-trainable params: 240\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "optimiser = optimizers.Adam() #write your optimizer\n",
    "model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "print (model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = generator(train_path, train_doc, batch_size)\n",
    "val_generator = generator(val_path, val_doc, batch_size,validation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_dt_time = datetime.datetime.now()\n",
    "model_name = 'model_init_Conv3D' + '_' + str(curr_dt_time).replace(' ','').replace(':','_') + '/'\n",
    "    \n",
    "if not os.path.exists(model_name):\n",
    "    os.mkdir(model_name)\n",
    "        \n",
    "filepath = model_name + 'model-{epoch:05d}-{loss:.5f}-{categorical_accuracy:.5f}-{val_loss:.5f}-{val_categorical_accuracy:.5f}.h5'\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath, save_best_only=True, monitor='val_loss', verbose=1, save_weights_only=False, mode='auto', period=1)\n",
    "\n",
    "# write the Reducelronplateau code here\n",
    "LR = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, cooldown=1, verbose=1)\n",
    "callbacks_list = [checkpoint, LR]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (num_train_sequences%batch_size) == 0:\n",
    "    steps_per_epoch = int(num_train_sequences/batch_size)\n",
    "else:\n",
    "    steps_per_epoch = (num_train_sequences//batch_size) + 1\n",
    "\n",
    "if (num_val_sequences%batch_size) == 0:\n",
    "    validation_steps = int(num_val_sequences/batch_size)\n",
    "else:\n",
    "    validation_steps = (num_val_sequences//batch_size) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source path =  Project_data/val ; batch size = 30\n",
      "Source path =  Project_data/train ; batch size = 30\n",
      "Epoch 1/20\n",
      "23/23 [==============================] - 172s 7s/step - loss: 2.3875 - categorical_accuracy: 0.2622 - val_loss: 1.5937 - val_categorical_accuracy: 0.2700\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.59374, saving model to model_init_Conv3D_2020-11-0817_04_48.865669/model-00001-2.42762-0.25943-1.59374-0.27000.h5\n",
      "Epoch 2/20\n",
      "23/23 [==============================] - 16s 690ms/step - loss: 1.6744 - categorical_accuracy: 0.2512 - val_loss: 1.5825 - val_categorical_accuracy: 0.2750\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.59374 to 1.58246, saving model to model_init_Conv3D_2020-11-0817_04_48.865669/model-00002-1.67440-0.25121-1.58246-0.27500.h5\n",
      "Epoch 3/20\n",
      "23/23 [==============================] - 19s 841ms/step - loss: 1.6133 - categorical_accuracy: 0.2560 - val_loss: 1.6065 - val_categorical_accuracy: 0.2000\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1.58246\n",
      "Epoch 4/20\n",
      "23/23 [==============================] - 20s 876ms/step - loss: 1.6058 - categorical_accuracy: 0.2077 - val_loss: 1.6121 - val_categorical_accuracy: 0.1250\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.58246\n",
      "\n",
      "Epoch 00004: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 5/20\n",
      "23/23 [==============================] - 26s 1s/step - loss: 1.6002 - categorical_accuracy: 0.2464 - val_loss: 1.6172 - val_categorical_accuracy: 0.1000\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1.58246\n",
      "Epoch 6/20\n",
      "23/23 [==============================] - 20s 875ms/step - loss: 1.5191 - categorical_accuracy: 0.3092 - val_loss: 1.4314 - val_categorical_accuracy: 0.3250\n",
      "\n",
      "Epoch 00006: val_loss improved from 1.58246 to 1.43142, saving model to model_init_Conv3D_2020-11-0817_04_48.865669/model-00006-1.51908-0.30918-1.43142-0.32500.h5\n",
      "Epoch 7/20\n",
      "23/23 [==============================] - 25s 1s/step - loss: 1.5039 - categorical_accuracy: 0.2705 - val_loss: 1.4168 - val_categorical_accuracy: 0.4750\n",
      "\n",
      "Epoch 00007: val_loss improved from 1.43142 to 1.41679, saving model to model_init_Conv3D_2020-11-0817_04_48.865669/model-00007-1.50387-0.27053-1.41679-0.47500.h5\n",
      "Epoch 8/20\n",
      "23/23 [==============================] - 18s 775ms/step - loss: 1.5968 - categorical_accuracy: 0.2657 - val_loss: 1.4817 - val_categorical_accuracy: 0.5000\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1.41679\n",
      "Epoch 9/20\n",
      "23/23 [==============================] - 15s 664ms/step - loss: 1.5062 - categorical_accuracy: 0.3285 - val_loss: 1.5820 - val_categorical_accuracy: 0.1500\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 1.41679\n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 10/20\n",
      "23/23 [==============================] - 15s 635ms/step - loss: 1.5058 - categorical_accuracy: 0.2657 - val_loss: 1.4642 - val_categorical_accuracy: 0.4250\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 1.41679\n",
      "Epoch 11/20\n",
      "23/23 [==============================] - 16s 678ms/step - loss: 1.2572 - categorical_accuracy: 0.4831 - val_loss: 1.4330 - val_categorical_accuracy: 0.3750\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 1.41679\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 12/20\n",
      "23/23 [==============================] - 15s 659ms/step - loss: 1.1611 - categorical_accuracy: 0.5604 - val_loss: 1.2878 - val_categorical_accuracy: 0.4000\n",
      "\n",
      "Epoch 00012: val_loss improved from 1.41679 to 1.28779, saving model to model_init_Conv3D_2020-11-0817_04_48.865669/model-00012-1.16111-0.56039-1.28779-0.40000.h5\n",
      "Epoch 13/20\n",
      "23/23 [==============================] - 16s 683ms/step - loss: 1.1014 - categorical_accuracy: 0.5169 - val_loss: 1.2611 - val_categorical_accuracy: 0.5250\n",
      "\n",
      "Epoch 00013: val_loss improved from 1.28779 to 1.26107, saving model to model_init_Conv3D_2020-11-0817_04_48.865669/model-00013-1.10138-0.51691-1.26107-0.52500.h5\n",
      "Epoch 14/20\n",
      "23/23 [==============================] - 16s 694ms/step - loss: 1.2014 - categorical_accuracy: 0.5072 - val_loss: 1.3403 - val_categorical_accuracy: 0.4000\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 1.26107\n",
      "Epoch 15/20\n",
      "23/23 [==============================] - 15s 643ms/step - loss: 1.2906 - categorical_accuracy: 0.4493 - val_loss: 1.2768 - val_categorical_accuracy: 0.5000\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 1.26107\n",
      "\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Epoch 16/20\n",
      "23/23 [==============================] - 15s 665ms/step - loss: 1.1002 - categorical_accuracy: 0.5942 - val_loss: 1.1782 - val_categorical_accuracy: 0.4750\n",
      "\n",
      "Epoch 00016: val_loss improved from 1.26107 to 1.17818, saving model to model_init_Conv3D_2020-11-0817_04_48.865669/model-00016-1.10017-0.59420-1.17818-0.47500.h5\n",
      "Epoch 17/20\n",
      "23/23 [==============================] - 16s 677ms/step - loss: 1.0442 - categorical_accuracy: 0.5797 - val_loss: 1.1827 - val_categorical_accuracy: 0.4500\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 1.17818\n",
      "Epoch 18/20\n",
      "23/23 [==============================] - 16s 710ms/step - loss: 1.0776 - categorical_accuracy: 0.5169 - val_loss: 1.0079 - val_categorical_accuracy: 0.5250\n",
      "\n",
      "Epoch 00018: val_loss improved from 1.17818 to 1.00789, saving model to model_init_Conv3D_2020-11-0817_04_48.865669/model-00018-1.07756-0.51691-1.00789-0.52500.h5\n",
      "Epoch 19/20\n",
      "23/23 [==============================] - 16s 692ms/step - loss: 1.2324 - categorical_accuracy: 0.5169 - val_loss: 1.0980 - val_categorical_accuracy: 0.5250\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 1.00789\n",
      "Epoch 20/20\n",
      "23/23 [==============================] - 16s 682ms/step - loss: 1.0849 - categorical_accuracy: 0.5749 - val_loss: 0.9909 - val_categorical_accuracy: 0.5500\n",
      "\n",
      "Epoch 00020: val_loss improved from 1.00789 to 0.99092, saving model to model_init_Conv3D_2020-11-0817_04_48.865669/model-00020-1.08486-0.57488-0.99092-0.55000.h5\n"
     ]
    }
   ],
   "source": [
    "batch_size = 10\n",
    "num_epochs = 20\n",
    "model_history = model.fit_generator(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
    "                   callbacks=callbacks_list, validation_data=val_generator, \n",
    "                   validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot(model_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Neural_Nets_Project_Starter_Code.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
