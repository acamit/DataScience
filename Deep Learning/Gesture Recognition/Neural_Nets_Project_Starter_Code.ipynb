{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VDqMakhdmxeZ"
   },
   "source": [
    "# Gesture Recognition\n",
    "In this group project, you are going to build a 3D Conv model that will be able to predict the 5 gestures correctly. Please import the following libraries to get started."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1264,
     "status": "ok",
     "timestamp": 1604436124652,
     "user": {
      "displayName": "Amit Chawla",
      "photoUrl": "",
      "userId": "06080236380106251748"
     },
     "user_tz": -330
    },
    "id": "BTT3MufZmxeZ",
    "outputId": "202516b5-292f-4a5e-faeb-b3e5f5bbdc16"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 1905,
     "status": "ok",
     "timestamp": 1604436125310,
     "user": {
      "displayName": "Amit Chawla",
      "photoUrl": "",
      "userId": "06080236380106251748"
     },
     "user_tz": -330
    },
    "id": "ObsTCqZGmxef"
   },
   "outputs": [],
   "source": [
    "# import os\n",
    "# os.environ['KAGGLE_CONFIG_DIR'] = \"/content/gdrive/My Drive/Colab Notebooks\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1893,
     "status": "ok",
     "timestamp": 1604436125311,
     "user": {
      "displayName": "Amit Chawla",
      "photoUrl": "",
      "userId": "06080236380106251748"
     },
     "user_tz": -330
    },
    "id": "5uHfxQ0amxeh",
    "outputId": "0263a77f-532a-4474-8514-fb75cc4c17fb"
   },
   "outputs": [],
   "source": [
    "# %cd /content/gdrive/My Drive/Colab Notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 3407,
     "status": "ok",
     "timestamp": 1604436126836,
     "user": {
      "displayName": "Amit Chawla",
      "photoUrl": "",
      "userId": "06080236380106251748"
     },
     "user_tz": -330
    },
    "id": "TQBPqv4tmxek"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "# from scipy.misc import imread, imresize\n",
    "import datetime\n",
    "import os\n",
    "import keras\n",
    "from skimage import io\n",
    "from skimage.transform import rescale, resize\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter \n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tGWWjZmWmxem"
   },
   "source": [
    "We set the random seed so that the results don't vary drastically."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uIgjhwHP1K4S"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 3405,
     "status": "ok",
     "timestamp": 1604436126840,
     "user": {
      "displayName": "Amit Chawla",
      "photoUrl": "",
      "userId": "06080236380106251748"
     },
     "user_tz": -330
    },
    "id": "WMQ8D_b7mxen"
   },
   "outputs": [],
   "source": [
    "np.random.seed(30)\n",
    "import random as rn\n",
    "# rn.seed(30) #disabled for experimenting\n",
    "from keras import backend as K\n",
    "import tensorflow as tf\n",
    "# tf.set_random_seed(30)\n",
    "tf.random.set_seed(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ElbM_EOhmxep"
   },
   "source": [
    "In this block, you read the folder names for training and validation. You also set the `batch_size` here. Note that you set the batch size in such a way that you are able to use the GPU in full capacity. You keep increasing the batch size until the machine throws an error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 3398,
     "status": "ok",
     "timestamp": 1604436126840,
     "user": {
      "displayName": "Amit Chawla",
      "photoUrl": "",
      "userId": "06080236380106251748"
     },
     "user_tz": -330
    },
    "id": "Ktl51Bgjmxeq"
   },
   "outputs": [],
   "source": [
    "train_doc = np.random.permutation(open('Project_data/train.csv').readlines())\n",
    "val_doc = np.random.permutation(open('Project_data/val.csv').readlines())\n",
    "# train_doc=train_doc[:100]\n",
    "# val_doc = val_doc[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 3392,
     "status": "ok",
     "timestamp": 1604436126841,
     "user": {
      "displayName": "Amit Chawla",
      "photoUrl": "",
      "userId": "06080236380106251748"
     },
     "user_tz": -330
    },
    "id": "iXpH5G_Zmxes"
   },
   "outputs": [],
   "source": [
    "# we start with full train data as 1 batch\n",
    "batch_size = 30 #experiment with the batch size\n",
    "\n",
    "# we start with 120*120 images and adjust these later for model building process\n",
    "frames = 30\n",
    "rows = 120 # final image height to be decided\n",
    "cols = 120 # final image width to be decided\n",
    "channels = 3\n",
    "step_size = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 3381,
     "status": "ok",
     "timestamp": 1604436126841,
     "user": {
      "displayName": "Amit Chawla",
      "photoUrl": "",
      "userId": "06080236380106251748"
     },
     "user_tz": -330
    },
    "id": "13E1RyUxmxew"
   },
   "outputs": [],
   "source": [
    "# we distribute the images on the basis of size. This is just done for experiment puroposes later.\n",
    "# outpaths = [train_path] #val_path\n",
    "def image_segregation(path='train'):\n",
    "    final_120 =[]\n",
    "    final_360=[]\n",
    "    doc = ''\n",
    "    if(path=='train'):\n",
    "        op = 'Project_data/train/'\n",
    "        doc = train_doc\n",
    "    else:\n",
    "        op = 'Project_data/val/'\n",
    "        doc = val_doc\n",
    "    for f in doc:\n",
    "        path = f.split(';')[0]\n",
    "        imgs = os.listdir(op+path)\n",
    "        for img in imgs:\n",
    "            image = io.imread(op+path+'/'+img)\n",
    "            if(image.shape[0]==360):\n",
    "                final_120.append(op+path+'/'+img) \n",
    "\n",
    "            if(image.shape[0]==120):\n",
    "                final_360.append(op+path+'/'+img)\n",
    "    return (final_120, final_360)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 3376,
     "status": "ok",
     "timestamp": 1604436126842,
     "user": {
      "displayName": "Amit Chawla",
      "photoUrl": "",
      "userId": "06080236380106251748"
     },
     "user_tz": -330
    },
    "id": "HXYE041rmxey"
   },
   "outputs": [],
   "source": [
    "# make list of images with corresponding sizes\n",
    "# final_120, final_360 = image_segregation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 3370,
     "status": "ok",
     "timestamp": 1604436126842,
     "user": {
      "displayName": "Amit Chawla",
      "photoUrl": "",
      "userId": "06080236380106251748"
     },
     "user_tz": -330
    },
    "id": "wNbx3UeNmxe1"
   },
   "outputs": [],
   "source": [
    "# # view random imagees\n",
    "# selectedIndexes  = []\n",
    "# for i in range(3):\n",
    "#     selectedIndexes.append(rn.randint(0,5520))\n",
    "\n",
    "\n",
    "# s_im_120 = [final_120[i] for i in selectedIndexes]\n",
    "# s_im_360 = [final_360[i] for i in selectedIndexes]\n",
    "# print(s_im_120)\n",
    "# print(s_im_360)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VwHEJ0ajmxe4"
   },
   "source": [
    "## Generator\n",
    "This is one of the most important part of the code. The overall structure of the generator has been given. In the generator, you are going to preprocess the images as you have images of 2 different dimensions as well as create a batch of video frames. You have to experiment with `img_idx`, `y`,`z` and normalization such that you get high accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 3362,
     "status": "ok",
     "timestamp": 1604436126842,
     "user": {
      "displayName": "Amit Chawla",
      "photoUrl": "",
      "userId": "06080236380106251748"
     },
     "user_tz": -330
    },
    "id": "bZVAwtRLmxe4"
   },
   "outputs": [],
   "source": [
    "def cropImage(image):\n",
    "    (image_h, image_w, _) = image.shape\n",
    "    \n",
    "    h_start=0\n",
    "    h_end = image_h\n",
    "    w_start=0\n",
    "    w_end = image_w\n",
    "    if(image_h==120):\n",
    "        h_start=20\n",
    "        w_start=10\n",
    "        w_end = 120\n",
    "    elif image_h==360:\n",
    "        h_start=30\n",
    "        w_start=30\n",
    "        w_end = 320\n",
    "    return image[h_start:h_end, w_start:w_end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 3351,
     "status": "ok",
     "timestamp": 1604436126843,
     "user": {
      "displayName": "Amit Chawla",
      "photoUrl": "",
      "userId": "06080236380106251748"
     },
     "user_tz": -330
    },
    "id": "iPDq9Y_qmxe7"
   },
   "outputs": [],
   "source": [
    "def resize_image(image, height=rows, width=cols):\n",
    "    return  resize(image, (height, width),anti_aliasing=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "executionInfo": {
     "elapsed": 3344,
     "status": "ok",
     "timestamp": 1604436126844,
     "user": {
      "displayName": "Amit Chawla",
      "photoUrl": "",
      "userId": "06080236380106251748"
     },
     "user_tz": -330
    },
    "id": "VtA2DmeHmxe9"
   },
   "outputs": [],
   "source": [
    "def normalize_image(image):\n",
    "    norm_image = image - np.min(image)/np.max(image) - np.min(image)\n",
    "#     norm_image = image - np.percentile(image,5)/ np.percentile(image,95) - np.percentile(image,5)\n",
    "    return norm_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "executionInfo": {
     "elapsed": 3334,
     "status": "ok",
     "timestamp": 1604436126844,
     "user": {
      "displayName": "Amit Chawla",
      "photoUrl": "",
      "userId": "06080236380106251748"
     },
     "user_tz": -330
    },
    "id": "qZT62WCDmxfA"
   },
   "outputs": [],
   "source": [
    "#untility to show processed images\n",
    "def showImage(array, idx):\n",
    "    a = array[idx]\n",
    "    image = io.imread(a)\n",
    "    plt.subplot(2, 2,1)\n",
    "    plt.imshow(image)\n",
    "\n",
    "    cropped = cropImage(image)\n",
    "    plt.subplot(2,2,2)\n",
    "    plt.imshow(cropped)\n",
    "\n",
    "    resized = resize_image(cropped)\n",
    "    plt.subplot(2, 2,3)\n",
    "    plt.imshow(resized)\n",
    "\n",
    "    \n",
    "    normalized = normalize_image(resized)\n",
    "    plt.subplot(2, 2,4)\n",
    "    plt.imshow(normalized)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "executionInfo": {
     "elapsed": 3327,
     "status": "ok",
     "timestamp": 1604436126845,
     "user": {
      "displayName": "Amit Chawla",
      "photoUrl": "",
      "userId": "06080236380106251748"
     },
     "user_tz": -330
    },
    "id": "K7tnO7qMmxfE"
   },
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(300,300))\n",
    "# showImage(s_im_360, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "executionInfo": {
     "elapsed": 3320,
     "status": "ok",
     "timestamp": 1604436126845,
     "user": {
      "displayName": "Amit Chawla",
      "photoUrl": "",
      "userId": "06080236380106251748"
     },
     "user_tz": -330
    },
    "id": "BsJO0HlMmxfG"
   },
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(300,300))\n",
    "# showImage(s_im_120, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to generate a random affine transform on the iamge\n",
    "def get_random_affine():\n",
    "    dx, dy = np.random.randint(-1.7, 1.8, 2)\n",
    "    M = np.float32([[1, 0, dx], [0, 1, dy]])\n",
    "    return M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to initialize all the batch image data and labels\n",
    "def init_batch_data(batch_size):\n",
    "    batch_data = np.zeros((batch_size, frames, rows, cols, channels)) \n",
    "    batch_labels = np.zeros((batch_size,5)) # batch_labels is the one hot representation of the output\n",
    "    return batch_data, batch_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "executionInfo": {
     "elapsed": 3313,
     "status": "ok",
     "timestamp": 1604436126846,
     "user": {
      "displayName": "Amit Chawla",
      "photoUrl": "",
      "userId": "06080236380106251748"
     },
     "user_tz": -330
    },
    "id": "d6X9RiBtmSxp"
   },
   "outputs": [],
   "source": [
    "\n",
    "def fetch_aug_batchdata(source_path, folder_list, batch_num, batch_size, t,validation):\n",
    "    \n",
    "    batch_data,batch_labels = init_batch_data(batch_size)\n",
    "    \n",
    "    # We will also build an augumented batch data with affine transformation\n",
    "    batch_data_aug,batch_labels_aug = init_batch_data(batch_size)\n",
    "    \n",
    "    # We will also build an augmented batch data with horizontal flip\n",
    "    batch_data_flip,batch_labels_flip = init_batch_data(batch_size)\n",
    "    \n",
    "    #create a list of image numbers you want to use for a particular video using full frames\n",
    "    img_idx = [x for x in range(0, frames)] \n",
    "\n",
    "    for folder in range(batch_size): # iterate over the batch_size\n",
    "        # read all the images in the folder\n",
    "        imgs = sorted(os.listdir(source_path+'/'+ t[folder + (batch_num*batch_size)].split(';')[0])) \n",
    "        # Generate a random affine to be used in image transformation for buidling agumented data set\n",
    "        M = get_random_affine()\n",
    "        \n",
    "        #  Iterate over the frames/images of a folder to read them in\n",
    "        for idx, item in enumerate(img_idx): \n",
    "            ## image = imread(source_path+'/'+ t[folder + (batch_num*batch_size)].strip().split(';')[0]+'/'+imgs[item]).astype(np.float32)\n",
    "            image = cv2.imread(source_path+'/'+ t[folder + (batch_num*batch_size)].strip().split(';')[0]+'/'+imgs[item], cv2.IMREAD_COLOR)\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "            \n",
    "            # Cropping non symmetric frames\n",
    "            if image.shape[0] != image.shape[1]:\n",
    "                image=image[0:120,20:140]\n",
    "            \n",
    "            #crop the images and resize them. Note that the images are of 2 different shape \n",
    "            #and the conv3D will throw error if the inputs in a batch have different shapes   \n",
    "            resized = cv2.resize(image, (rows, cols), interpolation = cv2.INTER_AREA)\n",
    "            #Normal data\n",
    "            batch_data[folder,idx] = (resized)\n",
    "            \n",
    "            #Data with affine transformation\n",
    "            batch_data_aug[folder,idx] = (cv2.warpAffine(resized, M, (resized.shape[0], resized.shape[1])))\n",
    "            \n",
    "            # Data with horizontal flip\n",
    "            batch_data_flip[folder,idx]= np.flip(resized,1)\n",
    "\n",
    "        batch_labels[folder, int(t[folder + (batch_num*batch_size)].strip().split(';')[2])] = 1\n",
    "        batch_labels_aug[folder, int(t[folder + (batch_num*batch_size)].strip().split(';')[2])] = 1\n",
    "        \n",
    "        # Labeling data with horizobtal flip, right swipe becomes left swipe and viceversa\n",
    "        if int(t[folder + (batch_num*batch_size)].strip().split(';')[2])==0:\n",
    "                    batch_labels_flip[folder, 1] = 1\n",
    "        elif int(t[folder + (batch_num*batch_size)].strip().split(';')[2])==1:\n",
    "                    batch_labels_flip[folder, 0] = 1\n",
    "                    \n",
    "        else:\n",
    "                    batch_labels_flip[folder, int(t[folder + (batch_num*batch_size)].strip().split(';')[2])] = 1\n",
    "                  \n",
    "    \n",
    "    batch_data_final = np.append(batch_data, batch_data_aug, axis = 0)\n",
    "    batch_data_final = np.append(batch_data_final, batch_data_flip, axis = 0)\n",
    "\n",
    "    batch_labels_final = np.append(batch_labels, batch_labels_aug, axis = 0) \n",
    "    batch_labels_final = np.append(batch_labels_final, batch_labels_flip, axis = 0)\n",
    "    \n",
    "    if validation:\n",
    "        batch_data_final=batch_data\n",
    "        batch_labels_final= batch_labels\n",
    "        \n",
    "    return batch_data_final,batch_labels_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "executionInfo": {
     "elapsed": 3304,
     "status": "ok",
     "timestamp": 1604436126846,
     "user": {
      "displayName": "Amit Chawla",
      "photoUrl": "",
      "userId": "06080236380106251748"
     },
     "user_tz": -330
    },
    "id": "Sjjx0Zt6mxfI"
   },
   "outputs": [],
   "source": [
    "def generator(source_path, folder_list, batch_size, validation=False,ablation=None):\n",
    "    print( 'Source path = ', source_path, '; batch size =', batch_size)\n",
    "    if(ablation!=None):\n",
    "        folder_list=folder_list[:ablation]\n",
    "    while True:\n",
    "        t = np.random.permutation(folder_list)\n",
    "        num_batches = len(folder_list)//batch_size # calculate the number of batches\n",
    "        for batch in range(num_batches): # we iterate over the number of batches\n",
    "            # you yield the batch_data and the batch_labels, remember what does yield do\n",
    "            yield fetch_aug_batchdata(source_path, folder_list, batch, batch_size, t,validation)\n",
    "            \n",
    "        \n",
    "        # Code for the remaining data points which are left after full batches\n",
    "        if (len(folder_list) != batch_size*num_batches):\n",
    "            batch_size = len(folder_list) - (batch_size*num_batches)\n",
    "            yield fetch_aug_batchdata(source_path, folder_list, batch, batch_size, t,validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vS7SH2h6mxfK"
   },
   "source": [
    "Note here that a video is represented above in the generator as (number of images, height, width, number of channels). Take this into consideration while creating the model architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3297,
     "status": "ok",
     "timestamp": 1604436126847,
     "user": {
      "displayName": "Amit Chawla",
      "photoUrl": "",
      "userId": "06080236380106251748"
     },
     "user_tz": -330
    },
    "id": "1lAO-MjDmxfK",
    "outputId": "d71f8854-2608-4939-ebd4-42f6d0b4aa7a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# training sequences = 663\n",
      "# validation sequences = 100\n",
      "# epochs = 10\n"
     ]
    }
   ],
   "source": [
    "curr_dt_time = datetime.datetime.now()\n",
    "train_path = 'Project_data/train'\n",
    "val_path = 'Project_data/val'\n",
    "num_train_sequences = len(train_doc)\n",
    "print('# training sequences =', num_train_sequences)\n",
    "num_val_sequences = len(val_doc)\n",
    "print('# validation sequences =', num_val_sequences)\n",
    "num_epochs = 10 # choose the number of epochs\n",
    "print ('# epochs =', num_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0pSW5czRmxfO"
   },
   "source": [
    "## Model\n",
    "Here you make the model using different functionalities that Keras provides. Remember to use `Conv3D` and `MaxPooling3D` and not `Conv2D` and `Maxpooling2D` for a 3D convolution model. You would want to use `TimeDistributed` while building a Conv2D + RNN model. Also remember that the last layer is the softmax. Design the network in such a way that the model is able to give good accuracy on the least number of parameters so that it can fit in the memory of the webcam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "executionInfo": {
     "elapsed": 3291,
     "status": "ok",
     "timestamp": 1604436126847,
     "user": {
      "displayName": "Amit Chawla",
      "photoUrl": "",
      "userId": "06080236380106251748"
     },
     "user_tz": -330
    },
    "id": "oomrFBismxfO"
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, GRU, Flatten, TimeDistributed, Flatten, BatchNormalization, Activation, Dropout, LSTM, ZeroPadding3D\n",
    "from keras.layers.convolutional import Conv3D, MaxPooling3D, Conv2D, MaxPooling2D\n",
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras import optimizers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "executionInfo": {
     "elapsed": 4564,
     "status": "ok",
     "timestamp": 1604436128129,
     "user": {
      "displayName": "Amit Chawla",
      "photoUrl": "",
      "userId": "06080236380106251748"
     },
     "user_tz": -330
    },
    "id": "-Tlfx79bmxfR"
   },
   "outputs": [],
   "source": [
    "#write your model here\n",
    "\n",
    "feature_map=[8, 16, 32, 64, 128] # we will expirment with different number of features for different layers\n",
    "dense_layer_size = [1000,500,5]\n",
    "classes= 5\n",
    "input_shape = (frames, rows, cols, channels)\n",
    "model = Sequential()\n",
    "# add multiple convulation layers\n",
    "model.add(TimeDistributed(Conv2D(feature_map[0], (3, 3), strides=(2, 2),activation='relu', padding='same'), input_shape=input_shape))\n",
    "\n",
    "model.add(TimeDistributed(Conv2D(feature_map[1], (3,3),padding='same', activation='relu')))\n",
    "model.add(TimeDistributed(MaxPooling2D((2, 2), strides=(2, 2))))\n",
    "model.add(TimeDistributed(BatchNormalization()))\n",
    "\n",
    "# model.add(keras.layers.Dropout(0.4))\n",
    "\n",
    "model.add(TimeDistributed(Conv2D(feature_map[2], (3,3),padding='same', activation='relu')))\n",
    "model.add(TimeDistributed(MaxPooling2D((2, 2), strides=(2, 2))))\n",
    "# model.add(keras.layers.Dropout(0.4))\n",
    "model.add(TimeDistributed(BatchNormalization()))\n",
    "\n",
    "model.add(TimeDistributed(Conv2D(feature_map[3], (2,2),padding='same', activation='relu')))\n",
    "model.add(TimeDistributed(MaxPooling2D((2, 2), strides=(2, 2))))\n",
    "\n",
    "# model.add(TimeDistributed(Conv2D(feature_map[4], (2,2),padding='same', activation='relu')))\n",
    "# model.add(TimeDistributed(MaxPooling2D((2, 2), strides=(2, 2))))\n",
    "\n",
    "\n",
    "model.add(TimeDistributed(BatchNormalization()))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(TimeDistributed(Flatten()))\n",
    "\n",
    "model.add(Dense(dense_layer_size[0], activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(dense_layer_size[1], activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "## using GRU as the RNN model along with softmax as our last layer.\n",
    "model.add(GRU(128, return_sequences=False))\n",
    "model.add(Dense(classes, activation='softmax')) # using Softmax as last layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jKpo5LkKmxfT"
   },
   "source": [
    "Now that you have written the model, the next step is to `compile` the model. When you print the `summary` of the model, you'll see the total number of parameters you have to train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4560,
     "status": "ok",
     "timestamp": 1604436128130,
     "user": {
      "displayName": "Amit Chawla",
      "photoUrl": "",
      "userId": "06080236380106251748"
     },
     "user_tz": -330
    },
    "id": "NaRv2AivmxfU",
    "outputId": "44e90e46-23c6-4207-8810-a0dfbff59b37",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "time_distributed (TimeDistri (None, 30, 60, 60, 8)     224       \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (None, 30, 60, 60, 16)    1168      \n",
      "_________________________________________________________________\n",
      "time_distributed_2 (TimeDist (None, 30, 30, 30, 16)    0         \n",
      "_________________________________________________________________\n",
      "time_distributed_3 (TimeDist (None, 30, 30, 30, 32)    4640      \n",
      "_________________________________________________________________\n",
      "time_distributed_4 (TimeDist (None, 30, 15, 15, 32)    0         \n",
      "_________________________________________________________________\n",
      "time_distributed_5 (TimeDist (None, 30, 15, 15, 64)    8256      \n",
      "_________________________________________________________________\n",
      "time_distributed_6 (TimeDist (None, 30, 7, 7, 64)      0         \n",
      "_________________________________________________________________\n",
      "time_distributed_7 (TimeDist (None, 30, 7, 7, 64)      256       \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 30, 7, 7, 64)      0         \n",
      "_________________________________________________________________\n",
      "time_distributed_8 (TimeDist (None, 30, 3136)          0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 30, 128)           401536    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 30, 128)           0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 30, 64)            8256      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 30, 64)            0         \n",
      "_________________________________________________________________\n",
      "gru (GRU)                    (None, 128)               74496     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 5)                 645       \n",
      "=================================================================\n",
      "Total params: 499,477\n",
      "Trainable params: 499,349\n",
      "Non-trainable params: 128\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "optimiser = optimizers.Adam(0.001) #write your optimizer\n",
    "model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "print (model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MqlBfwFtmxfW"
   },
   "source": [
    "Let us create the `train_generator` and the `val_generator` which will be used in `.fit_generator`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "executionInfo": {
     "elapsed": 4551,
     "status": "ok",
     "timestamp": 1604436128132,
     "user": {
      "displayName": "Amit Chawla",
      "photoUrl": "",
      "userId": "06080236380106251748"
     },
     "user_tz": -330
    },
    "id": "c45IEYaZmxfX"
   },
   "outputs": [],
   "source": [
    "train_generator = generator(train_path, train_doc, batch_size)\n",
    "val_generator = generator(val_path, val_doc, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4544,
     "status": "ok",
     "timestamp": 1604436128132,
     "user": {
      "displayName": "Amit Chawla",
      "photoUrl": "",
      "userId": "06080236380106251748"
     },
     "user_tz": -330
    },
    "id": "c6E-9uGqmxfZ",
    "outputId": "59d5557a-1311-4c21-ec60-8e3a5b71cadb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n"
     ]
    }
   ],
   "source": [
    "model_name = 'model_init_CNN' + '_' + str(curr_dt_time).replace(' ','').replace(':','_') + '/'\n",
    "    \n",
    "if not os.path.exists(model_name):\n",
    "    os.mkdir(model_name)\n",
    "        \n",
    "filepath = model_name + 'model-{epoch:05d}-{loss:.5f}-{categorical_accuracy:.5f}-{val_loss:.5f}-{val_categorical_accuracy:.5f}.h5'\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath, save_best_only=True, monitor='val_loss', verbose=1, save_weights_only=False, mode='auto', period=1)\n",
    "\n",
    "LR = ReduceLROnPlateau(monitor='val_loss', factor=0.001, patience=5, cooldown=4, verbose=1,mode='auto',epsilon=0.0001)# write the REducelronplateau code here\n",
    "callbacks_list = [checkpoint, LR]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hErw7p94mxfb"
   },
   "source": [
    "The `steps_per_epoch` and `validation_steps` are used by `fit_generator` to decide the number of next() calls it need to make."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "executionInfo": {
     "elapsed": 4538,
     "status": "ok",
     "timestamp": 1604436128133,
     "user": {
      "displayName": "Amit Chawla",
      "photoUrl": "",
      "userId": "06080236380106251748"
     },
     "user_tz": -330
    },
    "id": "iCuo6cpBmxfc"
   },
   "outputs": [],
   "source": [
    "if (num_train_sequences%batch_size) == 0:\n",
    "    steps_per_epoch = int(num_train_sequences/batch_size)\n",
    "else:\n",
    "    steps_per_epoch = (num_train_sequences//batch_size) + 1\n",
    "\n",
    "if (num_val_sequences%batch_size) == 0:\n",
    "    validation_steps = int(num_val_sequences/batch_size)\n",
    "else:\n",
    "    validation_steps = (num_val_sequences//batch_size) + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xj_F8IVMmxff"
   },
   "source": [
    "Let us now fit the model. This will start training the model and with the help of the checkpoints, you'll be able to save the model at the end of each epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QYF2SSQtmxfh",
    "outputId": "5e024d26-ac4d-4614-a8c8-a8477b53f1b7"
   },
   "outputs": [],
   "source": [
    "model.fit_generator(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
    "                   callbacks=callbacks_list, validation_data=val_generator, \n",
    "                   validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write your model here\n",
    "\n",
    "feature_map=[8, 16, 32, 64, 128] # we will expirment with different number of features for different layers\n",
    "dense_layer_size = [1000,500,5]\n",
    "classes= 5\n",
    "input_shape = (frames, rows, cols, channels)\n",
    "model = Sequential()\n",
    "# add multiple convulation layers\n",
    "model.add(TimeDistributed(Conv2D(feature_map[0], (3, 3), strides=(2, 2),activation='relu', padding='same'), input_shape=input_shape))\n",
    "\n",
    "model.add(TimeDistributed(Conv2D(feature_map[1], (3,3),padding='same', activation='relu')))\n",
    "model.add(TimeDistributed(MaxPooling2D((2, 2), strides=(2, 2))))\n",
    "model.add(TimeDistributed(BatchNormalization()))\n",
    "\n",
    "# model.add(keras.layers.Dropout(0.4))\n",
    "\n",
    "model.add(TimeDistributed(Conv2D(feature_map[2], (3,3),padding='same', activation='relu')))\n",
    "model.add(TimeDistributed(MaxPooling2D((2, 2), strides=(2, 2))))\n",
    "# model.add(keras.layers.Dropout(0.4))\n",
    "model.add(TimeDistributed(BatchNormalization()))\n",
    "\n",
    "model.add(TimeDistributed(Conv2D(feature_map[3], (2,2),padding='same', activation='relu')))\n",
    "model.add(TimeDistributed(MaxPooling2D((2, 2), strides=(2, 2))))\n",
    "\n",
    "# model.add(TimeDistributed(Conv2D(feature_map[4], (2,2),padding='same', activation='relu')))\n",
    "# model.add(TimeDistributed(MaxPooling2D((2, 2), strides=(2, 2))))\n",
    "\n",
    "\n",
    "model.add(TimeDistributed(BatchNormalization()))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(TimeDistributed(Flatten()))\n",
    "\n",
    "model.add(Dense(dense_layer_size[0], activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(dense_layer_size[1], activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "## using GRU as the RNN model along with softmax as our last layer.\n",
    "model.add(LSTM(128, return_sequences=False))\n",
    "model.add(Dense(classes, activation='softmax')) # using Softmax as last layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimiser = optimizers.Adam(0.001) #write your optimizer\n",
    "model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "print (model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'model_init_lstm' + '_' + str(curr_dt_time).replace(' ','').replace(':','_') + '/'\n",
    "    \n",
    "if not os.path.exists(model_name):\n",
    "    os.mkdir(model_name)\n",
    "        \n",
    "filepath = model_name + 'model-{epoch:05d}-{loss:.5f}-{categorical_accuracy:.5f}-{val_loss:.5f}-{val_categorical_accuracy:.5f}.h5'\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath, save_best_only=True, monitor='val_loss', verbose=1, save_weights_only=False, mode='auto', period=1)\n",
    "\n",
    "LR = ReduceLROnPlateau(monitor='val_loss', factor=0.001, patience=5, cooldown=4, verbose=1,mode='auto',epsilon=0.0001)# write the REducelronplateau code here\n",
    "callbacks_list = [checkpoint, LR]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = generator(train_path, train_doc, batch_size)\n",
    "val_generator = generator(val_path, val_doc, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit_generator(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
    "                   callbacks=callbacks_list, validation_data=val_generator, \n",
    "                   validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0eCOFgTUmxfj"
   },
   "source": [
    "## Conv3D model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "y6zFhT4ugNe6"
   },
   "outputs": [],
   "source": [
    "filters = [8,16,32,64]\n",
    "dense = [256, 128, 5]\n",
    "\n",
    "# Input\n",
    "input_shape=(frames, rows, cols, channels)\n",
    "\n",
    "# Define model\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv3D(filters[0], \n",
    "                 kernel_size=(3,3,3), \n",
    "                 input_shape=input_shape,\n",
    "                 padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(MaxPooling3D(pool_size=(2,2,2)))\n",
    "\n",
    "model.add(Conv3D(filters[1], \n",
    "                 kernel_size=(3,3,3), \n",
    "                 padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(MaxPooling3D(pool_size=(2,2,2)))\n",
    "\n",
    "model.add(Conv3D(filters[2], \n",
    "                 kernel_size=(1,3,3), \n",
    "                 padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(MaxPooling3D(pool_size=(2,2,2)))\n",
    "\n",
    "model.add(Conv3D(filters[3], \n",
    "                 kernel_size=(1,3,3), \n",
    "                 padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(MaxPooling3D(pool_size=(2,2,2)))\n",
    "\n",
    "#Flatten Layers\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(dense[0], activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(dense[1], activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "#softmax layer\n",
    "model.add(Dense(dense[2], activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv3d (Conv3D)              (None, 30, 120, 120, 8)   656       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 30, 120, 120, 8)   32        \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 30, 120, 120, 8)   0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d (MaxPooling3D) (None, 15, 60, 60, 8)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_1 (Conv3D)            (None, 15, 60, 60, 16)    3472      \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 15, 60, 60, 16)    64        \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 15, 60, 60, 16)    0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_1 (MaxPooling3 (None, 7, 30, 30, 16)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_2 (Conv3D)            (None, 7, 30, 30, 32)     4640      \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 7, 30, 30, 32)     128       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 7, 30, 30, 32)     0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_2 (MaxPooling3 (None, 3, 15, 15, 32)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_3 (Conv3D)            (None, 3, 15, 15, 64)     18496     \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 3, 15, 15, 64)     0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 3, 15, 15, 64)     0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_3 (MaxPooling3 (None, 1, 7, 7, 64)       0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 3136)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 256)               803072    \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 5)                 645       \n",
      "=================================================================\n",
      "Total params: 864,101\n",
      "Trainable params: 863,989\n",
      "Non-trainable params: 112\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "optimiser = optimizers.Adam() #write your optimizer\n",
    "model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "print (model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = generator(train_path, train_doc, batch_size)\n",
    "val_generator = generator(val_path, val_doc, batch_size,validation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    }
   ],
   "source": [
    "model_name = 'model_init_Conv3D' + '_' + str(curr_dt_time).replace(' ','').replace(':','_') + '/'\n",
    "    \n",
    "if not os.path.exists(model_name):\n",
    "    os.mkdir(model_name)\n",
    "        \n",
    "filepath = model_name + 'model-{epoch:05d}-{loss:.5f}-{categorical_accuracy:.5f}-{val_loss:.5f}-{val_categorical_accuracy:.5f}.h5'\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath, save_best_only=True, monitor='val_loss', verbose=1, save_weights_only=False, mode='auto', period=1)\n",
    "\n",
    "# write the Reducelronplateau code here\n",
    "LR = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, cooldown=1, verbose=1)\n",
    "callbacks_list = [checkpoint, LR]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (num_train_sequences%batch_size) == 0:\n",
    "    steps_per_epoch = int(num_train_sequences/batch_size)\n",
    "else:\n",
    "    steps_per_epoch = (num_train_sequences//batch_size) + 1\n",
    "\n",
    "if (num_val_sequences%batch_size) == 0:\n",
    "    validation_steps = int(num_val_sequences/batch_size)\n",
    "else:\n",
    "    validation_steps = (num_val_sequences//batch_size) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 10\n",
    "num_epochs = 20\n",
    "#model.fit_generator(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
    " #                   callbacks=callbacks_list, validation_data=val_generator, \n",
    "  #                  validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Changing dense hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes= 5\n",
    "input_shape = (frames, rows, cols, channels)\n",
    "\n",
    "nb_filters = [8,16,32,64]\n",
    "nb_dense = [1000, 500, 5]\n",
    "\n",
    "# Define model\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv3D(nb_filters[0], \n",
    "                 kernel_size=(3,3,3), \n",
    "                 input_shape=input_shape,\n",
    "                 padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(MaxPooling3D(pool_size=(2,2,2)))\n",
    "\n",
    "model.add(Conv3D(nb_filters[1], \n",
    "                 kernel_size=(3,3,3), \n",
    "                 padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(MaxPooling3D(pool_size=(2,2,2)))\n",
    "\n",
    "model.add(Conv3D(nb_filters[2], \n",
    "                 kernel_size=(1,3,3), \n",
    "                 padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(MaxPooling3D(pool_size=(2,2,2)))\n",
    "\n",
    "model.add(Conv3D(nb_filters[3], \n",
    "                 kernel_size=(1,3,3), \n",
    "                 padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(MaxPooling3D(pool_size=(2,2,2)))\n",
    "\n",
    "#Flatten Layers\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(nb_dense[0], activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(nb_dense[1], activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "#softmax layer\n",
    "model.add(Dense(nb_dense[2], activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv3d_4 (Conv3D)            (None, 30, 120, 120, 8)   656       \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 30, 120, 120, 8)   32        \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 30, 120, 120, 8)   0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_4 (MaxPooling3 (None, 15, 60, 60, 8)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_5 (Conv3D)            (None, 15, 60, 60, 16)    3472      \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 15, 60, 60, 16)    64        \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 15, 60, 60, 16)    0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_5 (MaxPooling3 (None, 7, 30, 30, 16)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_6 (Conv3D)            (None, 7, 30, 30, 32)     4640      \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 7, 30, 30, 32)     128       \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 7, 30, 30, 32)     0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_6 (MaxPooling3 (None, 3, 15, 15, 32)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_7 (Conv3D)            (None, 3, 15, 15, 64)     18496     \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 3, 15, 15, 64)     0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 3, 15, 15, 64)     0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_7 (MaxPooling3 (None, 1, 7, 7, 64)       0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 3136)              0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1000)              3137000   \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 500)               500500    \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 5)                 2505      \n",
      "=================================================================\n",
      "Total params: 3,667,493\n",
      "Trainable params: 3,667,381\n",
      "Non-trainable params: 112\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "optimiser = optimizers.Adam() #write your optimizer\n",
    "model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "print (model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = generator(train_path, train_doc, batch_size)\n",
    "val_generator = generator(val_path, val_doc, batch_size,validation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (num_train_sequences%batch_size) == 0:\n",
    "    steps_per_epoch = int(num_train_sequences/batch_size)\n",
    "else:\n",
    "    steps_per_epoch = (num_train_sequences//batch_size) + 1\n",
    "\n",
    "if (num_val_sequences%batch_size) == 0:\n",
    "    validation_steps = int(num_val_sequences/batch_size)\n",
    "else:\n",
    "    validation_steps = (num_val_sequences//batch_size) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 10\n",
    "num_epochs = 20\n",
    "#model.fit_generator(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
    " #                   callbacks=callbacks_list, validation_data=val_generator, \n",
    "  #                  validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding one extra layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes= 5\n",
    "input_shape = (frames, rows, cols, channels)\n",
    "\n",
    "nb_filters = [8, 16, 32, 64, 128]\n",
    "nb_dense = [1000, 500, 5]\n",
    "\n",
    "# Define model\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv3D(nb_filters[0], \n",
    "                 kernel_size=(3,3,3), \n",
    "                 input_shape=input_shape,\n",
    "                 padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(MaxPooling3D(pool_size=(2,2,2)))\n",
    "\n",
    "model.add(Conv3D(nb_filters[1], \n",
    "                 kernel_size=(3,3,3), \n",
    "                 padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(MaxPooling3D(pool_size=(2,2,2)))\n",
    "\n",
    "model.add(Conv3D(nb_filters[2], \n",
    "                 kernel_size=(1,3,3), \n",
    "                 padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(MaxPooling3D(pool_size=(2,2,2)))\n",
    "\n",
    "model.add(Conv3D(nb_filters[3], \n",
    "                 kernel_size=(1,3,3), \n",
    "                 padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv3D(nb_filters[4], \n",
    "                 kernel_size=(1,3,3), \n",
    "                 padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(MaxPooling3D(pool_size=(2,2,2)))\n",
    "\n",
    "\n",
    "#Flatten Layers\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(nb_dense[0], activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(nb_dense[1], activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "#softmax layer\n",
    "model.add(Dense(nb_dense[2], activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv3d_8 (Conv3D)            (None, 30, 120, 120, 8)   656       \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 30, 120, 120, 8)   32        \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 30, 120, 120, 8)   0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_8 (MaxPooling3 (None, 15, 60, 60, 8)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_9 (Conv3D)            (None, 15, 60, 60, 16)    3472      \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 15, 60, 60, 16)    64        \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 15, 60, 60, 16)    0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_9 (MaxPooling3 (None, 7, 30, 30, 16)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_10 (Conv3D)           (None, 7, 30, 30, 32)     4640      \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 7, 30, 30, 32)     128       \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 7, 30, 30, 32)     0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_10 (MaxPooling (None, 3, 15, 15, 32)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_11 (Conv3D)           (None, 3, 15, 15, 64)     18496     \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 3, 15, 15, 64)     0         \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 3, 15, 15, 64)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_12 (Conv3D)           (None, 3, 15, 15, 128)    73856     \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 3, 15, 15, 128)    0         \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 3, 15, 15, 128)    0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_11 (MaxPooling (None, 1, 7, 7, 128)      0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 6272)              0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 1000)              6273000   \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 500)               500500    \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 5)                 2505      \n",
      "=================================================================\n",
      "Total params: 6,877,349\n",
      "Trainable params: 6,877,237\n",
      "Non-trainable params: 112\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "optimiser = optimizers.Adam() #write your optimizer\n",
    "model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "print (model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = generator(train_path, train_doc, batch_size)\n",
    "val_generator = generator(val_path, val_doc, batch_size,validation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (num_train_sequences%batch_size) == 0:\n",
    "    steps_per_epoch = int(num_train_sequences/batch_size)\n",
    "else:\n",
    "    steps_per_epoch = (num_train_sequences//batch_size) + 1\n",
    "\n",
    "if (num_val_sequences%batch_size) == 0:\n",
    "    validation_steps = int(num_val_sequences/batch_size)\n",
    "else:\n",
    "    validation_steps = (num_val_sequences//batch_size) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 10\n",
    "num_epochs = 20\n",
    "#model.fit_generator(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
    " #                   callbacks=callbacks_list, validation_data=val_generator, \n",
    "  #                  validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Neural_Nets_Project_Starter_Code.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
